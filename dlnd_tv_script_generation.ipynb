{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TV Script Generation\n",
    "\n",
    "In this project, you'll generate your own [Seinfeld](https://en.wikipedia.org/wiki/Seinfeld) TV scripts using RNNs.  You'll be using part of the [Seinfeld dataset](https://www.kaggle.com/thec03u5/seinfeld-chronicles#scripts.csv) of scripts from 9 seasons.  The Neural Network you'll build will generate a new ,\"fake\" TV script, based on patterns it recognizes in this training data.\n",
    "\n",
    "## Get the Data\n",
    "\n",
    "The data is already provided for you in `./data/Seinfeld_Scripts.txt` and you're encouraged to open that file and look at the text. \n",
    ">* As a first step, we'll load in this data and look at some samples. \n",
    "* Then, you'll be tasked with defining and training an RNN to generate a new script!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# load in data\n",
    "import helper\n",
    "data_dir = './data/Seinfeld_Scripts.txt'\n",
    "text = helper.load_data(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "Play around with `view_line_range` to view different parts of the data. This will give you a sense of the data you'll be working with. You can see, for example, that it is all lowercase text, and each new line of dialogue is separated by a newline character `\\n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Stats\n",
      "Roughly the number of unique words: 46367\n",
      "Number of lines: 109233\n",
      "Average number of words in each line: 5.544240293684143\n",
      "\n",
      "The lines 0 to 10:\n",
      "jerry: do you know what this is all about? do you know, why were here? to be out, this is out...and out is one of the single most enjoyable experiences of life. people...did you ever hear people talking about we should go out? this is what theyre talking about...this whole thing, were all out now, no one is home. not one person here is home, were all out! there are people trying to find us, they dont know where we are. (on an imaginary phone) did you ring?, i cant find him. where did he go? he didnt tell me where he was going. he must have gone out. you wanna go out you get ready, you pick out the clothes, right? you take the shower, you get all ready, get the cash, get your friends, the car, the spot, the reservation...then youre standing around, what do you do? you go we gotta be getting back. once youre out, you wanna get back! you wanna go to sleep, you wanna get up, you wanna go out again tomorrow, right? where ever you are in life, its my feeling, youve gotta go. \n",
      "\n",
      "jerry: (pointing at georges shirt) see, to me, that button is in the worst possible spot. the second button literally makes or breaks the shirt, look at it. its too high! its in no-mans-land. you look like you live with your mother. \n",
      "\n",
      "george: are you through? \n",
      "\n",
      "jerry: you do of course try on, when you buy? \n",
      "\n",
      "george: yes, it was purple, i liked it, i dont actually recall considering the buttons. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "view_line_range = (0, 10)\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "print('Dataset Stats')\n",
    "print('Roughly the number of unique words: {}'.format(len({word: None for word in text.split()})))\n",
    "\n",
    "lines = text.split('\\n')\n",
    "print('Number of lines: {}'.format(len(lines)))\n",
    "word_count_line = [len(line.split()) for line in lines]\n",
    "print('Average number of words in each line: {}'.format(np.average(word_count_line)))\n",
    "\n",
    "print()\n",
    "print('The lines {} to {}:'.format(*view_line_range))\n",
    "print('\\n'.join(text.split('\\n')[view_line_range[0]:view_line_range[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Implement Pre-processing Functions\n",
    "The first thing to do to any dataset is pre-processing.  Implement the following pre-processing functions below:\n",
    "- Lookup Table\n",
    "- Tokenize Punctuation\n",
    "\n",
    "### Lookup Table\n",
    "To create a word embedding, you first need to transform the words to ids.  In this function, create two dictionaries:\n",
    "- Dictionary to go from the words to an id, we'll call `vocab_to_int`\n",
    "- Dictionary to go from the id to word, we'll call `int_to_vocab`\n",
    "\n",
    "Return these dictionaries in the following **tuple** `(vocab_to_int, int_to_vocab)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "import problem_unittests as tests\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def create_lookup_tables(text):\n",
    "    \"\"\"\n",
    "    Create lookup tables for vocabulary\n",
    "    :param text: The text of tv scripts split into words\n",
    "    :return: A tuple of dicts (vocab_to_int, int_to_vocab)\n",
    "    \"\"\"\n",
    "    \n",
    "    #word_counts = Counter(text)\n",
    "    # sorting the words from most to least frequent in text occurrence\n",
    "    #sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "    # create int_to_vocab dictionaries\n",
    "    #int_to_vocab = {ii: word for ii, word in enumerate(sorted_vocab)}\n",
    "    #vocab_to_int = {word: ii for ii, word in int_to_vocab.items()}\n",
    "    # return tuple\n",
    "    #return (vocab_to_int, int_to_vocab)\n",
    "\n",
    "    #vocab = set(text)\n",
    "    #vocab_to_int, int_to_vocab = {}, {}\n",
    "    #for i, w in enumerate(vocab):\n",
    "    #    vocab_to_int[w] = i\n",
    "    #    int_to_vocab[i] = w\n",
    "    #return (vocab_to_int, int_to_vocab)\n",
    "\n",
    "    word_count = Counter(text)\n",
    "    word_sorted = sorted(word_count, key=word_count.get, reverse=True)\n",
    "    vocab_to_int = {word: idx for idx, word in enumerate(word_sorted, 0)}\n",
    "    int_to_vocab = {idx: word for word, idx in vocab_to_int.items()}\n",
    "    # return tuple\n",
    "    return (vocab_to_int, int_to_vocab)\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_create_lookup_tables(create_lookup_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Punctuation\n",
    "We'll be splitting the script into a word array using spaces as delimiters.  However, punctuations like periods and exclamation marks can create multiple ids for the same word. For example, \"bye\" and \"bye!\" would generate two different word ids.\n",
    "\n",
    "Implement the function `token_lookup` to return a dict that will be used to tokenize symbols like \"!\" into \"||Exclamation_Mark||\".  Create a dictionary for the following symbols where the symbol is the key and value is the token:\n",
    "- Period ( **.** )\n",
    "- Comma ( **,** )\n",
    "- Quotation Mark ( **\"** )\n",
    "- Semicolon ( **;** )\n",
    "- Exclamation mark ( **!** )\n",
    "- Question mark ( **?** )\n",
    "- Left Parentheses ( **(** )\n",
    "- Right Parentheses ( **)** )\n",
    "- Dash ( **-** )\n",
    "- Return ( **\\n** )\n",
    "\n",
    "This dictionary will be used to tokenize the symbols and add the delimiter (space) around it.  This separates each symbols as its own word, making it easier for the neural network to predict the next word. Make sure you don't use a value that could be confused as a word; for example, instead of using the value \"dash\", try using something like \"||dash||\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def token_lookup():\n",
    "    \"\"\"\n",
    "    Generate a dict to turn punctuation into a token.\n",
    "    :return: Tokenized dictionary where the key is the punctuation and the value is the token\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    dict = {}\n",
    "    dict['.'] = '|Period|'\n",
    "    dict[','] = '|Comma|'\n",
    "    dict['\"'] = '|Quotation_Mark|'\n",
    "    dict[';'] = '|Semicolon|'\n",
    "    dict['!'] = '|Exclamation_Mark|'\n",
    "    dict['?'] = '|Question_Mark|'\n",
    "    dict['('] = '|Left_Parentheses|'\n",
    "    dict[')'] = '|Right_Parentheses|'\n",
    "    dict['-'] = '|Dash|'\n",
    "    dict['\\n'] = '|Return|'\n",
    "    return dict\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_tokenize(token_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process all the data and save it\n",
    "\n",
    "Running the code cell below will pre-process all the data and save it to file. You're encouraged to lok at the code for `preprocess_and_save_data` in the `helpers.py` file to see what it's doing in detail, but you do not need to change this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# pre-process training data\n",
    "helper.preprocess_and_save_data(data_dir, token_lookup, create_lookup_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint. If you ever decide to come back to this notebook or have to restart the notebook, you can start from here. The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import helper\n",
    "import problem_unittests as tests\n",
    "\n",
    "int_text, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Neural Network\n",
    "In this section, you'll build the components necessary to build an RNN by implementing the RNN Module and forward and backpropagation functions.\n",
    "\n",
    "### Check Access to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import torch\n",
    "\n",
    "# Check for a GPU\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if not train_on_gpu:\n",
    "    print('No GPU found. Please use a GPU to train your neural network.')\n",
    "    \n",
    "print(train_on_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input\n",
    "Let's start with the preprocessed input data. We'll use [TensorDataset](http://pytorch.org/docs/master/data.html#torch.utils.data.TensorDataset) to provide a known format to our dataset; in combination with [DataLoader](http://pytorch.org/docs/master/data.html#torch.utils.data.DataLoader), it will handle batching, shuffling, and other dataset iteration functions.\n",
    "\n",
    "You can create data with TensorDataset by passing in feature and target tensors. Then create a DataLoader as usual.\n",
    "```\n",
    "data = TensorDataset(feature_tensors, target_tensors)\n",
    "data_loader = torch.utils.data.DataLoader(data, \n",
    "                                          batch_size=batch_size)\n",
    "```\n",
    "\n",
    "### Batching\n",
    "Implement the `batch_data` function to batch `words` data into chunks of size `batch_size` using the `TensorDataset` and `DataLoader` classes.\n",
    "\n",
    ">You can batch words using the DataLoader, but it will be up to you to create `feature_tensors` and `target_tensors` of the correct size and content for a given `sequence_length`.\n",
    "\n",
    "For example, say we have these as input:\n",
    "```\n",
    "words = [1, 2, 3, 4, 5, 6, 7]\n",
    "sequence_length = 4\n",
    "```\n",
    "\n",
    "Your first `feature_tensor` should contain the values:\n",
    "```\n",
    "[1, 2, 3, 4]\n",
    "```\n",
    "And the corresponding `target_tensor` should just be the next \"word\"/tokenized word value:\n",
    "```\n",
    "5\n",
    "```\n",
    "This should continue with the second `feature_tensor`, `target_tensor` being:\n",
    "```\n",
    "[2, 3, 4, 5]  # features\n",
    "6             # target\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "def batch_data(words, sequence_length, batch_size):\n",
    "    \"\"\"\n",
    "    Batch the neural network data using DataLoader\n",
    "    :param words: The word ids of the TV scripts\n",
    "    :param sequence_length: The sequence length of each batch\n",
    "    :param batch_size: The size of each batch; the number of sequences in a batch\n",
    "    :return: DataLoader with batched data\n",
    "    \"\"\"\n",
    "    # TODO: Implement function\n",
    "    n_batches = len(words)//batch_size\n",
    "    \n",
    "    text_size = len(words)\n",
    "    feature, target = [], []\n",
    "    \n",
    "    for idx in range(text_size - sequence_length):\n",
    "        feature_temp = words[idx: idx+sequence_length]\n",
    "        target_temp = words[idx+sequence_length]\n",
    "        feature.append(feature_temp)\n",
    "        target.append(target_temp)\n",
    "        \n",
    "    \n",
    "    feature_tensors = torch.from_numpy(np.array(feature))\n",
    "    target_tensors = torch.from_numpy(np.array(target))\n",
    "    data = TensorDataset(feature_tensors, target_tensors)\n",
    "    data_loader = DataLoader(data, batch_size = batch_size)\n",
    "    # return a dataloader\n",
    "    return data_loader\n",
    "\n",
    "# there is no test for this function, but you are encouraged to create\n",
    "# print statements and tests of your own\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your dataloader \n",
    "\n",
    "You'll have to modify this code to test a batching function, but it should look fairly similar.\n",
    "\n",
    "Below, we're generating some test text data and defining a dataloader using the function you defined, above. Then, we are getting some sample batch of inputs `sample_x` and targets `sample_y` from our dataloader.\n",
    "\n",
    "Your code should return something like the following (likely in a different order, if you shuffled your data):\n",
    "\n",
    "```\n",
    "torch.Size([10, 5])\n",
    "tensor([[ 28,  29,  30,  31,  32],\n",
    "        [ 21,  22,  23,  24,  25],\n",
    "        [ 17,  18,  19,  20,  21],\n",
    "        [ 34,  35,  36,  37,  38],\n",
    "        [ 11,  12,  13,  14,  15],\n",
    "        [ 23,  24,  25,  26,  27],\n",
    "        [  6,   7,   8,   9,  10],\n",
    "        [ 38,  39,  40,  41,  42],\n",
    "        [ 25,  26,  27,  28,  29],\n",
    "        [  7,   8,   9,  10,  11]])\n",
    "\n",
    "torch.Size([10])\n",
    "tensor([ 33,  26,  22,  39,  16,  28,  11,  43,  30,  12])\n",
    "```\n",
    "\n",
    "### Sizes\n",
    "Your sample_x should be of size `(batch_size, sequence_length)` or (10, 5) in this case and sample_y should just have one dimension: batch_size (10). \n",
    "\n",
    "### Values\n",
    "\n",
    "You should also notice that the targets, sample_y, are the *next* value in the ordered test_text data. So, for an input sequence `[ 28,  29,  30,  31,  32]` that ends with the value `32`, the corresponding output should be `33`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 5])\n",
      "tensor([[  0,   1,   2,   3,   4],\n",
      "        [  1,   2,   3,   4,   5],\n",
      "        [  2,   3,   4,   5,   6],\n",
      "        [  3,   4,   5,   6,   7],\n",
      "        [  4,   5,   6,   7,   8],\n",
      "        [  5,   6,   7,   8,   9],\n",
      "        [  6,   7,   8,   9,  10],\n",
      "        [  7,   8,   9,  10,  11],\n",
      "        [  8,   9,  10,  11,  12],\n",
      "        [  9,  10,  11,  12,  13]])\n",
      "\n",
      "torch.Size([10])\n",
      "tensor([  5,   6,   7,   8,   9,  10,  11,  12,  13,  14])\n"
     ]
    }
   ],
   "source": [
    "# test dataloader\n",
    "\n",
    "test_text = range(50)\n",
    "t_loader = batch_data(test_text, sequence_length=5, batch_size=10)\n",
    "\n",
    "data_iter = iter(t_loader)\n",
    "sample_x, sample_y = data_iter.next()\n",
    "\n",
    "print(sample_x.shape)\n",
    "print(sample_x)\n",
    "print()\n",
    "print(sample_y.shape)\n",
    "print(sample_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Build the Neural Network\n",
    "Implement an RNN using PyTorch's [Module class](http://pytorch.org/docs/master/nn.html#torch.nn.Module). You may choose to use a GRU or an LSTM. To complete the RNN, you'll have to implement the following functions for the class:\n",
    " - `__init__` - The initialize function. \n",
    " - `init_hidden` - The initialization function for an LSTM/GRU hidden state\n",
    " - `forward` - Forward propagation function.\n",
    " \n",
    "The initialize function should create the layers of the neural network and save them to the class. The forward propagation function will use these layers to run forward propagation and generate an output and a hidden state.\n",
    "\n",
    "**The output of this model should be the *last* batch of word scores** after a complete sequence has been processed. That is, for each input sequence of words, we only want to output the word scores for a single, most likely, next word.\n",
    "\n",
    "### Hints\n",
    "\n",
    "1. Make sure to stack the outputs of the lstm to pass to your fully-connected layer, you can do this with `lstm_output = lstm_output.contiguous().view(-1, self.hidden_dim)`\n",
    "2. You can get the last batch of word scores by shaping the output of the final, fully-connected layer like so:\n",
    "\n",
    "```\n",
    "# reshape into (batch_size, seq_length, output_size)\n",
    "output = output.view(batch_size, -1, self.output_size)\n",
    "# get last batch\n",
    "out = output[:, -1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the PyTorch RNN Module\n",
    "        :param vocab_size: The number of input dimensions of the neural network (the size of the vocabulary)\n",
    "        :param output_size: The number of output dimensions of the neural network\n",
    "        :param embedding_dim: The size of embeddings, should you choose to use them        \n",
    "        :param hidden_dim: The size of the hidden layer outputs\n",
    "        :param dropout: dropout to add in between LSTM/GRU layers\n",
    "        \"\"\"\n",
    "        super(RNN, self).__init__()\n",
    "        # TODO: Implement function\n",
    "        # set class variables\n",
    "        self.output_size = output_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size,embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers,dropout=dropout,batch_first = True)\n",
    "        \n",
    "        # define model layers\n",
    "        self.fc = nn.Linear(hidden_dim,output_size)\n",
    "        #self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, nn_input, hidden):\n",
    "        \"\"\"\n",
    "        Forward propagation of the neural network\n",
    "        :param nn_input: The input to the neural network\n",
    "        :param hidden: The hidden state        \n",
    "        :return: Two Tensors, the output of the neural network and the latest hidden state\n",
    "        \"\"\"\n",
    "        # TODO: Implement function   \n",
    "        # get the batch size\n",
    "        batch_size = nn_input.size(0)\n",
    "        \n",
    "        # Embedding and LSTM layer\n",
    "        embeds = self.embedding(nn_input)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        \n",
    "        # stack up LSTM output to pass through the last FC output layer\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        # dropout layer after LSTM\n",
    "        #output = self.dropout(lstm_out)\n",
    "        output = lstm_out\n",
    "        \n",
    "        # last FC layer\n",
    "        output = self.fc(output)\n",
    "        \n",
    "        # reshape into (batch_size, seq_length, output_size)\n",
    "        output = output.view(batch_size, -1, self.output_size)\n",
    "        \n",
    "        # get last batch\n",
    "        out = output[:, -1]\n",
    "        # return one batch of output word scores and the hidden state\n",
    "        return out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        '''\n",
    "        Initialize the hidden state of an LSTM/GRU\n",
    "        :param batch_size: The batch_size of the hidden state\n",
    "        :return: hidden state of dims (n_layers, batch_size, hidden_dim)\n",
    "        '''\n",
    "        # Implement function\n",
    "        \n",
    "        # initialize hidden state with zero weights, and move to GPU if available\n",
    "        \n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_rnn(RNN, train_on_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define forward and backpropagation\n",
    "\n",
    "Use the RNN class you implemented to apply forward and back propagation. This function will be called, iteratively, in the training loop as follows:\n",
    "```\n",
    "loss = forward_back_prop(decoder, decoder_optimizer, criterion, inp, target)\n",
    "```\n",
    "\n",
    "And it should return the average loss over a batch and the hidden state returned by a call to `RNN(inp, hidden)`. Recall that you can get this loss by computing it, as usual, and calling `loss.item()`.\n",
    "\n",
    "**If a GPU is available, you should move your data to that GPU device, here.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def forward_back_prop(rnn, optimizer, criterion, inp, target, hidden):\n",
    "    \"\"\"\n",
    "    Forward and backward propagation on the neural network\n",
    "    :param decoder: The PyTorch Module that holds the neural network\n",
    "    :param decoder_optimizer: The PyTorch optimizer for the neural network\n",
    "    :param criterion: The PyTorch loss function\n",
    "    :param inp: A batch of input to the neural network\n",
    "    :param target: The target output for the batch of input\n",
    "    :return: The loss and the latest hidden state Tensor\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    # move data to GPU, if available\n",
    "    device = torch.cuda.is_available()\n",
    "    if device:\n",
    "       # rnn.cuda()\n",
    "        inp,target = inp.cuda(),target.cuda()\n",
    "    h = tuple([each.data for each in hidden])\n",
    "    \n",
    "    rnn.zero_grad()\n",
    "    output,h = rnn(inp, h)\n",
    "    loss = criterion(output,target)\n",
    "    \n",
    "    # perform backpropagation and optimization\n",
    "    #loss.backward(retain_graph=True)\n",
    "    loss.backward()\n",
    "    #loss.backward()\n",
    "    clip = 5\n",
    "    nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n",
    "    optimizer.step()\n",
    "\n",
    "    # return the loss over a batch and the hidden state produced by our model\n",
    "    return loss.item(), h\n",
    "\n",
    "# Note that these tests aren't completely extensive.\n",
    "# they are here to act as general checks on the expected outputs of your functions\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_forward_back_prop(RNN, forward_back_prop, train_on_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Training\n",
    "\n",
    "With the structure of the network complete and data ready to be fed in the neural network, it's time to train it.\n",
    "\n",
    "### Train Loop\n",
    "\n",
    "The training loop is implemented for you in the `train_decoder` function. This function will train the network over all the batches for the number of epochs given. The model progress will be shown every number of batches. This number is set with the `show_every_n_batches` parameter. You'll set this parameter along with other parameters in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "\n",
    "def train_rnn(rnn, batch_size, optimizer, criterion, n_epochs, show_every_n_batches=100):\n",
    "    batch_losses = []\n",
    "    \n",
    "    rnn.train()\n",
    "\n",
    "    print(\"Training for %d epoch(s)...\" % n_epochs)\n",
    "    for epoch_i in range(1, n_epochs + 1):\n",
    "        \n",
    "        # initialize hidden state\n",
    "        hidden = rnn.init_hidden(batch_size)\n",
    "        \n",
    "        for batch_i, (inputs, labels) in enumerate(train_loader, 1):\n",
    "            \n",
    "            # make sure you iterate over completely full batches, only\n",
    "            n_batches = len(train_loader.dataset)//batch_size\n",
    "            if(batch_i > n_batches):\n",
    "                break\n",
    "            \n",
    "            # forward, back prop\n",
    "            loss, hidden = forward_back_prop(rnn, optimizer, criterion, inputs, labels, hidden)          \n",
    "            # record loss\n",
    "            batch_losses.append(loss)\n",
    "\n",
    "            # printing loss stats\n",
    "            if batch_i % show_every_n_batches == 0:\n",
    "                print('Epoch: {:>4}/{:<4}  Loss: {}\\n'.format(\n",
    "                    epoch_i, n_epochs, np.average(batch_losses)))\n",
    "                batch_losses = []\n",
    "\n",
    "    # returns a trained rnn\n",
    "    return rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "Set and train the neural network with the following parameters:\n",
    "- Set `sequence_length` to the length of a sequence.\n",
    "- Set `batch_size` to the batch size.\n",
    "- Set `num_epochs` to the number of epochs to train for.\n",
    "- Set `learning_rate` to the learning rate for an Adam optimizer.\n",
    "- Set `vocab_size` to the number of uniqe tokens in our vocabulary.\n",
    "- Set `output_size` to the desired size of the output.\n",
    "- Set `embedding_dim` to the embedding dimension; smaller than the vocab_size.\n",
    "- Set `hidden_dim` to the hidden dimension of your RNN.\n",
    "- Set `n_layers` to the number of layers/cells in your RNN.\n",
    "- Set `show_every_n_batches` to the number of batches at which the neural network should print progress.\n",
    "\n",
    "If the network isn't getting the desired results, tweak these parameters and/or the layers in the `RNN` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data params\n",
    "# Sequence Length\n",
    "sequence_length = 10  # of words in a sequence\n",
    "# Batch Size\n",
    "batch_size = 32\n",
    "\n",
    "# data loader - do not change\n",
    "train_loader = batch_data(int_text, sequence_length, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "# Number of Epochs\n",
    "num_epochs = 10\n",
    "# Learning Rate\n",
    "learning_rate = 0.0005\n",
    "\n",
    "# Model parameters\n",
    "# Vocab size\n",
    "vocab_size = len(vocab_to_int)\n",
    "#vocab_size = len(set(vocab_to_int))\n",
    "# Output size\n",
    "output_size = vocab_size\n",
    "# Embedding Dimension\n",
    "embedding_dim = 200\n",
    "# Hidden Dimension\n",
    "hidden_dim = 256\n",
    "# Number of RNN Layers\n",
    "n_layers = 2\n",
    "\n",
    "# Show stats for every n number of batches\n",
    "show_every_n_batches = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "In the next cell, you'll train the neural network on the pre-processed data.  If you have a hard time getting a good loss, you may consider changing your hyperparameters. In general, you may get better results with larger hidden and n_layer dimensions, but larger models take a longer time to train. \n",
    "> **You should aim for a loss less than 3.5.** \n",
    "\n",
    "You should also experiment with different sequence lengths, which determine the size of the long range dependencies that a model can learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 10 epoch(s)...\n",
      "Epoch:    1/10    Loss: 7.090288038253784\n",
      "\n",
      "Epoch:    1/10    Loss: 5.894915170669556\n",
      "\n",
      "Epoch:    1/10    Loss: 5.411924130916596\n",
      "\n",
      "Epoch:    1/10    Loss: 5.4060809874534606\n",
      "\n",
      "Epoch:    1/10    Loss: 5.099718008041382\n",
      "\n",
      "Epoch:    1/10    Loss: 5.200321571826935\n",
      "\n",
      "Epoch:    1/10    Loss: 5.245385024547577\n",
      "\n",
      "Epoch:    1/10    Loss: 5.111312539577484\n",
      "\n",
      "Epoch:    1/10    Loss: 5.167422347068786\n",
      "\n",
      "Epoch:    1/10    Loss: 4.894117608070373\n",
      "\n",
      "Epoch:    1/10    Loss: 5.08760390996933\n",
      "\n",
      "Epoch:    1/10    Loss: 4.993311834335327\n",
      "\n",
      "Epoch:    1/10    Loss: 5.035841982364655\n",
      "\n",
      "Epoch:    1/10    Loss: 4.692293083667755\n",
      "\n",
      "Epoch:    1/10    Loss: 4.945197415351868\n",
      "\n",
      "Epoch:    1/10    Loss: 4.979721693992615\n",
      "\n",
      "Epoch:    1/10    Loss: 4.718140723705292\n",
      "\n",
      "Epoch:    1/10    Loss: 5.103805947303772\n",
      "\n",
      "Epoch:    1/10    Loss: 5.094625465869903\n",
      "\n",
      "Epoch:    1/10    Loss: 5.200520083904267\n",
      "\n",
      "Epoch:    1/10    Loss: 4.800583696365356\n",
      "\n",
      "Epoch:    1/10    Loss: 4.79495365858078\n",
      "\n",
      "Epoch:    1/10    Loss: 5.038623702526093\n",
      "\n",
      "Epoch:    1/10    Loss: 4.881453611850739\n",
      "\n",
      "Epoch:    1/10    Loss: 4.804549481868744\n",
      "\n",
      "Epoch:    1/10    Loss: 5.195021080970764\n",
      "\n",
      "Epoch:    1/10    Loss: 4.647465090751648\n",
      "\n",
      "Epoch:    1/10    Loss: 4.943960223197937\n",
      "\n",
      "Epoch:    1/10    Loss: 4.763712334632873\n",
      "\n",
      "Epoch:    1/10    Loss: 4.571537017822266\n",
      "\n",
      "Epoch:    1/10    Loss: 5.014767081737518\n",
      "\n",
      "Epoch:    1/10    Loss: 4.59100830078125\n",
      "\n",
      "Epoch:    1/10    Loss: 5.214503026008606\n",
      "\n",
      "Epoch:    1/10    Loss: 4.9205721306800845\n",
      "\n",
      "Epoch:    1/10    Loss: 4.621932981014251\n",
      "\n",
      "Epoch:    1/10    Loss: 4.5103610277175905\n",
      "\n",
      "Epoch:    1/10    Loss: 4.334624199867249\n",
      "\n",
      "Epoch:    1/10    Loss: 4.324752502441406\n",
      "\n",
      "Epoch:    1/10    Loss: 4.47028819322586\n",
      "\n",
      "Epoch:    1/10    Loss: 4.634322445392609\n",
      "\n",
      "Epoch:    1/10    Loss: 4.40320524930954\n",
      "\n",
      "Epoch:    1/10    Loss: 4.512807426452636\n",
      "\n",
      "Epoch:    1/10    Loss: 4.7743364381790165\n",
      "\n",
      "Epoch:    1/10    Loss: 4.629669386148453\n",
      "\n",
      "Epoch:    1/10    Loss: 5.06622239112854\n",
      "\n",
      "Epoch:    1/10    Loss: 4.64753841638565\n",
      "\n",
      "Epoch:    1/10    Loss: 4.5658670210838315\n",
      "\n",
      "Epoch:    1/10    Loss: 4.656116056442261\n",
      "\n",
      "Epoch:    1/10    Loss: 4.243968026638031\n",
      "\n",
      "Epoch:    1/10    Loss: 4.5661263847351075\n",
      "\n",
      "Epoch:    1/10    Loss: 4.575021846294403\n",
      "\n",
      "Epoch:    1/10    Loss: 4.467395038604736\n",
      "\n",
      "Epoch:    1/10    Loss: 4.687956770658493\n",
      "\n",
      "Epoch:    1/10    Loss: 4.542416360378265\n",
      "\n",
      "Epoch:    1/10    Loss: 4.594703667163849\n",
      "\n",
      "Epoch:    1/10    Loss: 4.567914354801178\n",
      "\n",
      "Epoch:    1/10    Loss: 4.297158603668213\n",
      "\n",
      "Epoch:    1/10    Loss: 4.169455223083496\n",
      "\n",
      "Epoch:    1/10    Loss: 4.193202135562896\n",
      "\n",
      "Epoch:    1/10    Loss: 4.403636033535004\n",
      "\n",
      "Epoch:    1/10    Loss: 4.675057327747345\n",
      "\n",
      "Epoch:    1/10    Loss: 4.661922707557678\n",
      "\n",
      "Epoch:    1/10    Loss: 4.551492347717285\n",
      "\n",
      "Epoch:    1/10    Loss: 4.107045304775238\n",
      "\n",
      "Epoch:    1/10    Loss: 4.251168522834778\n",
      "\n",
      "Epoch:    1/10    Loss: 4.355208311080933\n",
      "\n",
      "Epoch:    1/10    Loss: 4.218979120254517\n",
      "\n",
      "Epoch:    1/10    Loss: 4.57537362575531\n",
      "\n",
      "Epoch:    1/10    Loss: 4.24140711069107\n",
      "\n",
      "Epoch:    1/10    Loss: 4.305433330535888\n",
      "\n",
      "Epoch:    1/10    Loss: 4.414296479225158\n",
      "\n",
      "Epoch:    1/10    Loss: 4.549444336891174\n",
      "\n",
      "Epoch:    1/10    Loss: 4.455281052589417\n",
      "\n",
      "Epoch:    1/10    Loss: 4.472149233818055\n",
      "\n",
      "Epoch:    1/10    Loss: 4.465565297603607\n",
      "\n",
      "Epoch:    1/10    Loss: 4.2404426050186155\n",
      "\n",
      "Epoch:    1/10    Loss: 4.577906420230866\n",
      "\n",
      "Epoch:    1/10    Loss: 4.225916264057159\n",
      "\n",
      "Epoch:    1/10    Loss: 4.231818590164185\n",
      "\n",
      "Epoch:    1/10    Loss: 4.822988870143891\n",
      "\n",
      "Epoch:    1/10    Loss: 4.2320453071594235\n",
      "\n",
      "Epoch:    1/10    Loss: 4.997449209690094\n",
      "\n",
      "Epoch:    1/10    Loss: 4.688789823055267\n",
      "\n",
      "Epoch:    1/10    Loss: 4.314313526153565\n",
      "\n",
      "Epoch:    1/10    Loss: 4.308895661830902\n",
      "\n",
      "Epoch:    1/10    Loss: 4.382892415523529\n",
      "\n",
      "Epoch:    1/10    Loss: 4.590078887939453\n",
      "\n",
      "Epoch:    1/10    Loss: 4.77360515832901\n",
      "\n",
      "Epoch:    1/10    Loss: 4.616550908088684\n",
      "\n",
      "Epoch:    1/10    Loss: 4.322064576148986\n",
      "\n",
      "Epoch:    1/10    Loss: 4.541599056720734\n",
      "\n",
      "Epoch:    1/10    Loss: 4.312331743240357\n",
      "\n",
      "Epoch:    1/10    Loss: 4.45253830909729\n",
      "\n",
      "Epoch:    1/10    Loss: 4.288602786064148\n",
      "\n",
      "Epoch:    1/10    Loss: 4.42336156129837\n",
      "\n",
      "Epoch:    1/10    Loss: 4.401377465724945\n",
      "\n",
      "Epoch:    1/10    Loss: 4.4090990686416625\n",
      "\n",
      "Epoch:    1/10    Loss: 4.591848828792572\n",
      "\n",
      "Epoch:    1/10    Loss: 4.110520732402802\n",
      "\n",
      "Epoch:    1/10    Loss: 4.195004003047943\n",
      "\n",
      "Epoch:    1/10    Loss: 4.513130424022674\n",
      "\n",
      "Epoch:    1/10    Loss: 4.266294059753418\n",
      "\n",
      "Epoch:    1/10    Loss: 4.313323276042938\n",
      "\n",
      "Epoch:    1/10    Loss: 4.278446720838547\n",
      "\n",
      "Epoch:    1/10    Loss: 4.699334061145782\n",
      "\n",
      "Epoch:    1/10    Loss: 4.816274967193603\n",
      "\n",
      "Epoch:    1/10    Loss: 4.6074252033233645\n",
      "\n",
      "Epoch:    1/10    Loss: 4.286475036144257\n",
      "\n",
      "Epoch:    1/10    Loss: 4.218309760093689\n",
      "\n",
      "Epoch:    1/10    Loss: 4.579266221523285\n",
      "\n",
      "Epoch:    1/10    Loss: 4.475091512203217\n",
      "\n",
      "Epoch:    1/10    Loss: 4.401139454841614\n",
      "\n",
      "Epoch:    1/10    Loss: 4.325022749900818\n",
      "\n",
      "Epoch:    1/10    Loss: 4.392535936832428\n",
      "\n",
      "Epoch:    1/10    Loss: 4.728145377635956\n",
      "\n",
      "Epoch:    1/10    Loss: 4.614862728118896\n",
      "\n",
      "Epoch:    1/10    Loss: 4.564484488964081\n",
      "\n",
      "Epoch:    1/10    Loss: 4.351010248661042\n",
      "\n",
      "Epoch:    1/10    Loss: 4.63199478149414\n",
      "\n",
      "Epoch:    1/10    Loss: 4.606693911552429\n",
      "\n",
      "Epoch:    1/10    Loss: 4.559644310474396\n",
      "\n",
      "Epoch:    1/10    Loss: 4.374138512611389\n",
      "\n",
      "Epoch:    1/10    Loss: 4.588067846298218\n",
      "\n",
      "Epoch:    1/10    Loss: 4.420343868732452\n",
      "\n",
      "Epoch:    1/10    Loss: 4.321967453956604\n",
      "\n",
      "Epoch:    1/10    Loss: 4.090090181827545\n",
      "\n",
      "Epoch:    1/10    Loss: 4.5000449919700625\n",
      "\n",
      "Epoch:    1/10    Loss: 4.398192687034607\n",
      "\n",
      "Epoch:    1/10    Loss: 4.3900386691093445\n",
      "\n",
      "Epoch:    1/10    Loss: 4.556542794704438\n",
      "\n",
      "Epoch:    1/10    Loss: 4.602657005786896\n",
      "\n",
      "Epoch:    1/10    Loss: 4.229025874137879\n",
      "\n",
      "Epoch:    1/10    Loss: 4.413468277454376\n",
      "\n",
      "Epoch:    1/10    Loss: 4.366138870716095\n",
      "\n",
      "Epoch:    1/10    Loss: 4.474560341835022\n",
      "\n",
      "Epoch:    1/10    Loss: 4.38364652633667\n",
      "\n",
      "Epoch:    1/10    Loss: 4.303360960483551\n",
      "\n",
      "Epoch:    1/10    Loss: 4.374782400131226\n",
      "\n",
      "Epoch:    1/10    Loss: 4.323476548194885\n",
      "\n",
      "Epoch:    1/10    Loss: 4.198901388645172\n",
      "\n",
      "Epoch:    1/10    Loss: 4.147962081432342\n",
      "\n",
      "Epoch:    1/10    Loss: 4.183322846889496\n",
      "\n",
      "Epoch:    1/10    Loss: 4.343546917438507\n",
      "\n",
      "Epoch:    1/10    Loss: 4.485960555076599\n",
      "\n",
      "Epoch:    1/10    Loss: 4.100824825763702\n",
      "\n",
      "Epoch:    1/10    Loss: 4.4946490359306335\n",
      "\n",
      "Epoch:    1/10    Loss: 4.33027503490448\n",
      "\n",
      "Epoch:    1/10    Loss: 4.6719603967666625\n",
      "\n",
      "Epoch:    1/10    Loss: 4.287724404335022\n",
      "\n",
      "Epoch:    1/10    Loss: 4.588320960998535\n",
      "\n",
      "Epoch:    1/10    Loss: 4.693829424381256\n",
      "\n",
      "Epoch:    1/10    Loss: 4.334933061599731\n",
      "\n",
      "Epoch:    1/10    Loss: 4.188380062580109\n",
      "\n",
      "Epoch:    1/10    Loss: 4.09447211265564\n",
      "\n",
      "Epoch:    1/10    Loss: 4.091781249046326\n",
      "\n",
      "Epoch:    1/10    Loss: 4.119866242408753\n",
      "\n",
      "Epoch:    1/10    Loss: 4.205785603523254\n",
      "\n",
      "Epoch:    1/10    Loss: 3.9564998936653137\n",
      "\n",
      "Epoch:    1/10    Loss: 4.112690439224243\n",
      "\n",
      "Epoch:    1/10    Loss: 4.019377157688141\n",
      "\n",
      "Epoch:    1/10    Loss: 4.220739874839783\n",
      "\n",
      "Epoch:    1/10    Loss: 4.040549163818359\n",
      "\n",
      "Epoch:    1/10    Loss: 3.983921971321106\n",
      "\n",
      "Epoch:    1/10    Loss: 4.364625909328461\n",
      "\n",
      "Epoch:    1/10    Loss: 4.064952328205108\n",
      "\n",
      "Epoch:    1/10    Loss: 4.200089507102966\n",
      "\n",
      "Epoch:    1/10    Loss: 4.370724329948425\n",
      "\n",
      "Epoch:    1/10    Loss: 4.246586651802063\n",
      "\n",
      "Epoch:    1/10    Loss: 4.738604183197022\n",
      "\n",
      "Epoch:    1/10    Loss: 3.9581281638145445\n",
      "\n",
      "Epoch:    1/10    Loss: 3.7926697540283203\n",
      "\n",
      "Epoch:    1/10    Loss: 4.195975153446198\n",
      "\n",
      "Epoch:    1/10    Loss: 4.327482140064239\n",
      "\n",
      "Epoch:    1/10    Loss: 4.434552705287933\n",
      "\n",
      "Epoch:    1/10    Loss: 4.468010065555572\n",
      "\n",
      "Epoch:    1/10    Loss: 4.469390969276429\n",
      "\n",
      "Epoch:    1/10    Loss: 4.466616051197052\n",
      "\n",
      "Epoch:    1/10    Loss: 4.200689010620117\n",
      "\n",
      "Epoch:    1/10    Loss: 4.052900422811508\n",
      "\n",
      "Epoch:    1/10    Loss: 4.380759019851684\n",
      "\n",
      "Epoch:    1/10    Loss: 4.225824339389801\n",
      "\n",
      "Epoch:    1/10    Loss: 4.311024167537689\n",
      "\n",
      "Epoch:    1/10    Loss: 4.209251940250397\n",
      "\n",
      "Epoch:    1/10    Loss: 4.163405265808105\n",
      "\n",
      "Epoch:    1/10    Loss: 4.364073812961578\n",
      "\n",
      "Epoch:    1/10    Loss: 4.144964144229889\n",
      "\n",
      "Epoch:    1/10    Loss: 4.08530987739563\n",
      "\n",
      "Epoch:    1/10    Loss: 4.44806982755661\n",
      "\n",
      "Epoch:    1/10    Loss: 4.405650606155396\n",
      "\n",
      "Epoch:    1/10    Loss: 4.09447245836258\n",
      "\n",
      "Epoch:    1/10    Loss: 4.238593869209289\n",
      "\n",
      "Epoch:    1/10    Loss: 3.871163957118988\n",
      "\n",
      "Epoch:    1/10    Loss: 4.107931866645813\n",
      "\n",
      "Epoch:    1/10    Loss: 4.238696422576904\n",
      "\n",
      "Epoch:    1/10    Loss: 4.461709818840027\n",
      "\n",
      "Epoch:    1/10    Loss: 4.149113738536835\n",
      "\n",
      "Epoch:    1/10    Loss: 4.328434801101684\n",
      "\n",
      "Epoch:    1/10    Loss: 4.10216381907463\n",
      "\n",
      "Epoch:    1/10    Loss: 4.021791422367096\n",
      "\n",
      "Epoch:    1/10    Loss: 4.116592144966125\n",
      "\n",
      "Epoch:    1/10    Loss: 4.290508017539978\n",
      "\n",
      "Epoch:    1/10    Loss: 4.250146152973175\n",
      "\n",
      "Epoch:    1/10    Loss: 4.516613638401031\n",
      "\n",
      "Epoch:    1/10    Loss: 4.345841624736786\n",
      "\n",
      "Epoch:    1/10    Loss: 4.345132479667663\n",
      "\n",
      "Epoch:    1/10    Loss: 4.412532069683075\n",
      "\n",
      "Epoch:    1/10    Loss: 4.210472314357758\n",
      "\n",
      "Epoch:    1/10    Loss: 3.929828724861145\n",
      "\n",
      "Epoch:    1/10    Loss: 4.285911719799042\n",
      "\n",
      "Epoch:    1/10    Loss: 4.325464005470276\n",
      "\n",
      "Epoch:    1/10    Loss: 4.247419693470001\n",
      "\n",
      "Epoch:    1/10    Loss: 4.563864824771881\n",
      "\n",
      "Epoch:    1/10    Loss: 4.35052975654602\n",
      "\n",
      "Epoch:    1/10    Loss: 4.264136900901795\n",
      "\n",
      "Epoch:    1/10    Loss: 4.111651133298874\n",
      "\n",
      "Epoch:    1/10    Loss: 4.229503753185273\n",
      "\n",
      "Epoch:    1/10    Loss: 4.55916275024414\n",
      "\n",
      "Epoch:    1/10    Loss: 4.636907751560211\n",
      "\n",
      "Epoch:    1/10    Loss: 4.336189608573914\n",
      "\n",
      "Epoch:    1/10    Loss: 4.477638943195343\n",
      "\n",
      "Epoch:    1/10    Loss: 4.501386497020722\n",
      "\n",
      "Epoch:    1/10    Loss: 4.557698390483856\n",
      "\n",
      "Epoch:    1/10    Loss: 4.504855971336365\n",
      "\n",
      "Epoch:    1/10    Loss: 4.590828919410706\n",
      "\n",
      "Epoch:    1/10    Loss: 4.334665904045105\n",
      "\n",
      "Epoch:    1/10    Loss: 4.312178418636322\n",
      "\n",
      "Epoch:    1/10    Loss: 4.175449621677399\n",
      "\n",
      "Epoch:    1/10    Loss: 4.272910239696503\n",
      "\n",
      "Epoch:    1/10    Loss: 4.332830286026001\n",
      "\n",
      "Epoch:    1/10    Loss: 4.479378416538238\n",
      "\n",
      "Epoch:    1/10    Loss: 4.3820368194580075\n",
      "\n",
      "Epoch:    1/10    Loss: 4.185338494777679\n",
      "\n",
      "Epoch:    1/10    Loss: 4.552946007251739\n",
      "\n",
      "Epoch:    1/10    Loss: 4.328797924518585\n",
      "\n",
      "Epoch:    1/10    Loss: 4.158997235298156\n",
      "\n",
      "Epoch:    1/10    Loss: 4.475616471767426\n",
      "\n",
      "Epoch:    1/10    Loss: 4.464960808753967\n",
      "\n",
      "Epoch:    1/10    Loss: 4.348727502822876\n",
      "\n",
      "Epoch:    1/10    Loss: 4.518470375537873\n",
      "\n",
      "Epoch:    1/10    Loss: 4.281657862663269\n",
      "\n",
      "Epoch:    1/10    Loss: 4.683904914855957\n",
      "\n",
      "Epoch:    1/10    Loss: 4.340523173809052\n",
      "\n",
      "Epoch:    1/10    Loss: 4.344372310638428\n",
      "\n",
      "Epoch:    1/10    Loss: 4.21558926820755\n",
      "\n",
      "Epoch:    1/10    Loss: 4.594617300033569\n",
      "\n",
      "Epoch:    1/10    Loss: 4.485712461471557\n",
      "\n",
      "Epoch:    1/10    Loss: 4.357873790264129\n",
      "\n",
      "Epoch:    1/10    Loss: 4.3061129450798035\n",
      "\n",
      "Epoch:    1/10    Loss: 4.2362432026863095\n",
      "\n",
      "Epoch:    1/10    Loss: 4.142596824169159\n",
      "\n",
      "Epoch:    1/10    Loss: 4.50513566493988\n",
      "\n",
      "Epoch:    1/10    Loss: 4.673825793266296\n",
      "\n",
      "Epoch:    1/10    Loss: 4.250999121665955\n",
      "\n",
      "Epoch:    1/10    Loss: 4.264027452468872\n",
      "\n",
      "Epoch:    1/10    Loss: 4.3615418672561646\n",
      "\n",
      "Epoch:    1/10    Loss: 4.248873255252838\n",
      "\n",
      "Epoch:    1/10    Loss: 4.571047232151032\n",
      "\n",
      "Epoch:    1/10    Loss: 4.358490192890168\n",
      "\n",
      "Epoch:    1/10    Loss: 4.367184655666351\n",
      "\n",
      "Epoch:    1/10    Loss: 4.513059089183807\n",
      "\n",
      "Epoch:    1/10    Loss: 4.616484599113464\n",
      "\n",
      "Epoch:    1/10    Loss: 4.355254342556\n",
      "\n",
      "Epoch:    1/10    Loss: 4.0370554351806645\n",
      "\n",
      "Epoch:    1/10    Loss: 4.303431749343872\n",
      "\n",
      "Epoch:    1/10    Loss: 4.321626467704773\n",
      "\n",
      "Epoch:    1/10    Loss: 4.191364846229553\n",
      "\n",
      "Epoch:    1/10    Loss: 4.129830181598663\n",
      "\n",
      "Epoch:    1/10    Loss: 4.291670956611633\n",
      "\n",
      "Epoch:    1/10    Loss: 4.562878727912903\n",
      "\n",
      "Epoch:    1/10    Loss: 4.467815532684326\n",
      "\n",
      "Epoch:    1/10    Loss: 4.413383266925812\n",
      "\n",
      "Epoch:    1/10    Loss: 4.377456135749817\n",
      "\n",
      "Epoch:    1/10    Loss: 4.216711316108704\n",
      "\n",
      "Epoch:    1/10    Loss: 4.0431692254543306\n",
      "\n",
      "Epoch:    1/10    Loss: 4.254811170101166\n",
      "\n",
      "Epoch:    1/10    Loss: 4.1954806256294255\n",
      "\n",
      "Epoch:    1/10    Loss: 4.205251576900483\n",
      "\n",
      "Epoch:    1/10    Loss: 5.308316037654877\n",
      "\n",
      "Epoch:    2/10    Loss: 4.625953044784203\n",
      "\n",
      "Epoch:    2/10    Loss: 4.196021797657013\n",
      "\n",
      "Epoch:    2/10    Loss: 4.000962858200073\n",
      "\n",
      "Epoch:    2/10    Loss: 4.131331901550293\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8797874593734742\n",
      "\n",
      "Epoch:    2/10    Loss: 3.92004727602005\n",
      "\n",
      "Epoch:    2/10    Loss: 4.120862264633178\n",
      "\n",
      "Epoch:    2/10    Loss: 4.045169012546539\n",
      "\n",
      "Epoch:    2/10    Loss: 4.105651280879974\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9006157326698303\n",
      "\n",
      "Epoch:    2/10    Loss: 4.203237638473511\n",
      "\n",
      "Epoch:    2/10    Loss: 4.087169668674469\n",
      "\n",
      "Epoch:    2/10    Loss: 4.148812980651855\n",
      "\n",
      "Epoch:    2/10    Loss: 3.825451545715332\n",
      "\n",
      "Epoch:    2/10    Loss: 4.13108475446701\n",
      "\n",
      "Epoch:    2/10    Loss: 4.12652765750885\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9144313144683838\n",
      "\n",
      "Epoch:    2/10    Loss: 4.224729199409484\n",
      "\n",
      "Epoch:    2/10    Loss: 4.129257833957672\n",
      "\n",
      "Epoch:    2/10    Loss: 4.309612939357757\n",
      "\n",
      "Epoch:    2/10    Loss: 3.966678705215454\n",
      "\n",
      "Epoch:    2/10    Loss: 4.058376002311706\n",
      "\n",
      "Epoch:    2/10    Loss: 4.226638827323914\n",
      "\n",
      "Epoch:    2/10    Loss: 4.089065217971802\n",
      "\n",
      "Epoch:    2/10    Loss: 4.072917037010193\n",
      "\n",
      "Epoch:    2/10    Loss: 4.429489433765411\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9676332235336305\n",
      "\n",
      "Epoch:    2/10    Loss: 4.303452844619751\n",
      "\n",
      "Epoch:    2/10    Loss: 4.107930266857148\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8104184079170227\n",
      "\n",
      "Epoch:    2/10    Loss: 4.318643913269043\n",
      "\n",
      "Epoch:    2/10    Loss: 3.991188862323761\n",
      "\n",
      "Epoch:    2/10    Loss: 4.581032721996308\n",
      "\n",
      "Epoch:    2/10    Loss: 4.315191116333008\n",
      "\n",
      "Epoch:    2/10    Loss: 3.999342889785767\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9264786505699156\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8155275058746336\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8272500443458557\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9467009329795837\n",
      "\n",
      "Epoch:    2/10    Loss: 4.029342098236084\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8170959091186525\n",
      "\n",
      "Epoch:    2/10    Loss: 3.903755168914795\n",
      "\n",
      "Epoch:    2/10    Loss: 4.142652156352997\n",
      "\n",
      "Epoch:    2/10    Loss: 4.0879744219779965\n",
      "\n",
      "Epoch:    2/10    Loss: 4.565581040382385\n",
      "\n",
      "Epoch:    2/10    Loss: 4.174946064949036\n",
      "\n",
      "Epoch:    2/10    Loss: 4.0536958026885985\n",
      "\n",
      "Epoch:    2/10    Loss: 4.147110362052917\n",
      "\n",
      "Epoch:    2/10    Loss: 3.715580358505249\n",
      "\n",
      "Epoch:    2/10    Loss: 4.048056809902191\n",
      "\n",
      "Epoch:    2/10    Loss: 4.111770663261414\n",
      "\n",
      "Epoch:    2/10    Loss: 4.027121806144715\n",
      "\n",
      "Epoch:    2/10    Loss: 4.195263835191727\n",
      "\n",
      "Epoch:    2/10    Loss: 4.093347773551941\n",
      "\n",
      "Epoch:    2/10    Loss: 4.090995061397552\n",
      "\n",
      "Epoch:    2/10    Loss: 4.053148283958435\n",
      "\n",
      "Epoch:    2/10    Loss: 3.804766137599945\n",
      "\n",
      "Epoch:    2/10    Loss: 3.754277250766754\n",
      "\n",
      "Epoch:    2/10    Loss: 3.736470458507538\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9033908915519713\n",
      "\n",
      "Epoch:    2/10    Loss: 4.243448700904846\n",
      "\n",
      "Epoch:    2/10    Loss: 4.19136754989624\n",
      "\n",
      "Epoch:    2/10    Loss: 4.077478184700012\n",
      "\n",
      "Epoch:    2/10    Loss: 3.7589319133758545\n",
      "\n",
      "Epoch:    2/10    Loss: 3.846339087486267\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9491188073158265\n",
      "\n",
      "Epoch:    2/10    Loss: 3.797410697937012\n",
      "\n",
      "Epoch:    2/10    Loss: 4.153872139453888\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8144248580932616\n",
      "\n",
      "Epoch:    2/10    Loss: 3.842268908023834\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9823370671272276\n",
      "\n",
      "Epoch:    2/10    Loss: 4.052906057834625\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9694839978218077\n",
      "\n",
      "Epoch:    2/10    Loss: 4.100977610349656\n",
      "\n",
      "Epoch:    2/10    Loss: 4.092369520664215\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8601923990249634\n",
      "\n",
      "Epoch:    2/10    Loss: 4.1624117684364315\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8192302536964418\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8893611550331117\n",
      "\n",
      "Epoch:    2/10    Loss: 4.4560505843162534\n",
      "\n",
      "Epoch:    2/10    Loss: 3.889811511039734\n",
      "\n",
      "Epoch:    2/10    Loss: 4.656055653095246\n",
      "\n",
      "Epoch:    2/10    Loss: 4.399210131168365\n",
      "\n",
      "Epoch:    2/10    Loss: 3.987085130214691\n",
      "\n",
      "Epoch:    2/10    Loss: 3.971007468700409\n",
      "\n",
      "Epoch:    2/10    Loss: 4.009726145267487\n",
      "\n",
      "Epoch:    2/10    Loss: 4.262996098995209\n",
      "\n",
      "Epoch:    2/10    Loss: 4.42141352891922\n",
      "\n",
      "Epoch:    2/10    Loss: 4.300295040607453\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9632002878189088\n",
      "\n",
      "Epoch:    2/10    Loss: 4.226294288635254\n",
      "\n",
      "Epoch:    2/10    Loss: 4.027535741329193\n",
      "\n",
      "Epoch:    2/10    Loss: 4.18270182132721\n",
      "\n",
      "Epoch:    2/10    Loss: 3.964969937801361\n",
      "\n",
      "Epoch:    2/10    Loss: 4.049885609149933\n",
      "\n",
      "Epoch:    2/10    Loss: 4.108212080001831\n",
      "\n",
      "Epoch:    2/10    Loss: 4.061647214889526\n",
      "\n",
      "Epoch:    2/10    Loss: 4.276603724956512\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8425485610961916\n",
      "\n",
      "Epoch:    2/10    Loss: 3.902836128473282\n",
      "\n",
      "Epoch:    2/10    Loss: 4.173086531162262\n",
      "\n",
      "Epoch:    2/10    Loss: 3.969913058280945\n",
      "\n",
      "Epoch:    2/10    Loss: 4.009596140384674\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9922447597980497\n",
      "\n",
      "Epoch:    2/10    Loss: 4.364590411186218\n",
      "\n",
      "Epoch:    2/10    Loss: 4.518572771549225\n",
      "\n",
      "Epoch:    2/10    Loss: 4.280149464607239\n",
      "\n",
      "Epoch:    2/10    Loss: 3.982909502983093\n",
      "\n",
      "Epoch:    2/10    Loss: 3.918229262828827\n",
      "\n",
      "Epoch:    2/10    Loss: 4.276424431800843\n",
      "\n",
      "Epoch:    2/10    Loss: 4.183782224655151\n",
      "\n",
      "Epoch:    2/10    Loss: 4.101113255023956\n",
      "\n",
      "Epoch:    2/10    Loss: 4.023585369586945\n",
      "\n",
      "Epoch:    2/10    Loss: 4.113712408542633\n",
      "\n",
      "Epoch:    2/10    Loss: 4.370419461727142\n",
      "\n",
      "Epoch:    2/10    Loss: 4.305069324970245\n",
      "\n",
      "Epoch:    2/10    Loss: 4.307471778392792\n",
      "\n",
      "Epoch:    2/10    Loss: 4.08299287557602\n",
      "\n",
      "Epoch:    2/10    Loss: 4.393953490257263\n",
      "\n",
      "Epoch:    2/10    Loss: 4.35637927532196\n",
      "\n",
      "Epoch:    2/10    Loss: 4.3453084754943845\n",
      "\n",
      "Epoch:    2/10    Loss: 4.144058594703674\n",
      "\n",
      "Epoch:    2/10    Loss: 4.324013793468476\n",
      "\n",
      "Epoch:    2/10    Loss: 4.127094841003418\n",
      "\n",
      "Epoch:    2/10    Loss: 4.071266405582428\n",
      "\n",
      "Epoch:    2/10    Loss: 3.851367623806\n",
      "\n",
      "Epoch:    2/10    Loss: 4.249733848571777\n",
      "\n",
      "Epoch:    2/10    Loss: 4.1676915264129635\n",
      "\n",
      "Epoch:    2/10    Loss: 4.135755157470703\n",
      "\n",
      "Epoch:    2/10    Loss: 4.322750170230865\n",
      "\n",
      "Epoch:    2/10    Loss: 4.379087030887604\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9447809052467346\n",
      "\n",
      "Epoch:    2/10    Loss: 4.153217799663544\n",
      "\n",
      "Epoch:    2/10    Loss: 4.124935309886933\n",
      "\n",
      "Epoch:    2/10    Loss: 4.251854650974273\n",
      "\n",
      "Epoch:    2/10    Loss: 4.135101661682129\n",
      "\n",
      "Epoch:    2/10    Loss: 4.08300703048706\n",
      "\n",
      "Epoch:    2/10    Loss: 4.147743291854859\n",
      "\n",
      "Epoch:    2/10    Loss: 4.096756200790406\n",
      "\n",
      "Epoch:    2/10    Loss: 3.945410726070404\n",
      "\n",
      "Epoch:    2/10    Loss: 3.926051068305969\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9341367936134337\n",
      "\n",
      "Epoch:    2/10    Loss: 4.10990471124649\n",
      "\n",
      "Epoch:    2/10    Loss: 4.2363605427742\n",
      "\n",
      "Epoch:    2/10    Loss: 3.882385528087616\n",
      "\n",
      "Epoch:    2/10    Loss: 4.2708221054077145\n",
      "\n",
      "Epoch:    2/10    Loss: 4.069803051948547\n",
      "\n",
      "Epoch:    2/10    Loss: 4.470027210712433\n",
      "\n",
      "Epoch:    2/10    Loss: 4.0596380710601805\n",
      "\n",
      "Epoch:    2/10    Loss: 4.392978937625885\n",
      "\n",
      "Epoch:    2/10    Loss: 4.466548006534577\n",
      "\n",
      "Epoch:    2/10    Loss: 4.145163300037384\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9517525959014894\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9349251103401186\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8878322398662566\n",
      "\n",
      "Epoch:    2/10    Loss: 3.916925346851349\n",
      "\n",
      "Epoch:    2/10    Loss: 4.001959834098816\n",
      "\n",
      "Epoch:    2/10    Loss: 3.701319324970245\n",
      "\n",
      "Epoch:    2/10    Loss: 3.895217573642731\n",
      "\n",
      "Epoch:    2/10    Loss: 3.802874732017517\n",
      "\n",
      "Epoch:    2/10    Loss: 4.00927684545517\n",
      "\n",
      "Epoch:    2/10    Loss: 3.811335290670395\n",
      "\n",
      "Epoch:    2/10    Loss: 3.7814947676658632\n",
      "\n",
      "Epoch:    2/10    Loss: 4.149768481254577\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8398987078666686\n",
      "\n",
      "Epoch:    2/10    Loss: 3.951160778999329\n",
      "\n",
      "Epoch:    2/10    Loss: 4.151201329231262\n",
      "\n",
      "Epoch:    2/10    Loss: 4.029481620788574\n",
      "\n",
      "Epoch:    2/10    Loss: 4.506129100322723\n",
      "\n",
      "Epoch:    2/10    Loss: 3.714001085758209\n",
      "\n",
      "Epoch:    2/10    Loss: 3.601021112203598\n",
      "\n",
      "Epoch:    2/10    Loss: 4.021236336231231\n",
      "\n",
      "Epoch:    2/10    Loss: 4.091025142669678\n",
      "\n",
      "Epoch:    2/10    Loss: 4.186951529979706\n",
      "\n",
      "Epoch:    2/10    Loss: 4.2410561466217045\n",
      "\n",
      "Epoch:    2/10    Loss: 4.213688247203827\n",
      "\n",
      "Epoch:    2/10    Loss: 4.138581142425537\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9485520553588866\n",
      "\n",
      "Epoch:    2/10    Loss: 3.750324597358704\n",
      "\n",
      "Epoch:    2/10    Loss: 4.1568265366554265\n",
      "\n",
      "Epoch:    2/10    Loss: 4.043588831424713\n",
      "\n",
      "Epoch:    2/10    Loss: 4.1160538244247435\n",
      "\n",
      "Epoch:    2/10    Loss: 3.989802129268646\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9770645928382873\n",
      "\n",
      "Epoch:    2/10    Loss: 4.16254840373993\n",
      "\n",
      "Epoch:    2/10    Loss: 3.937298903465271\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8634901452064514\n",
      "\n",
      "Epoch:    2/10    Loss: 4.217933747768402\n",
      "\n",
      "Epoch:    2/10    Loss: 4.198832154273987\n",
      "\n",
      "Epoch:    2/10    Loss: 3.905387463569641\n",
      "\n",
      "Epoch:    2/10    Loss: 4.097704539299011\n",
      "\n",
      "Epoch:    2/10    Loss: 3.6480613994598388\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9107866430282594\n",
      "\n",
      "Epoch:    2/10    Loss: 4.02788904428482\n",
      "\n",
      "Epoch:    2/10    Loss: 4.237089660167694\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9328166389465333\n",
      "\n",
      "Epoch:    2/10    Loss: 4.12775897026062\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9393187963962557\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8546792459487915\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9710178637504576\n",
      "\n",
      "Epoch:    2/10    Loss: 4.151322710514068\n",
      "\n",
      "Epoch:    2/10    Loss: 4.1101571297645565\n",
      "\n",
      "Epoch:    2/10    Loss: 4.335037431716919\n",
      "\n",
      "Epoch:    2/10    Loss: 4.1898757314682005\n",
      "\n",
      "Epoch:    2/10    Loss: 4.1571160459518435\n",
      "\n",
      "Epoch:    2/10    Loss: 4.213797433376312\n",
      "\n",
      "Epoch:    2/10    Loss: 4.0287574291229244\n",
      "\n",
      "Epoch:    2/10    Loss: 3.7913167524337767\n",
      "\n",
      "Epoch:    2/10    Loss: 4.106936466693878\n",
      "\n",
      "Epoch:    2/10    Loss: 4.153010722398758\n",
      "\n",
      "Epoch:    2/10    Loss: 4.074184303283691\n",
      "\n",
      "Epoch:    2/10    Loss: 4.394363515377044\n",
      "\n",
      "Epoch:    2/10    Loss: 4.20458153963089\n",
      "\n",
      "Epoch:    2/10    Loss: 4.119846897125244\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9681943225860596\n",
      "\n",
      "Epoch:    2/10    Loss: 4.080553760528565\n",
      "\n",
      "Epoch:    2/10    Loss: 4.39706237077713\n",
      "\n",
      "Epoch:    2/10    Loss: 4.468281693458557\n",
      "\n",
      "Epoch:    2/10    Loss: 4.1807622146606445\n",
      "\n",
      "Epoch:    2/10    Loss: 4.3249424147605895\n",
      "\n",
      "Epoch:    2/10    Loss: 4.375229115486145\n",
      "\n",
      "Epoch:    2/10    Loss: 4.3561833333969116\n",
      "\n",
      "Epoch:    2/10    Loss: 4.315381824970245\n",
      "\n",
      "Epoch:    2/10    Loss: 4.387214031219482\n",
      "\n",
      "Epoch:    2/10    Loss: 4.172858755588532\n",
      "\n",
      "Epoch:    2/10    Loss: 4.181986944675446\n",
      "\n",
      "Epoch:    2/10    Loss: 4.091661412715911\n",
      "\n",
      "Epoch:    2/10    Loss: 4.14514285326004\n",
      "\n",
      "Epoch:    2/10    Loss: 4.188531482219696\n",
      "\n",
      "Epoch:    2/10    Loss: 4.357428848743439\n",
      "\n",
      "Epoch:    2/10    Loss: 4.262636513710022\n",
      "\n",
      "Epoch:    2/10    Loss: 4.05230031490326\n",
      "\n",
      "Epoch:    2/10    Loss: 4.406823754310608\n",
      "\n",
      "Epoch:    2/10    Loss: 4.2384031915664675\n",
      "\n",
      "Epoch:    2/10    Loss: 4.056700208187103\n",
      "\n",
      "Epoch:    2/10    Loss: 4.318195371627808\n",
      "\n",
      "Epoch:    2/10    Loss: 4.3044781231880185\n",
      "\n",
      "Epoch:    2/10    Loss: 4.160398178100586\n",
      "\n",
      "Epoch:    2/10    Loss: 4.377396314144135\n",
      "\n",
      "Epoch:    2/10    Loss: 4.126102077960968\n",
      "\n",
      "Epoch:    2/10    Loss: 4.471699919700622\n",
      "\n",
      "Epoch:    2/10    Loss: 4.216911933422089\n",
      "\n",
      "Epoch:    2/10    Loss: 4.200306479930878\n",
      "\n",
      "Epoch:    2/10    Loss: 4.095487577915192\n",
      "\n",
      "Epoch:    2/10    Loss: 4.346183598041534\n",
      "\n",
      "Epoch:    2/10    Loss: 4.23867222070694\n",
      "\n",
      "Epoch:    2/10    Loss: 4.253510637283325\n",
      "\n",
      "Epoch:    2/10    Loss: 4.1903235912323\n",
      "\n",
      "Epoch:    2/10    Loss: 4.119844748973846\n",
      "\n",
      "Epoch:    2/10    Loss: 4.03846580028534\n",
      "\n",
      "Epoch:    2/10    Loss: 4.38886043548584\n",
      "\n",
      "Epoch:    2/10    Loss: 4.564017300605774\n",
      "\n",
      "Epoch:    2/10    Loss: 4.164620571136474\n",
      "\n",
      "Epoch:    2/10    Loss: 4.157414078712463\n",
      "\n",
      "Epoch:    2/10    Loss: 4.216650331020356\n",
      "\n",
      "Epoch:    2/10    Loss: 4.084669711589814\n",
      "\n",
      "Epoch:    2/10    Loss: 4.470161757469177\n",
      "\n",
      "Epoch:    2/10    Loss: 4.234568655490875\n",
      "\n",
      "Epoch:    2/10    Loss: 4.206043570041657\n",
      "\n",
      "Epoch:    2/10    Loss: 4.324158318042755\n",
      "\n",
      "Epoch:    2/10    Loss: 4.450643656253814\n",
      "\n",
      "Epoch:    2/10    Loss: 4.213975191116333\n",
      "\n",
      "Epoch:    2/10    Loss: 3.909110996723175\n",
      "\n",
      "Epoch:    2/10    Loss: 4.194098734855652\n",
      "\n",
      "Epoch:    2/10    Loss: 4.192832989692688\n",
      "\n",
      "Epoch:    2/10    Loss: 4.050466458797455\n",
      "\n",
      "Epoch:    2/10    Loss: 3.987778012752533\n",
      "\n",
      "Epoch:    2/10    Loss: 4.152326309680939\n",
      "\n",
      "Epoch:    2/10    Loss: 4.444596707820892\n",
      "\n",
      "Epoch:    2/10    Loss: 4.30483108997345\n",
      "\n",
      "Epoch:    2/10    Loss: 4.275114481449127\n",
      "\n",
      "Epoch:    2/10    Loss: 4.2387218141555785\n",
      "\n",
      "Epoch:    2/10    Loss: 4.0687494730949405\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9047777366638186\n",
      "\n",
      "Epoch:    2/10    Loss: 4.143657431602478\n",
      "\n",
      "Epoch:    2/10    Loss: 4.055112380981445\n",
      "\n",
      "Epoch:    2/10    Loss: 4.068757054805755\n",
      "\n",
      "Epoch:    2/10    Loss: 5.131657433509827\n",
      "\n",
      "Epoch:    3/10    Loss: 4.440958888343211\n",
      "\n",
      "Epoch:    3/10    Loss: 4.058416438102722\n",
      "\n",
      "Epoch:    3/10    Loss: 3.843589015007019\n",
      "\n",
      "Epoch:    3/10    Loss: 4.024634561538696\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7759314036369322\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8101051115989684\n",
      "\n",
      "Epoch:    3/10    Loss: 4.003898391723633\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8859517097473146\n",
      "\n",
      "Epoch:    3/10    Loss: 3.9879075717926025\n",
      "\n",
      "Epoch:    3/10    Loss: 3.801032528877258\n",
      "\n",
      "Epoch:    3/10    Loss: 4.093488025665283\n",
      "\n",
      "Epoch:    3/10    Loss: 3.969914404153824\n",
      "\n",
      "Epoch:    3/10    Loss: 4.046478399038315\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6970579552650453\n",
      "\n",
      "Epoch:    3/10    Loss: 3.977603863477707\n",
      "\n",
      "Epoch:    3/10    Loss: 3.98904895067215\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7928221654891967\n",
      "\n",
      "Epoch:    3/10    Loss: 4.0982144570350645\n",
      "\n",
      "Epoch:    3/10    Loss: 4.000493574142456\n",
      "\n",
      "Epoch:    3/10    Loss: 4.175609648227692\n",
      "\n",
      "Epoch:    3/10    Loss: 3.828997116088867\n",
      "\n",
      "Epoch:    3/10    Loss: 3.919443049430847\n",
      "\n",
      "Epoch:    3/10    Loss: 4.089567110538483\n",
      "\n",
      "Epoch:    3/10    Loss: 3.9313438510894776\n",
      "\n",
      "Epoch:    3/10    Loss: 3.931294901371002\n",
      "\n",
      "Epoch:    3/10    Loss: 4.267345118522644\n",
      "\n",
      "Epoch:    3/10    Loss: 3.829686679840088\n",
      "\n",
      "Epoch:    3/10    Loss: 4.205618028640747\n",
      "\n",
      "Epoch:    3/10    Loss: 4.009972289800644\n",
      "\n",
      "Epoch:    3/10    Loss: 3.668299708366394\n",
      "\n",
      "Epoch:    3/10    Loss: 4.14859335899353\n",
      "\n",
      "Epoch:    3/10    Loss: 3.858918125629425\n",
      "\n",
      "Epoch:    3/10    Loss: 4.43660032749176\n",
      "\n",
      "Epoch:    3/10    Loss: 4.1888437795639035\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8480521988868714\n",
      "\n",
      "Epoch:    3/10    Loss: 3.848298366069794\n",
      "\n",
      "Epoch:    3/10    Loss: 3.725555145740509\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7431074678897858\n",
      "\n",
      "Epoch:    3/10    Loss: 3.829715883731842\n",
      "\n",
      "Epoch:    3/10    Loss: 3.9208995020389557\n",
      "\n",
      "Epoch:    3/10    Loss: 3.689799506664276\n",
      "\n",
      "Epoch:    3/10    Loss: 3.803758087158203\n",
      "\n",
      "Epoch:    3/10    Loss: 3.998827118873596\n",
      "\n",
      "Epoch:    3/10    Loss: 3.981314021348953\n",
      "\n",
      "Epoch:    3/10    Loss: 4.437234661579132\n",
      "\n",
      "Epoch:    3/10    Loss: 4.074699892997741\n",
      "\n",
      "Epoch:    3/10    Loss: 3.9340746879577635\n",
      "\n",
      "Epoch:    3/10    Loss: 4.048551232814789\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5977569580078126\n",
      "\n",
      "Epoch:    3/10    Loss: 3.9259100484848024\n",
      "\n",
      "Epoch:    3/10    Loss: 3.978367612361908\n",
      "\n",
      "Epoch:    3/10    Loss: 3.9300816440582276\n",
      "\n",
      "Epoch:    3/10    Loss: 4.077539983987808\n",
      "\n",
      "Epoch:    3/10    Loss: 3.9819936418533324\n",
      "\n",
      "Epoch:    3/10    Loss: 3.977481904029846\n",
      "\n",
      "Epoch:    3/10    Loss: 3.90519419670105\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6912335896492006\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6442751908302307\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5918155169487\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7789304947853086\n",
      "\n",
      "Epoch:    3/10    Loss: 4.071207492351532\n",
      "\n",
      "Epoch:    3/10    Loss: 4.051517213582993\n",
      "\n",
      "Epoch:    3/10    Loss: 3.9555814027786256\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6347566986083986\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7319521367549897\n",
      "\n",
      "Epoch:    3/10    Loss: 3.831792550086975\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6758442759513854\n",
      "\n",
      "Epoch:    3/10    Loss: 3.9868054282665253\n",
      "\n",
      "Epoch:    3/10    Loss: 3.647494354248047\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7158543050289152\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8313042306900025\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8977405619621277\n",
      "\n",
      "Epoch:    3/10    Loss: 3.837875075340271\n",
      "\n",
      "Epoch:    3/10    Loss: 3.9757702708244325\n",
      "\n",
      "Epoch:    3/10    Loss: 3.9364812922477723\n",
      "\n",
      "Epoch:    3/10    Loss: 3.74492066860199\n",
      "\n",
      "Epoch:    3/10    Loss: 4.034022443294525\n",
      "\n",
      "Epoch:    3/10    Loss: 3.689513363838196\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7652010798454283\n",
      "\n",
      "Epoch:    3/10    Loss: 4.319091899394989\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7842578125\n",
      "\n",
      "Epoch:    3/10    Loss: 4.4861980414390565\n",
      "\n",
      "Epoch:    3/10    Loss: 4.221108503341675\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8732465863227845\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8305500102043153\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8613749670982362\n",
      "\n",
      "Epoch:    3/10    Loss: 4.107170610427857\n",
      "\n",
      "Epoch:    3/10    Loss: 4.275011658668518\n",
      "\n",
      "Epoch:    3/10    Loss: 4.167973823547364\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8298473453521726\n",
      "\n",
      "Epoch:    3/10    Loss: 4.130421445369721\n",
      "\n",
      "Epoch:    3/10    Loss: 3.956339192390442\n",
      "\n",
      "Epoch:    3/10    Loss: 4.088422718048096\n",
      "\n",
      "Epoch:    3/10    Loss: 3.83156854391098\n",
      "\n",
      "Epoch:    3/10    Loss: 3.935967140197754\n",
      "\n",
      "Epoch:    3/10    Loss: 3.9778690242767336\n",
      "\n",
      "Epoch:    3/10    Loss: 3.9352942156791686\n",
      "\n",
      "Epoch:    3/10    Loss: 4.138067498207092\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7403531634807585\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7775664579868318\n",
      "\n",
      "Epoch:    3/10    Loss: 4.016136844158172\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8155674505233765\n",
      "\n",
      "Epoch:    3/10    Loss: 3.869748901128769\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8822087562084198\n",
      "\n",
      "Epoch:    3/10    Loss: 4.248187680244445\n",
      "\n",
      "Epoch:    3/10    Loss: 4.388032255172729\n",
      "\n",
      "Epoch:    3/10    Loss: 4.171160182952881\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8799762105941773\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8121855950355528\n",
      "\n",
      "Epoch:    3/10    Loss: 4.1330783700942995\n",
      "\n",
      "Epoch:    3/10    Loss: 4.119937102794648\n",
      "\n",
      "Epoch:    3/10    Loss: 4.03680294752121\n",
      "\n",
      "Epoch:    3/10    Loss: 3.928841474056244\n",
      "\n",
      "Epoch:    3/10    Loss: 4.017680844068527\n",
      "\n",
      "Epoch:    3/10    Loss: 4.25999382019043\n",
      "\n",
      "Epoch:    3/10    Loss: 4.158947194814682\n",
      "\n",
      "Epoch:    3/10    Loss: 4.1737686252594\n",
      "\n",
      "Epoch:    3/10    Loss: 3.966066002845764\n",
      "\n",
      "Epoch:    3/10    Loss: 4.2766523361206055\n",
      "\n",
      "Epoch:    3/10    Loss: 4.29719379901886\n",
      "\n",
      "Epoch:    3/10    Loss: 4.219440853595733\n",
      "\n",
      "Epoch:    3/10    Loss: 4.025665743350983\n",
      "\n",
      "Epoch:    3/10    Loss: 4.224638953208923\n",
      "\n",
      "Epoch:    3/10    Loss: 4.056031441688537\n",
      "\n",
      "Epoch:    3/10    Loss: 3.9566151523590087\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7392429280281068\n",
      "\n",
      "Epoch:    3/10    Loss: 4.146548993587494\n",
      "\n",
      "Epoch:    3/10    Loss: 4.066578736305237\n",
      "\n",
      "Epoch:    3/10    Loss: 4.050143727064133\n",
      "\n",
      "Epoch:    3/10    Loss: 4.206949291229248\n",
      "\n",
      "Epoch:    3/10    Loss: 4.270279359817505\n",
      "\n",
      "Epoch:    3/10    Loss: 3.888159599304199\n",
      "\n",
      "Epoch:    3/10    Loss: 4.058192191123962\n",
      "\n",
      "Epoch:    3/10    Loss: 4.0395143961906435\n",
      "\n",
      "Epoch:    3/10    Loss: 4.1447558760643\n",
      "\n",
      "Epoch:    3/10    Loss: 4.015018916130066\n",
      "\n",
      "Epoch:    3/10    Loss: 3.968416485786438\n",
      "\n",
      "Epoch:    3/10    Loss: 4.040940749645233\n",
      "\n",
      "Epoch:    3/10    Loss: 3.9596535658836363\n",
      "\n",
      "Epoch:    3/10    Loss: 3.892508370876312\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8122359991073607\n",
      "\n",
      "Epoch:    3/10    Loss: 3.830988042354584\n",
      "\n",
      "Epoch:    3/10    Loss: 4.016281666755677\n",
      "\n",
      "Epoch:    3/10    Loss: 4.131256372928619\n",
      "\n",
      "Epoch:    3/10    Loss: 3.755675926208496\n",
      "\n",
      "Epoch:    3/10    Loss: 4.164415631294251\n",
      "\n",
      "Epoch:    3/10    Loss: 3.925339012145996\n",
      "\n",
      "Epoch:    3/10    Loss: 4.316969029903412\n",
      "\n",
      "Epoch:    3/10    Loss: 3.9440129566192628\n",
      "\n",
      "Epoch:    3/10    Loss: 4.270534379482269\n",
      "\n",
      "Epoch:    3/10    Loss: 4.374310791492462\n",
      "\n",
      "Epoch:    3/10    Loss: 4.019464304447174\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8807521200180055\n",
      "\n",
      "Epoch:    3/10    Loss: 3.843908807039261\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8175121784210204\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8308737897872924\n",
      "\n",
      "Epoch:    3/10    Loss: 3.9484487700462343\n",
      "\n",
      "Epoch:    3/10    Loss: 3.603752562999725\n",
      "\n",
      "Epoch:    3/10    Loss: 3.784992368221283\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7377567863464356\n",
      "\n",
      "Epoch:    3/10    Loss: 3.9250279569625857\n",
      "\n",
      "Epoch:    3/10    Loss: 3.715234980583191\n",
      "\n",
      "Epoch:    3/10    Loss: 3.735562151670456\n",
      "\n",
      "Epoch:    3/10    Loss: 4.0878861618041995\n",
      "\n",
      "Epoch:    3/10    Loss: 3.770792233943939\n",
      "\n",
      "Epoch:    3/10    Loss: 3.918274953365326\n",
      "\n",
      "Epoch:    3/10    Loss: 4.079476525783539\n",
      "\n",
      "Epoch:    3/10    Loss: 3.9603354144096374\n",
      "\n",
      "Epoch:    3/10    Loss: 4.457942774295807\n",
      "\n",
      "Epoch:    3/10    Loss: 3.679597373008728\n",
      "\n",
      "Epoch:    3/10    Loss: 3.575398519039154\n",
      "\n",
      "Epoch:    3/10    Loss: 3.949296779632568\n",
      "\n",
      "Epoch:    3/10    Loss: 4.043136367797851\n",
      "\n",
      "Epoch:    3/10    Loss: 4.130548532009125\n",
      "\n",
      "Epoch:    3/10    Loss: 4.20108068227768\n",
      "\n",
      "Epoch:    3/10    Loss: 4.141942517757416\n",
      "\n",
      "Epoch:    3/10    Loss: 4.045255389213562\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8462651491165163\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6783374869823455\n",
      "\n",
      "Epoch:    3/10    Loss: 4.121699290275574\n",
      "\n",
      "Epoch:    3/10    Loss: 3.973252239227295\n",
      "\n",
      "Epoch:    3/10    Loss: 4.030316715240478\n",
      "\n",
      "Epoch:    3/10    Loss: 3.935937740802765\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8759797048568725\n",
      "\n",
      "Epoch:    3/10    Loss: 4.055005962848663\n",
      "\n",
      "Epoch:    3/10    Loss: 3.851892213821411\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7600566363334655\n",
      "\n",
      "Epoch:    3/10    Loss: 4.119924138784409\n",
      "\n",
      "Epoch:    3/10    Loss: 4.133319046497345\n",
      "\n",
      "Epoch:    3/10    Loss: 3.858729317188263\n",
      "\n",
      "Epoch:    3/10    Loss: 3.996446406841278\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5349529814720153\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8091039764881134\n",
      "\n",
      "Epoch:    3/10    Loss: 3.9331929159164427\n",
      "\n",
      "Epoch:    3/10    Loss: 4.166516876220703\n",
      "\n",
      "Epoch:    3/10    Loss: 3.847173833847046\n",
      "\n",
      "Epoch:    3/10    Loss: 4.03488055229187\n",
      "\n",
      "Epoch:    3/10    Loss: 3.858065221309662\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7566224002838133\n",
      "\n",
      "Epoch:    3/10    Loss: 3.854690680503845\n",
      "\n",
      "Epoch:    3/10    Loss: 4.062688348293304\n",
      "\n",
      "Epoch:    3/10    Loss: 4.005519950389862\n",
      "\n",
      "Epoch:    3/10    Loss: 4.242353758811951\n",
      "\n",
      "Epoch:    3/10    Loss: 4.083490719795227\n",
      "\n",
      "Epoch:    3/10    Loss: 4.092858017683029\n",
      "\n",
      "Epoch:    3/10    Loss: 4.1256845092773435\n",
      "\n",
      "Epoch:    3/10    Loss: 3.9703570437431335\n",
      "\n",
      "Epoch:    3/10    Loss: 3.737046117782593\n",
      "\n",
      "Epoch:    3/10    Loss: 4.016608357429504\n",
      "\n",
      "Epoch:    3/10    Loss: 4.0886787664890285\n",
      "\n",
      "Epoch:    3/10    Loss: 3.9777733492851257\n",
      "\n",
      "Epoch:    3/10    Loss: 4.297493393421173\n",
      "\n",
      "Epoch:    3/10    Loss: 4.072557165622711\n",
      "\n",
      "Epoch:    3/10    Loss: 4.030105001926422\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8860207390785217\n",
      "\n",
      "Epoch:    3/10    Loss: 4.010658500194549\n",
      "\n",
      "Epoch:    3/10    Loss: 4.358897521495819\n",
      "\n",
      "Epoch:    3/10    Loss: 4.354953811168671\n",
      "\n",
      "Epoch:    3/10    Loss: 4.099219346046448\n",
      "\n",
      "Epoch:    3/10    Loss: 4.2256313943862915\n",
      "\n",
      "Epoch:    3/10    Loss: 4.274867298603058\n",
      "\n",
      "Epoch:    3/10    Loss: 4.280725219249725\n",
      "\n",
      "Epoch:    3/10    Loss: 4.271882895231247\n",
      "\n",
      "Epoch:    3/10    Loss: 4.346589934825897\n",
      "\n",
      "Epoch:    3/10    Loss: 4.128960609436035\n",
      "\n",
      "Epoch:    3/10    Loss: 4.141806564331055\n",
      "\n",
      "Epoch:    3/10    Loss: 4.0465612840652465\n",
      "\n",
      "Epoch:    3/10    Loss: 4.095899224281311\n",
      "\n",
      "Epoch:    3/10    Loss: 4.129601418972015\n",
      "\n",
      "Epoch:    3/10    Loss: 4.257612373828888\n",
      "\n",
      "Epoch:    3/10    Loss: 4.176218934059143\n",
      "\n",
      "Epoch:    3/10    Loss: 3.971526906490326\n",
      "\n",
      "Epoch:    3/10    Loss: 4.331660447120666\n",
      "\n",
      "Epoch:    3/10    Loss: 4.156190586090088\n",
      "\n",
      "Epoch:    3/10    Loss: 3.9516689443588255\n",
      "\n",
      "Epoch:    3/10    Loss: 4.221638827323914\n",
      "\n",
      "Epoch:    3/10    Loss: 4.229029169082642\n",
      "\n",
      "Epoch:    3/10    Loss: 4.082856607437134\n",
      "\n",
      "Epoch:    3/10    Loss: 4.305484800338745\n",
      "\n",
      "Epoch:    3/10    Loss: 4.05041289806366\n",
      "\n",
      "Epoch:    3/10    Loss: 4.39920583486557\n",
      "\n",
      "Epoch:    3/10    Loss: 4.140676162242889\n",
      "\n",
      "Epoch:    3/10    Loss: 4.112861115932464\n",
      "\n",
      "Epoch:    3/10    Loss: 4.014016554355622\n",
      "\n",
      "Epoch:    3/10    Loss: 4.275579342842102\n",
      "\n",
      "Epoch:    3/10    Loss: 4.173456318378449\n",
      "\n",
      "Epoch:    3/10    Loss: 4.159993641376495\n",
      "\n",
      "Epoch:    3/10    Loss: 4.097313277721405\n",
      "\n",
      "Epoch:    3/10    Loss: 4.0573360228538515\n",
      "\n",
      "Epoch:    3/10    Loss: 3.974065616130829\n",
      "\n",
      "Epoch:    3/10    Loss: 4.318732812404632\n",
      "\n",
      "Epoch:    3/10    Loss: 4.472170715332031\n",
      "\n",
      "Epoch:    3/10    Loss: 4.080761559009552\n",
      "\n",
      "Epoch:    3/10    Loss: 4.05901002407074\n",
      "\n",
      "Epoch:    3/10    Loss: 4.083603987693786\n",
      "\n",
      "Epoch:    3/10    Loss: 3.9757561755180357\n",
      "\n",
      "Epoch:    3/10    Loss: 4.379402453899384\n",
      "\n",
      "Epoch:    3/10    Loss: 4.174786422252655\n",
      "\n",
      "Epoch:    3/10    Loss: 4.111175348758698\n",
      "\n",
      "Epoch:    3/10    Loss: 4.239003763198853\n",
      "\n",
      "Epoch:    3/10    Loss: 4.344072794914245\n",
      "\n",
      "Epoch:    3/10    Loss: 4.144983730316162\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8499828505516054\n",
      "\n",
      "Epoch:    3/10    Loss: 4.1234246706962585\n",
      "\n",
      "Epoch:    3/10    Loss: 4.125645701885223\n",
      "\n",
      "Epoch:    3/10    Loss: 3.9416265082359314\n",
      "\n",
      "Epoch:    3/10    Loss: 3.890092556476593\n",
      "\n",
      "Epoch:    3/10    Loss: 4.050688433647156\n",
      "\n",
      "Epoch:    3/10    Loss: 4.359864206314087\n",
      "\n",
      "Epoch:    3/10    Loss: 4.243910543918609\n",
      "\n",
      "Epoch:    3/10    Loss: 4.186305365562439\n",
      "\n",
      "Epoch:    3/10    Loss: 4.1228090977668765\n",
      "\n",
      "Epoch:    3/10    Loss: 4.003411374092102\n",
      "\n",
      "Epoch:    3/10    Loss: 3.829916231632233\n",
      "\n",
      "Epoch:    3/10    Loss: 4.070791577100754\n",
      "\n",
      "Epoch:    3/10    Loss: 3.956967159509659\n",
      "\n",
      "Epoch:    3/10    Loss: 4.000886631011963\n",
      "\n",
      "Epoch:    3/10    Loss: 4.9563030242919925\n",
      "\n",
      "Epoch:    4/10    Loss: 4.337629757570417\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9683251905441286\n",
      "\n",
      "Epoch:    4/10    Loss: 3.7262020468711854\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9486214256286623\n",
      "\n",
      "Epoch:    4/10    Loss: 3.675743522644043\n",
      "\n",
      "Epoch:    4/10    Loss: 3.7320179414749144\n",
      "\n",
      "Epoch:    4/10    Loss: 3.905260784626007\n",
      "\n",
      "Epoch:    4/10    Loss: 3.8457115030288698\n",
      "\n",
      "Epoch:    4/10    Loss: 3.921933913230896\n",
      "\n",
      "Epoch:    4/10    Loss: 3.7317303216457365\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9948902535438537\n",
      "\n",
      "Epoch:    4/10    Loss: 3.8735098564624786\n",
      "\n",
      "Epoch:    4/10    Loss: 3.972340794801712\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6467819452285766\n",
      "\n",
      "Epoch:    4/10    Loss: 3.883981263637543\n",
      "\n",
      "Epoch:    4/10    Loss: 3.938442140817642\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6961428725719454\n",
      "\n",
      "Epoch:    4/10    Loss: 4.035997586250305\n",
      "\n",
      "Epoch:    4/10    Loss: 3.909747612476349\n",
      "\n",
      "Epoch:    4/10    Loss: 4.0557684898376465\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6963739442825316\n",
      "\n",
      "Epoch:    4/10    Loss: 3.84732843875885\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9931496524810792\n",
      "\n",
      "Epoch:    4/10    Loss: 3.857877027988434\n",
      "\n",
      "Epoch:    4/10    Loss: 3.8685003519058228\n",
      "\n",
      "Epoch:    4/10    Loss: 4.218211410045623\n",
      "\n",
      "Epoch:    4/10    Loss: 3.7531399440765383\n",
      "\n",
      "Epoch:    4/10    Loss: 4.121946241855621\n",
      "\n",
      "Epoch:    4/10    Loss: 3.920118176937103\n",
      "\n",
      "Epoch:    4/10    Loss: 3.611718602180481\n",
      "\n",
      "Epoch:    4/10    Loss: 4.066301012039185\n",
      "\n",
      "Epoch:    4/10    Loss: 3.7728647112846376\n",
      "\n",
      "Epoch:    4/10    Loss: 4.3834561514854435\n",
      "\n",
      "Epoch:    4/10    Loss: 4.117214725017548\n",
      "\n",
      "Epoch:    4/10    Loss: 3.781077148914337\n",
      "\n",
      "Epoch:    4/10    Loss: 3.7324851679801943\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6796060955524443\n",
      "\n",
      "Epoch:    4/10    Loss: 3.673208727836609\n",
      "\n",
      "Epoch:    4/10    Loss: 3.7773211288452146\n",
      "\n",
      "Epoch:    4/10    Loss: 3.8504015707969668\n",
      "\n",
      "Epoch:    4/10    Loss: 3.625817606449127\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6937411761283876\n",
      "\n",
      "Epoch:    4/10    Loss: 3.946383326053619\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9251660907268526\n",
      "\n",
      "Epoch:    4/10    Loss: 4.382715184688568\n",
      "\n",
      "Epoch:    4/10    Loss: 3.976364676952362\n",
      "\n",
      "Epoch:    4/10    Loss: 3.8640793228149413\n",
      "\n",
      "Epoch:    4/10    Loss: 3.990389716625214\n",
      "\n",
      "Epoch:    4/10    Loss: 3.5476478791236876\n",
      "\n",
      "Epoch:    4/10    Loss: 3.8712383484840394\n",
      "\n",
      "Epoch:    4/10    Loss: 3.907440481185913\n",
      "\n",
      "Epoch:    4/10    Loss: 3.8730592370033263\n",
      "\n",
      "Epoch:    4/10    Loss: 4.031111482381821\n",
      "\n",
      "Epoch:    4/10    Loss: 3.921975495815277\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9084624671936035\n",
      "\n",
      "Epoch:    4/10    Loss: 3.8361444091796875\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6293386745452882\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6111116456985473\n",
      "\n",
      "Epoch:    4/10    Loss: 3.549364993572235\n",
      "\n",
      "Epoch:    4/10    Loss: 3.72150283575058\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9870569586753843\n",
      "\n",
      "Epoch:    4/10    Loss: 3.987904827594757\n",
      "\n",
      "Epoch:    4/10    Loss: 3.8875452852249146\n",
      "\n",
      "Epoch:    4/10    Loss: 3.590030362606049\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6774744415283203\n",
      "\n",
      "Epoch:    4/10    Loss: 3.800975534915924\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6215573525428773\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9351123666763304\n",
      "\n",
      "Epoch:    4/10    Loss: 3.575100846290588\n",
      "\n",
      "Epoch:    4/10    Loss: 3.692703170776367\n",
      "\n",
      "Epoch:    4/10    Loss: 3.7766655778884886\n",
      "\n",
      "Epoch:    4/10    Loss: 3.8435186886787416\n",
      "\n",
      "Epoch:    4/10    Loss: 3.762347538471222\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9462758827209474\n",
      "\n",
      "Epoch:    4/10    Loss: 3.8861922359466554\n",
      "\n",
      "Epoch:    4/10    Loss: 3.7112433910369873\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9862149024009703\n",
      "\n",
      "Epoch:    4/10    Loss: 3.630764961242676\n",
      "\n",
      "Epoch:    4/10    Loss: 3.718138632774353\n",
      "\n",
      "Epoch:    4/10    Loss: 4.272431554794312\n",
      "\n",
      "Epoch:    4/10    Loss: 3.7590067100524904\n",
      "\n",
      "Epoch:    4/10    Loss: 4.436840918064117\n",
      "\n",
      "Epoch:    4/10    Loss: 4.184879970550537\n",
      "\n",
      "Epoch:    4/10    Loss: 3.8233635568618776\n",
      "\n",
      "Epoch:    4/10    Loss: 3.781318964958191\n",
      "\n",
      "Epoch:    4/10    Loss: 3.826398861408234\n",
      "\n",
      "Epoch:    4/10    Loss: 4.078034541606903\n",
      "\n",
      "Epoch:    4/10    Loss: 4.21036601305008\n",
      "\n",
      "Epoch:    4/10    Loss: 4.088994805812836\n",
      "\n",
      "Epoch:    4/10    Loss: 3.755687110424042\n",
      "\n",
      "Epoch:    4/10    Loss: 4.070899198055267\n",
      "\n",
      "Epoch:    4/10    Loss: 3.887309775352478\n",
      "\n",
      "Epoch:    4/10    Loss: 4.028646981716156\n",
      "\n",
      "Epoch:    4/10    Loss: 3.7876631569862367\n",
      "\n",
      "Epoch:    4/10    Loss: 3.878551461696625\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9091367745399475\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9115816140174866\n",
      "\n",
      "Epoch:    4/10    Loss: 4.077415945529938\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6927962839603423\n",
      "\n",
      "Epoch:    4/10    Loss: 3.751127054691315\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9658371758461\n",
      "\n",
      "Epoch:    4/10    Loss: 3.774951597452164\n",
      "\n",
      "Epoch:    4/10    Loss: 3.7974198770523073\n",
      "\n",
      "Epoch:    4/10    Loss: 3.851935750246048\n",
      "\n",
      "Epoch:    4/10    Loss: 4.211282002925873\n",
      "\n",
      "Epoch:    4/10    Loss: 4.330345675945282\n",
      "\n",
      "Epoch:    4/10    Loss: 4.122014164924622\n",
      "\n",
      "Epoch:    4/10    Loss: 3.816415469646454\n",
      "\n",
      "Epoch:    4/10    Loss: 3.7495788311958314\n",
      "\n",
      "Epoch:    4/10    Loss: 4.052517400979996\n",
      "\n",
      "Epoch:    4/10    Loss: 4.042582525014877\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9643384194374085\n",
      "\n",
      "Epoch:    4/10    Loss: 3.8784763526916506\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9778499245643615\n",
      "\n",
      "Epoch:    4/10    Loss: 4.183418803215027\n",
      "\n",
      "Epoch:    4/10    Loss: 4.093779977560043\n",
      "\n",
      "Epoch:    4/10    Loss: 4.0868311834335325\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9283687925338744\n",
      "\n",
      "Epoch:    4/10    Loss: 4.209281127452851\n",
      "\n",
      "Epoch:    4/10    Loss: 4.2342826676368714\n",
      "\n",
      "Epoch:    4/10    Loss: 4.161134009361267\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9680569553375244\n",
      "\n",
      "Epoch:    4/10    Loss: 4.1515648078918455\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9705247259140015\n",
      "\n",
      "Epoch:    4/10    Loss: 3.879249985218048\n",
      "\n",
      "Epoch:    4/10    Loss: 3.692317292690277\n",
      "\n",
      "Epoch:    4/10    Loss: 4.089639155864716\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9940656542778017\n",
      "\n",
      "Epoch:    4/10    Loss: 4.001873378753662\n",
      "\n",
      "Epoch:    4/10    Loss: 4.104434964656829\n",
      "\n",
      "Epoch:    4/10    Loss: 4.201171061992645\n",
      "\n",
      "Epoch:    4/10    Loss: 3.82148681640625\n",
      "\n",
      "Epoch:    4/10    Loss: 4.021476686000824\n",
      "\n",
      "Epoch:    4/10    Loss: 3.948139684200287\n",
      "\n",
      "Epoch:    4/10    Loss: 4.091025929450989\n",
      "\n",
      "Epoch:    4/10    Loss: 3.941162552833557\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9123466086387633\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9896552181243896\n",
      "\n",
      "Epoch:    4/10    Loss: 3.943501217365265\n",
      "\n",
      "Epoch:    4/10    Loss: 3.8228649878501892\n",
      "\n",
      "Epoch:    4/10    Loss: 3.779893493652344\n",
      "\n",
      "Epoch:    4/10    Loss: 3.763580946922302\n",
      "\n",
      "Epoch:    4/10    Loss: 3.984202620983124\n",
      "\n",
      "Epoch:    4/10    Loss: 4.066686673164368\n",
      "\n",
      "Epoch:    4/10    Loss: 3.7576198291778566\n",
      "\n",
      "Epoch:    4/10    Loss: 4.142527823448181\n",
      "\n",
      "Epoch:    4/10    Loss: 3.838421156406403\n",
      "\n",
      "Epoch:    4/10    Loss: 4.26309949874878\n",
      "\n",
      "Epoch:    4/10    Loss: 3.8525505018234254\n",
      "\n",
      "Epoch:    4/10    Loss: 4.234632821083069\n",
      "\n",
      "Epoch:    4/10    Loss: 4.332638182640076\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9827004504203796\n",
      "\n",
      "Epoch:    4/10    Loss: 3.8070413208007814\n",
      "\n",
      "Epoch:    4/10    Loss: 3.767799731492996\n",
      "\n",
      "Epoch:    4/10    Loss: 3.760028771162033\n",
      "\n",
      "Epoch:    4/10    Loss: 3.775769200325012\n",
      "\n",
      "Epoch:    4/10    Loss: 3.8832235145568847\n",
      "\n",
      "Epoch:    4/10    Loss: 3.5479448890686034\n",
      "\n",
      "Epoch:    4/10    Loss: 3.749567484855652\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6753323900699617\n",
      "\n",
      "Epoch:    4/10    Loss: 3.8501821541786194\n",
      "\n",
      "Epoch:    4/10    Loss: 3.650230259895325\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6932950401306153\n",
      "\n",
      "Epoch:    4/10    Loss: 4.0490074837207795\n",
      "\n",
      "Epoch:    4/10    Loss: 3.683424718379974\n",
      "\n",
      "Epoch:    4/10    Loss: 3.8624682140350344\n",
      "\n",
      "Epoch:    4/10    Loss: 4.013436012268066\n",
      "\n",
      "Epoch:    4/10    Loss: 3.879555344581604\n",
      "\n",
      "Epoch:    4/10    Loss: 4.380639958381653\n",
      "\n",
      "Epoch:    4/10    Loss: 3.5703617620468138\n",
      "\n",
      "Epoch:    4/10    Loss: 3.5202932238578795\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9044092750549315\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9337406384944917\n",
      "\n",
      "Epoch:    4/10    Loss: 4.0605609679222106\n",
      "\n",
      "Epoch:    4/10    Loss: 4.172117683887482\n",
      "\n",
      "Epoch:    4/10    Loss: 4.109265642166138\n",
      "\n",
      "Epoch:    4/10    Loss: 3.985458824634552\n",
      "\n",
      "Epoch:    4/10    Loss: 3.8249079751968384\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6477575874328614\n",
      "\n",
      "Epoch:    4/10    Loss: 4.075621342658996\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9422572922706602\n",
      "\n",
      "Epoch:    4/10    Loss: 3.978687915802002\n",
      "\n",
      "Epoch:    4/10    Loss: 3.8745133209228517\n",
      "\n",
      "Epoch:    4/10    Loss: 3.7795301604270937\n",
      "\n",
      "Epoch:    4/10    Loss: 3.952942473888397\n",
      "\n",
      "Epoch:    4/10    Loss: 3.7864817142486573\n",
      "\n",
      "Epoch:    4/10    Loss: 3.696451659202576\n",
      "\n",
      "Epoch:    4/10    Loss: 4.023158023357391\n",
      "\n",
      "Epoch:    4/10    Loss: 4.065698306560517\n",
      "\n",
      "Epoch:    4/10    Loss: 3.8097338008880617\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9495026516914367\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4444849395751955\n",
      "\n",
      "Epoch:    4/10    Loss: 3.750485154390335\n",
      "\n",
      "Epoch:    4/10    Loss: 3.8690166211128236\n",
      "\n",
      "Epoch:    4/10    Loss: 4.073065197467804\n",
      "\n",
      "Epoch:    4/10    Loss: 3.8057855558395386\n",
      "\n",
      "Epoch:    4/10    Loss: 3.98355881690979\n",
      "\n",
      "Epoch:    4/10    Loss: 3.805969204902649\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6959989285469055\n",
      "\n",
      "Epoch:    4/10    Loss: 3.8335094952583315\n",
      "\n",
      "Epoch:    4/10    Loss: 4.011227705478668\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9620867013931274\n",
      "\n",
      "Epoch:    4/10    Loss: 4.1965863180160525\n",
      "\n",
      "Epoch:    4/10    Loss: 4.040948355197907\n",
      "\n",
      "Epoch:    4/10    Loss: 4.033024009466171\n",
      "\n",
      "Epoch:    4/10    Loss: 4.080499367713928\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9245841264724732\n",
      "\n",
      "Epoch:    4/10    Loss: 3.697990870475769\n",
      "\n",
      "Epoch:    4/10    Loss: 3.966833481788635\n",
      "\n",
      "Epoch:    4/10    Loss: 4.021264455318451\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9364958786964417\n",
      "\n",
      "Epoch:    4/10    Loss: 4.26002269744873\n",
      "\n",
      "Epoch:    4/10    Loss: 4.008531792163849\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9700435471534727\n",
      "\n",
      "Epoch:    4/10    Loss: 3.810592460632324\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9311869072914125\n",
      "\n",
      "Epoch:    4/10    Loss: 4.2780836391448975\n",
      "\n",
      "Epoch:    4/10    Loss: 4.321847984790802\n",
      "\n",
      "Epoch:    4/10    Loss: 4.051270837783814\n",
      "\n",
      "Epoch:    4/10    Loss: 4.181861665248871\n",
      "\n",
      "Epoch:    4/10    Loss: 4.2531751036643985\n",
      "\n",
      "Epoch:    4/10    Loss: 4.24918963432312\n",
      "\n",
      "Epoch:    4/10    Loss: 4.212191300392151\n",
      "\n",
      "Epoch:    4/10    Loss: 4.298310248851776\n",
      "\n",
      "Epoch:    4/10    Loss: 4.038080337047577\n",
      "\n",
      "Epoch:    4/10    Loss: 4.088221089839935\n",
      "\n",
      "Epoch:    4/10    Loss: 3.987656338214874\n",
      "\n",
      "Epoch:    4/10    Loss: 4.023186194896698\n",
      "\n",
      "Epoch:    4/10    Loss: 4.0605840229988095\n",
      "\n",
      "Epoch:    4/10    Loss: 4.198440840244293\n",
      "\n",
      "Epoch:    4/10    Loss: 4.13005053281784\n",
      "\n",
      "Epoch:    4/10    Loss: 3.91060706615448\n",
      "\n",
      "Epoch:    4/10    Loss: 4.262211520671844\n",
      "\n",
      "Epoch:    4/10    Loss: 4.1168196630477905\n",
      "\n",
      "Epoch:    4/10    Loss: 3.8801744055747984\n",
      "\n",
      "Epoch:    4/10    Loss: 4.16180358171463\n",
      "\n",
      "Epoch:    4/10    Loss: 4.138087902069092\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9846654391288756\n",
      "\n",
      "Epoch:    4/10    Loss: 4.2394029712677\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9861570739746095\n",
      "\n",
      "Epoch:    4/10    Loss: 4.346625754833221\n",
      "\n",
      "Epoch:    4/10    Loss: 4.087562193870545\n",
      "\n",
      "Epoch:    4/10    Loss: 4.060176846981048\n",
      "\n",
      "Epoch:    4/10    Loss: 3.938807907104492\n",
      "\n",
      "Epoch:    4/10    Loss: 4.230975384712219\n",
      "\n",
      "Epoch:    4/10    Loss: 4.076976064443588\n",
      "\n",
      "Epoch:    4/10    Loss: 4.129527137279511\n",
      "\n",
      "Epoch:    4/10    Loss: 4.0519224905967715\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9842037749290466\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9239727377891542\n",
      "\n",
      "Epoch:    4/10    Loss: 4.247405982017517\n",
      "\n",
      "Epoch:    4/10    Loss: 4.425836043357849\n",
      "\n",
      "Epoch:    4/10    Loss: 4.041556127071381\n",
      "\n",
      "Epoch:    4/10    Loss: 4.000946419239044\n",
      "\n",
      "Epoch:    4/10    Loss: 3.985139055252075\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9075492548942568\n",
      "\n",
      "Epoch:    4/10    Loss: 4.3438835000991824\n",
      "\n",
      "Epoch:    4/10    Loss: 4.1006091737747195\n",
      "\n",
      "Epoch:    4/10    Loss: 4.050074450969696\n",
      "\n",
      "Epoch:    4/10    Loss: 4.169534738063812\n",
      "\n",
      "Epoch:    4/10    Loss: 4.269392766952515\n",
      "\n",
      "Epoch:    4/10    Loss: 4.099042363166809\n",
      "\n",
      "Epoch:    4/10    Loss: 3.7944078469276428\n",
      "\n",
      "Epoch:    4/10    Loss: 4.074930917024613\n",
      "\n",
      "Epoch:    4/10    Loss: 4.067772238254547\n",
      "\n",
      "Epoch:    4/10    Loss: 3.911445574760437\n",
      "\n",
      "Epoch:    4/10    Loss: 3.860528998374939\n",
      "\n",
      "Epoch:    4/10    Loss: 4.020881471633911\n",
      "\n",
      "Epoch:    4/10    Loss: 4.2830879545211795\n",
      "\n",
      "Epoch:    4/10    Loss: 4.200206444263459\n",
      "\n",
      "Epoch:    4/10    Loss: 4.147198269367218\n",
      "\n",
      "Epoch:    4/10    Loss: 4.087486367225647\n",
      "\n",
      "Epoch:    4/10    Loss: 3.927294120788574\n",
      "\n",
      "Epoch:    4/10    Loss: 3.796436252593994\n",
      "\n",
      "Epoch:    4/10    Loss: 4.014685969352723\n",
      "\n",
      "Epoch:    4/10    Loss: 3.93006432056427\n",
      "\n",
      "Epoch:    4/10    Loss: 3.974164445400238\n",
      "\n",
      "Epoch:    4/10    Loss: 4.87109929561615\n",
      "\n",
      "Epoch:    5/10    Loss: 4.2646675458115135\n",
      "\n",
      "Epoch:    5/10    Loss: 3.8999316811561586\n",
      "\n",
      "Epoch:    5/10    Loss: 3.609546649456024\n",
      "\n",
      "Epoch:    5/10    Loss: 3.8525666046142577\n",
      "\n",
      "Epoch:    5/10    Loss: 3.6267758917808535\n",
      "\n",
      "Epoch:    5/10    Loss: 3.6499426770210266\n",
      "\n",
      "Epoch:    5/10    Loss: 3.858155093193054\n",
      "\n",
      "Epoch:    5/10    Loss: 3.772003149986267\n",
      "\n",
      "Epoch:    5/10    Loss: 3.883925359249115\n",
      "\n",
      "Epoch:    5/10    Loss: 3.6797164034843446\n",
      "\n",
      "Epoch:    5/10    Loss: 3.9512742733955384\n",
      "\n",
      "Epoch:    5/10    Loss: 3.827568187713623\n",
      "\n",
      "Epoch:    5/10    Loss: 3.9004581475257876\n",
      "\n",
      "Epoch:    5/10    Loss: 3.588235385417938\n",
      "\n",
      "Epoch:    5/10    Loss: 3.8732954406738282\n",
      "\n",
      "Epoch:    5/10    Loss: 3.899370186328888\n",
      "\n",
      "Epoch:    5/10    Loss: 3.6777724909782408\n",
      "\n",
      "Epoch:    5/10    Loss: 3.998155167102814\n",
      "\n",
      "Epoch:    5/10    Loss: 3.859928150177002\n",
      "\n",
      "Epoch:    5/10    Loss: 3.99578693151474\n",
      "\n",
      "Epoch:    5/10    Loss: 3.638392491340637\n",
      "\n",
      "Epoch:    5/10    Loss: 3.8165508198738096\n",
      "\n",
      "Epoch:    5/10    Loss: 3.951053671836853\n",
      "\n",
      "Epoch:    5/10    Loss: 3.8316475343704224\n",
      "\n",
      "Epoch:    5/10    Loss: 3.831145625114441\n",
      "\n",
      "Epoch:    5/10    Loss: 4.164325165748596\n",
      "\n",
      "Epoch:    5/10    Loss: 3.7322527050971983\n",
      "\n",
      "Epoch:    5/10    Loss: 4.078028080463409\n",
      "\n",
      "Epoch:    5/10    Loss: 3.8731899762153628\n",
      "\n",
      "Epoch:    5/10    Loss: 3.56606290102005\n",
      "\n",
      "Epoch:    5/10    Loss: 4.053980910778046\n",
      "\n",
      "Epoch:    5/10    Loss: 3.737538321018219\n",
      "\n",
      "Epoch:    5/10    Loss: 4.340529968738556\n",
      "\n",
      "Epoch:    5/10    Loss: 4.0762295794487\n",
      "\n",
      "Epoch:    5/10    Loss: 3.7054087591171263\n",
      "\n",
      "Epoch:    5/10    Loss: 3.7430744862556455\n",
      "\n",
      "Epoch:    5/10    Loss: 3.647574533224106\n",
      "\n",
      "Epoch:    5/10    Loss: 3.658833248615265\n",
      "\n",
      "Epoch:    5/10    Loss: 3.7644151496887206\n",
      "\n",
      "Epoch:    5/10    Loss: 3.8213535273075103\n",
      "\n",
      "Epoch:    5/10    Loss: 3.583951930999756\n",
      "\n",
      "Epoch:    5/10    Loss: 3.628810052871704\n",
      "\n",
      "Epoch:    5/10    Loss: 3.9071040391921996\n",
      "\n",
      "Epoch:    5/10    Loss: 3.8749876832962036\n",
      "\n",
      "Epoch:    5/10    Loss: 4.337634665966034\n",
      "\n",
      "Epoch:    5/10    Loss: 3.933100504875183\n",
      "\n",
      "Epoch:    5/10    Loss: 3.8534430384635927\n",
      "\n",
      "Epoch:    5/10    Loss: 3.975033440589905\n",
      "\n",
      "Epoch:    5/10    Loss: 3.5003922140598296\n",
      "\n",
      "Epoch:    5/10    Loss: 3.807630407810211\n",
      "\n",
      "Epoch:    5/10    Loss: 3.8732625341415403\n",
      "\n",
      "Epoch:    5/10    Loss: 3.8382808566093445\n",
      "\n",
      "Epoch:    5/10    Loss: 4.006441283226013\n",
      "\n",
      "Epoch:    5/10    Loss: 3.8989101386070253\n",
      "\n",
      "Epoch:    5/10    Loss: 3.8647754192352295\n",
      "\n",
      "Epoch:    5/10    Loss: 3.8223290729522703\n",
      "\n",
      "Epoch:    5/10    Loss: 3.621119947433472\n",
      "\n",
      "Epoch:    5/10    Loss: 3.5736356353759766\n",
      "\n",
      "Epoch:    5/10    Loss: 3.5180612528324127\n",
      "\n",
      "Epoch:    5/10    Loss: 3.6886211037635803\n",
      "\n",
      "Epoch:    5/10    Loss: 3.9458123588562013\n",
      "\n",
      "Epoch:    5/10    Loss: 3.9057876873016357\n",
      "\n",
      "Epoch:    5/10    Loss: 3.8722842633724213\n",
      "\n",
      "Epoch:    5/10    Loss: 3.554353370666504\n",
      "\n",
      "Epoch:    5/10    Loss: 3.651019732952118\n",
      "\n",
      "Epoch:    5/10    Loss: 3.7840547585487365\n",
      "\n",
      "Epoch:    5/10    Loss: 3.6171081256866455\n",
      "\n",
      "Epoch:    5/10    Loss: 3.897326463460922\n",
      "\n",
      "Epoch:    5/10    Loss: 3.5618438029289248\n",
      "\n",
      "Epoch:    5/10    Loss: 3.6831723928451536\n",
      "\n",
      "Epoch:    5/10    Loss: 3.7268911719322206\n",
      "\n",
      "Epoch:    5/10    Loss: 3.7984159445762633\n",
      "\n",
      "Epoch:    5/10    Loss: 3.7079732930660247\n",
      "\n",
      "Epoch:    5/10    Loss: 3.9017430078983306\n",
      "\n",
      "Epoch:    5/10    Loss: 3.8319907855987547\n",
      "\n",
      "Epoch:    5/10    Loss: 3.6555063343048095\n",
      "\n",
      "Epoch:    5/10    Loss: 3.8880282258987426\n",
      "\n",
      "Epoch:    5/10    Loss: 3.604240915775299\n",
      "\n",
      "Epoch:    5/10    Loss: 3.663637797832489\n",
      "\n",
      "Epoch:    5/10    Loss: 4.225170471668243\n",
      "\n",
      "Epoch:    5/10    Loss: 3.7157434535026552\n",
      "\n",
      "Epoch:    5/10    Loss: 4.383515527248383\n",
      "\n",
      "Epoch:    5/10    Loss: 4.153788042068482\n",
      "\n",
      "Epoch:    5/10    Loss: 3.8090108823776245\n",
      "\n",
      "Epoch:    5/10    Loss: 3.7313443493843077\n",
      "\n",
      "Epoch:    5/10    Loss: 3.7843075013160705\n",
      "\n",
      "Epoch:    5/10    Loss: 3.994575572013855\n",
      "\n",
      "Epoch:    5/10    Loss: 4.140623462200165\n",
      "\n",
      "Epoch:    5/10    Loss: 4.005039029121399\n",
      "\n",
      "Epoch:    5/10    Loss: 3.718676145076752\n",
      "\n",
      "Epoch:    5/10    Loss: 4.006860511302948\n",
      "\n",
      "Epoch:    5/10    Loss: 3.845858156681061\n",
      "\n",
      "Epoch:    5/10    Loss: 3.9779705286026\n",
      "\n",
      "Epoch:    5/10    Loss: 3.737469942569733\n",
      "\n",
      "Epoch:    5/10    Loss: 3.8343461298942567\n",
      "\n",
      "Epoch:    5/10    Loss: 3.8415294313430786\n",
      "\n",
      "Epoch:    5/10    Loss: 3.870131869316101\n",
      "\n",
      "Epoch:    5/10    Loss: 4.036090605258941\n",
      "\n",
      "Epoch:    5/10    Loss: 3.678997633457184\n",
      "\n",
      "Epoch:    5/10    Loss: 3.6847178530693054\n",
      "\n",
      "Epoch:    5/10    Loss: 3.958614454269409\n",
      "\n",
      "Epoch:    5/10    Loss: 3.7180565464496613\n",
      "\n",
      "Epoch:    5/10    Loss: 3.769777500629425\n",
      "\n",
      "Epoch:    5/10    Loss: 3.7818390202522276\n",
      "\n",
      "Epoch:    5/10    Loss: 4.162312324047089\n",
      "\n",
      "Epoch:    5/10    Loss: 4.3046413207054135\n",
      "\n",
      "Epoch:    5/10    Loss: 4.0789381277561185\n",
      "\n",
      "Epoch:    5/10    Loss: 3.7822559690475464\n",
      "\n",
      "Epoch:    5/10    Loss: 3.7049576926231382\n",
      "\n",
      "Epoch:    5/10    Loss: 4.032254643440247\n",
      "\n",
      "Epoch:    5/10    Loss: 3.994135110378265\n",
      "\n",
      "Epoch:    5/10    Loss: 3.9367569518089294\n",
      "\n",
      "Epoch:    5/10    Loss: 3.8409464621543883\n",
      "\n",
      "Epoch:    5/10    Loss: 3.9249087154865263\n",
      "\n",
      "Epoch:    5/10    Loss: 4.104282331466675\n",
      "\n",
      "Epoch:    5/10    Loss: 4.052598637342453\n",
      "\n",
      "Epoch:    5/10    Loss: 4.064201312065125\n",
      "\n",
      "Epoch:    5/10    Loss: 3.8903028082847597\n",
      "\n",
      "Epoch:    5/10    Loss: 4.197090644836425\n",
      "\n",
      "Epoch:    5/10    Loss: 4.193753473758697\n",
      "\n",
      "Epoch:    5/10    Loss: 4.123707582950592\n",
      "\n",
      "Epoch:    5/10    Loss: 3.9424391841888426\n",
      "\n",
      "Epoch:    5/10    Loss: 4.1460549974441525\n",
      "\n",
      "Epoch:    5/10    Loss: 3.964473547935486\n",
      "\n",
      "Epoch:    5/10    Loss: 3.8733140516281126\n",
      "\n",
      "Epoch:    5/10    Loss: 3.660840718746185\n",
      "\n",
      "Epoch:    5/10    Loss: 4.009112033843994\n",
      "\n",
      "Epoch:    5/10    Loss: 3.961781702041626\n",
      "\n",
      "Epoch:    5/10    Loss: 3.9263424146175385\n",
      "\n",
      "Epoch:    5/10    Loss: 4.04354325056076\n",
      "\n",
      "Epoch:    5/10    Loss: 4.139349935054779\n",
      "\n",
      "Epoch:    5/10    Loss: 3.7918100810050963\n",
      "\n",
      "Epoch:    5/10    Loss: 3.962356653213501\n",
      "\n",
      "Epoch:    5/10    Loss: 3.9518966126441955\n",
      "\n",
      "Epoch:    5/10    Loss: 4.037842605113983\n",
      "\n",
      "Epoch:    5/10    Loss: 3.901958854198456\n",
      "\n",
      "Epoch:    5/10    Loss: 3.822028629779816\n",
      "\n",
      "Epoch:    5/10    Loss: 3.93043692111969\n",
      "\n",
      "Epoch:    5/10    Loss: 3.8655175411701204\n",
      "\n",
      "Epoch:    5/10    Loss: 3.7734237718582153\n",
      "\n",
      "Epoch:    5/10    Loss: 3.749993498325348\n",
      "\n",
      "Epoch:    5/10    Loss: 3.7357301354408263\n",
      "\n",
      "Epoch:    5/10    Loss: 3.9095611214637755\n",
      "\n",
      "Epoch:    5/10    Loss: 4.023573319911957\n",
      "\n",
      "Epoch:    5/10    Loss: 3.6834892010688782\n",
      "\n",
      "Epoch:    5/10    Loss: 4.081367506980896\n",
      "\n",
      "Epoch:    5/10    Loss: 3.8082335448265074\n",
      "\n",
      "Epoch:    5/10    Loss: 4.20408729314804\n",
      "\n",
      "Epoch:    5/10    Loss: 3.816796944141388\n",
      "\n",
      "Epoch:    5/10    Loss: 4.167341465950012\n",
      "\n",
      "Epoch:    5/10    Loss: 4.290039136409759\n",
      "\n",
      "Epoch:    5/10    Loss: 3.9656698155403136\n",
      "\n",
      "Epoch:    5/10    Loss: 3.7722065329551695\n",
      "\n",
      "Epoch:    5/10    Loss: 3.7322267472743986\n",
      "\n",
      "Epoch:    5/10    Loss: 3.7170410776138305\n",
      "\n",
      "Epoch:    5/10    Loss: 3.7568592119216917\n",
      "\n",
      "Epoch:    5/10    Loss: 3.864031159877777\n",
      "\n",
      "Epoch:    5/10    Loss: 3.5158135628700258\n",
      "\n",
      "Epoch:    5/10    Loss: 3.7147022914886474\n",
      "\n",
      "Epoch:    5/10    Loss: 3.630490641593933\n",
      "\n",
      "Epoch:    5/10    Loss: 3.7950392293930055\n",
      "\n",
      "Epoch:    5/10    Loss: 3.6096434473991392\n",
      "\n",
      "Epoch:    5/10    Loss: 3.6519890439510347\n",
      "\n",
      "Epoch:    5/10    Loss: 4.017927536964416\n",
      "\n",
      "Epoch:    5/10    Loss: 3.6700529932975767\n",
      "\n",
      "Epoch:    5/10    Loss: 3.8235904216766357\n",
      "\n",
      "Epoch:    5/10    Loss: 3.9507269620895387\n",
      "\n",
      "Epoch:    5/10    Loss: 3.85007376909256\n",
      "\n",
      "Epoch:    5/10    Loss: 4.287668285369873\n",
      "\n",
      "Epoch:    5/10    Loss: 3.557063081264496\n",
      "\n",
      "Epoch:    5/10    Loss: 3.4870305705070495\n",
      "\n",
      "Epoch:    5/10    Loss: 3.864009919166565\n",
      "\n",
      "Epoch:    5/10    Loss: 3.896055006980896\n",
      "\n",
      "Epoch:    5/10    Loss: 3.999352514743805\n",
      "\n",
      "Epoch:    5/10    Loss: 4.16376407623291\n",
      "\n",
      "Epoch:    5/10    Loss: 4.054026951789856\n",
      "\n",
      "Epoch:    5/10    Loss: 3.9168698477745054\n",
      "\n",
      "Epoch:    5/10    Loss: 3.7694940435886384\n",
      "\n",
      "Epoch:    5/10    Loss: 3.5925221157073977\n",
      "\n",
      "Epoch:    5/10    Loss: 4.01870331287384\n",
      "\n",
      "Epoch:    5/10    Loss: 3.86232759475708\n",
      "\n",
      "Epoch:    5/10    Loss: 3.9455056595802307\n",
      "\n",
      "Epoch:    5/10    Loss: 3.8235015082359314\n",
      "\n",
      "Epoch:    5/10    Loss: 3.735209403038025\n",
      "\n",
      "Epoch:    5/10    Loss: 3.9136864042282102\n",
      "\n",
      "Epoch:    5/10    Loss: 3.7384114050865174\n",
      "\n",
      "Epoch:    5/10    Loss: 3.6763753294944763\n",
      "\n",
      "Epoch:    5/10    Loss: 3.980538017749786\n",
      "\n",
      "Epoch:    5/10    Loss: 4.024731531143188\n",
      "\n",
      "Epoch:    5/10    Loss: 3.767246890068054\n",
      "\n",
      "Epoch:    5/10    Loss: 3.901185233592987\n",
      "\n",
      "Epoch:    5/10    Loss: 3.418036212921143\n",
      "\n",
      "Epoch:    5/10    Loss: 3.701922105550766\n",
      "\n",
      "Epoch:    5/10    Loss: 3.802901167869568\n",
      "\n",
      "Epoch:    5/10    Loss: 4.034300675392151\n",
      "\n",
      "Epoch:    5/10    Loss: 3.7705873107910155\n",
      "\n",
      "Epoch:    5/10    Loss: 3.9229804944992064\n",
      "\n",
      "Epoch:    5/10    Loss: 3.746409102678299\n",
      "\n",
      "Epoch:    5/10    Loss: 3.625432195663452\n",
      "\n",
      "Epoch:    5/10    Loss: 3.7838957858085633\n",
      "\n",
      "Epoch:    5/10    Loss: 3.9630949902534485\n",
      "\n",
      "Epoch:    5/10    Loss: 3.8801938819885256\n",
      "\n",
      "Epoch:    5/10    Loss: 4.171220927238465\n",
      "\n",
      "Epoch:    5/10    Loss: 3.982704837322235\n",
      "\n",
      "Epoch:    5/10    Loss: 4.000104970932007\n",
      "\n",
      "Epoch:    5/10    Loss: 4.018392171859741\n",
      "\n",
      "Epoch:    5/10    Loss: 3.887873215675354\n",
      "\n",
      "Epoch:    5/10    Loss: 3.665972938537598\n",
      "\n",
      "Epoch:    5/10    Loss: 3.95324423789978\n",
      "\n",
      "Epoch:    5/10    Loss: 3.967611402273178\n",
      "\n",
      "Epoch:    5/10    Loss: 3.8866894125938414\n",
      "\n",
      "Epoch:    5/10    Loss: 4.252483086585999\n",
      "\n",
      "Epoch:    5/10    Loss: 3.9975816130638124\n",
      "\n",
      "Epoch:    5/10    Loss: 3.9479607343673706\n",
      "\n",
      "Epoch:    5/10    Loss: 3.7956617629528044\n",
      "\n",
      "Epoch:    5/10    Loss: 3.8924469447135923\n",
      "\n",
      "Epoch:    5/10    Loss: 4.253283824920654\n",
      "\n",
      "Epoch:    5/10    Loss: 4.277034661769867\n",
      "\n",
      "Epoch:    5/10    Loss: 3.9808419275283815\n",
      "\n",
      "Epoch:    5/10    Loss: 4.169798793792725\n",
      "\n",
      "Epoch:    5/10    Loss: 4.174734706878662\n",
      "\n",
      "Epoch:    5/10    Loss: 4.205862352848053\n",
      "\n",
      "Epoch:    5/10    Loss: 4.150198277235031\n",
      "\n",
      "Epoch:    5/10    Loss: 4.209102756977082\n",
      "\n",
      "Epoch:    5/10    Loss: 3.9658591771125793\n",
      "\n",
      "Epoch:    5/10    Loss: 4.035853998661041\n",
      "\n",
      "Epoch:    5/10    Loss: 3.939785499572754\n",
      "\n",
      "Epoch:    5/10    Loss: 3.999809308052063\n",
      "\n",
      "Epoch:    5/10    Loss: 4.023579585552215\n",
      "\n",
      "Epoch:    5/10    Loss: 4.17617297410965\n",
      "\n",
      "Epoch:    5/10    Loss: 4.093623750209808\n",
      "\n",
      "Epoch:    5/10    Loss: 3.883023223876953\n",
      "\n",
      "Epoch:    5/10    Loss: 4.22871396780014\n",
      "\n",
      "Epoch:    5/10    Loss: 4.062223284244538\n",
      "\n",
      "Epoch:    5/10    Loss: 3.810436246395111\n",
      "\n",
      "Epoch:    5/10    Loss: 4.12341769695282\n",
      "\n",
      "Epoch:    5/10    Loss: 4.142930405139923\n",
      "\n",
      "Epoch:    5/10    Loss: 3.920912961959839\n",
      "\n",
      "Epoch:    5/10    Loss: 4.195203287601471\n",
      "\n",
      "Epoch:    5/10    Loss: 3.9284322166442873\n",
      "\n",
      "Epoch:    5/10    Loss: 4.294424264431\n",
      "\n",
      "Epoch:    5/10    Loss: 4.060829870700836\n",
      "\n",
      "Epoch:    5/10    Loss: 4.039738997220993\n",
      "\n",
      "Epoch:    5/10    Loss: 3.929470593929291\n",
      "\n",
      "Epoch:    5/10    Loss: 4.163104002475738\n",
      "\n",
      "Epoch:    5/10    Loss: 3.9992715334892273\n",
      "\n",
      "Epoch:    5/10    Loss: 4.065683217048645\n",
      "\n",
      "Epoch:    5/10    Loss: 4.01123370885849\n",
      "\n",
      "Epoch:    5/10    Loss: 3.921080812215805\n",
      "\n",
      "Epoch:    5/10    Loss: 3.86217538356781\n",
      "\n",
      "Epoch:    5/10    Loss: 4.19966632604599\n",
      "\n",
      "Epoch:    5/10    Loss: 4.3767747521400455\n",
      "\n",
      "Epoch:    5/10    Loss: 4.005699560642243\n",
      "\n",
      "Epoch:    5/10    Loss: 3.9567682766914367\n",
      "\n",
      "Epoch:    5/10    Loss: 3.9106761980056763\n",
      "\n",
      "Epoch:    5/10    Loss: 3.8640394628047945\n",
      "\n",
      "Epoch:    5/10    Loss: 4.266520615816116\n",
      "\n",
      "Epoch:    5/10    Loss: 4.045718834400177\n",
      "\n",
      "Epoch:    5/10    Loss: 4.0300453186035154\n",
      "\n",
      "Epoch:    5/10    Loss: 4.116579239368439\n",
      "\n",
      "Epoch:    5/10    Loss: 4.210660104751587\n",
      "\n",
      "Epoch:    5/10    Loss: 4.02221607208252\n",
      "\n",
      "Epoch:    5/10    Loss: 3.732897620201111\n",
      "\n",
      "Epoch:    5/10    Loss: 4.032094295024872\n",
      "\n",
      "Epoch:    5/10    Loss: 4.033303706645966\n",
      "\n",
      "Epoch:    5/10    Loss: 3.8693420553207396\n",
      "\n",
      "Epoch:    5/10    Loss: 3.797104184627533\n",
      "\n",
      "Epoch:    5/10    Loss: 3.9600876712799074\n",
      "\n",
      "Epoch:    5/10    Loss: 4.275280823707581\n",
      "\n",
      "Epoch:    5/10    Loss: 4.133909862041474\n",
      "\n",
      "Epoch:    5/10    Loss: 4.084660367965698\n",
      "\n",
      "Epoch:    5/10    Loss: 4.019451329708099\n",
      "\n",
      "Epoch:    5/10    Loss: 3.8627676153182984\n",
      "\n",
      "Epoch:    5/10    Loss: 3.752395087480545\n",
      "\n",
      "Epoch:    5/10    Loss: 3.987060922384262\n",
      "\n",
      "Epoch:    5/10    Loss: 3.844952799081802\n",
      "\n",
      "Epoch:    5/10    Loss: 3.9013381719589235\n",
      "\n",
      "Epoch:    5/10    Loss: 4.77593879699707\n",
      "\n",
      "Epoch:    6/10    Loss: 4.1705852237980015\n",
      "\n",
      "Epoch:    6/10    Loss: 3.872937524318695\n",
      "\n",
      "Epoch:    6/10    Loss: 3.5732477045059206\n",
      "\n",
      "Epoch:    6/10    Loss: 3.843220191001892\n",
      "\n",
      "Epoch:    6/10    Loss: 3.610793205499649\n",
      "\n",
      "Epoch:    6/10    Loss: 3.6219607186317444\n",
      "\n",
      "Epoch:    6/10    Loss: 3.8301916027069094\n",
      "\n",
      "Epoch:    6/10    Loss: 3.759857437610626\n",
      "\n",
      "Epoch:    6/10    Loss: 3.8558154344558715\n",
      "\n",
      "Epoch:    6/10    Loss: 3.6542062628269196\n",
      "\n",
      "Epoch:    6/10    Loss: 3.9487263917922975\n",
      "\n",
      "Epoch:    6/10    Loss: 3.82230384349823\n",
      "\n",
      "Epoch:    6/10    Loss: 3.889141526222229\n",
      "\n",
      "Epoch:    6/10    Loss: 3.61434862613678\n",
      "\n",
      "Epoch:    6/10    Loss: 3.8549052357673643\n",
      "\n",
      "Epoch:    6/10    Loss: 3.850797475576401\n",
      "\n",
      "Epoch:    6/10    Loss: 3.665018194913864\n",
      "\n",
      "Epoch:    6/10    Loss: 3.959625880718231\n",
      "\n",
      "Epoch:    6/10    Loss: 3.785436191558838\n",
      "\n",
      "Epoch:    6/10    Loss: 3.973294930458069\n",
      "\n",
      "Epoch:    6/10    Loss: 3.6345618987083435\n",
      "\n",
      "Epoch:    6/10    Loss: 3.78950040102005\n",
      "\n",
      "Epoch:    6/10    Loss: 3.930757234096527\n",
      "\n",
      "Epoch:    6/10    Loss: 3.793305399417877\n",
      "\n",
      "Epoch:    6/10    Loss: 3.822868273258209\n",
      "\n",
      "Epoch:    6/10    Loss: 4.1471375823020935\n",
      "\n",
      "Epoch:    6/10    Loss: 3.7241977858543396\n",
      "\n",
      "Epoch:    6/10    Loss: 4.060772767066956\n",
      "\n",
      "Epoch:    6/10    Loss: 3.839179548025131\n",
      "\n",
      "Epoch:    6/10    Loss: 3.543401925563812\n",
      "\n",
      "Epoch:    6/10    Loss: 4.051456019878388\n",
      "\n",
      "Epoch:    6/10    Loss: 3.6748586535453795\n",
      "\n",
      "Epoch:    6/10    Loss: 4.279788689613342\n",
      "\n",
      "Epoch:    6/10    Loss: 4.064239375591278\n",
      "\n",
      "Epoch:    6/10    Loss: 3.708967515230179\n",
      "\n",
      "Epoch:    6/10    Loss: 3.6950574350357055\n",
      "\n",
      "Epoch:    6/10    Loss: 3.5979837203025817\n",
      "\n",
      "Epoch:    6/10    Loss: 3.6207784748077394\n",
      "\n",
      "Epoch:    6/10    Loss: 3.7309285044670104\n",
      "\n",
      "Epoch:    6/10    Loss: 3.79640625\n",
      "\n",
      "Epoch:    6/10    Loss: 3.5449961471557616\n",
      "\n",
      "Epoch:    6/10    Loss: 3.6269725918769837\n",
      "\n",
      "Epoch:    6/10    Loss: 3.8879275488853455\n",
      "\n",
      "Epoch:    6/10    Loss: 3.8617719626426696\n",
      "\n",
      "Epoch:    6/10    Loss: 4.273102371692658\n",
      "\n",
      "Epoch:    6/10    Loss: 3.8777295899391175\n",
      "\n",
      "Epoch:    6/10    Loss: 3.790687198638916\n",
      "\n",
      "Epoch:    6/10    Loss: 3.9115577149391174\n",
      "\n",
      "Epoch:    6/10    Loss: 3.4846497631072997\n",
      "\n",
      "Epoch:    6/10    Loss: 3.7749450039863586\n",
      "\n",
      "Epoch:    6/10    Loss: 3.8235334849357603\n",
      "\n",
      "Epoch:    6/10    Loss: 3.7858681297302246\n",
      "\n",
      "Epoch:    6/10    Loss: 3.9932264482975004\n",
      "\n",
      "Epoch:    6/10    Loss: 3.8105787467956542\n",
      "\n",
      "Epoch:    6/10    Loss: 3.818992655277252\n",
      "\n",
      "Epoch:    6/10    Loss: 3.773286232948303\n",
      "\n",
      "Epoch:    6/10    Loss: 3.59670702457428\n",
      "\n",
      "Epoch:    6/10    Loss: 3.589853081703186\n",
      "\n",
      "Epoch:    6/10    Loss: 3.4816169893741606\n",
      "\n",
      "Epoch:    6/10    Loss: 3.6464027857780454\n",
      "\n",
      "Epoch:    6/10    Loss: 3.918909251689911\n",
      "\n",
      "Epoch:    6/10    Loss: 3.909176388978958\n",
      "\n",
      "Epoch:    6/10    Loss: 3.832830581665039\n",
      "\n",
      "Epoch:    6/10    Loss: 3.5160539603233336\n",
      "\n",
      "Epoch:    6/10    Loss: 3.6365110838413237\n",
      "\n",
      "Epoch:    6/10    Loss: 3.749588897228241\n",
      "\n",
      "Epoch:    6/10    Loss: 3.55138605594635\n",
      "\n",
      "Epoch:    6/10    Loss: 3.8637611854076384\n",
      "\n",
      "Epoch:    6/10    Loss: 3.5694034767150877\n",
      "\n",
      "Epoch:    6/10    Loss: 3.635984057188034\n",
      "\n",
      "Epoch:    6/10    Loss: 3.6778502082824707\n",
      "\n",
      "Epoch:    6/10    Loss: 3.746893136501312\n",
      "\n",
      "Epoch:    6/10    Loss: 3.6661734771728516\n",
      "\n",
      "Epoch:    6/10    Loss: 3.8370437276363374\n",
      "\n",
      "Epoch:    6/10    Loss: 3.787826020717621\n",
      "\n",
      "Epoch:    6/10    Loss: 3.618273203372955\n",
      "\n",
      "Epoch:    6/10    Loss: 3.87164724111557\n",
      "\n",
      "Epoch:    6/10    Loss: 3.558805212974548\n",
      "\n",
      "Epoch:    6/10    Loss: 3.641845281124115\n",
      "\n",
      "Epoch:    6/10    Loss: 4.180607290267944\n",
      "\n",
      "Epoch:    6/10    Loss: 3.6612981152534485\n",
      "\n",
      "Epoch:    6/10    Loss: 4.384636828899383\n",
      "\n",
      "Epoch:    6/10    Loss: 4.1009015941619875\n",
      "\n",
      "Epoch:    6/10    Loss: 3.7480321502685547\n",
      "\n",
      "Epoch:    6/10    Loss: 3.6960197949409483\n",
      "\n",
      "Epoch:    6/10    Loss: 3.7237314891815188\n",
      "\n",
      "Epoch:    6/10    Loss: 3.9747842288017274\n",
      "\n",
      "Epoch:    6/10    Loss: 4.118585708141327\n",
      "\n",
      "Epoch:    6/10    Loss: 3.9970914268493654\n",
      "\n",
      "Epoch:    6/10    Loss: 3.689391567707062\n",
      "\n",
      "Epoch:    6/10    Loss: 3.9963545632362365\n",
      "\n",
      "Epoch:    6/10    Loss: 3.821466600894928\n",
      "\n",
      "Epoch:    6/10    Loss: 3.935708990097046\n",
      "\n",
      "Epoch:    6/10    Loss: 3.7232726120948794\n",
      "\n",
      "Epoch:    6/10    Loss: 3.85995769739151\n",
      "\n",
      "Epoch:    6/10    Loss: 3.8154874539375303\n",
      "\n",
      "Epoch:    6/10    Loss: 3.7882018184661863\n",
      "\n",
      "Epoch:    6/10    Loss: 3.9695354223251345\n",
      "\n",
      "Epoch:    6/10    Loss: 3.6097330033779143\n",
      "\n",
      "Epoch:    6/10    Loss: 3.651127201318741\n",
      "\n",
      "Epoch:    6/10    Loss: 3.9001901078224184\n",
      "\n",
      "Epoch:    6/10    Loss: 3.6946303391456605\n",
      "\n",
      "Epoch:    6/10    Loss: 3.7142175602912904\n",
      "\n",
      "Epoch:    6/10    Loss: 3.762044291496277\n",
      "\n",
      "Epoch:    6/10    Loss: 4.10707151889801\n",
      "\n",
      "Epoch:    6/10    Loss: 4.243375384807587\n",
      "\n",
      "Epoch:    6/10    Loss: 4.067745583057404\n",
      "\n",
      "Epoch:    6/10    Loss: 3.7449554419517517\n",
      "\n",
      "Epoch:    6/10    Loss: 3.6928425908088682\n",
      "\n",
      "Epoch:    6/10    Loss: 4.01144397854805\n",
      "\n",
      "Epoch:    6/10    Loss: 3.988538407087326\n",
      "\n",
      "Epoch:    6/10    Loss: 3.876059470176697\n",
      "\n",
      "Epoch:    6/10    Loss: 3.794129540920258\n",
      "\n",
      "Epoch:    6/10    Loss: 3.8598307049274445\n",
      "\n",
      "Epoch:    6/10    Loss: 4.058931875228882\n",
      "\n",
      "Epoch:    6/10    Loss: 4.039713826179504\n",
      "\n",
      "Epoch:    6/10    Loss: 4.036911529302597\n",
      "\n",
      "Epoch:    6/10    Loss: 3.859275469779968\n",
      "\n",
      "Epoch:    6/10    Loss: 4.160417132377624\n",
      "\n",
      "Epoch:    6/10    Loss: 4.12812730550766\n",
      "\n",
      "Epoch:    6/10    Loss: 4.014669849872589\n",
      "\n",
      "Epoch:    6/10    Loss: 3.8811306285858156\n",
      "\n",
      "Epoch:    6/10    Loss: 4.101045725345611\n",
      "\n",
      "Epoch:    6/10    Loss: 3.9302422976493836\n",
      "\n",
      "Epoch:    6/10    Loss: 3.7791052162647247\n",
      "\n",
      "Epoch:    6/10    Loss: 3.5930759072303773\n",
      "\n",
      "Epoch:    6/10    Loss: 3.9945143556594847\n",
      "\n",
      "Epoch:    6/10    Loss: 3.8898465251922607\n",
      "\n",
      "Epoch:    6/10    Loss: 3.8827111089229582\n",
      "\n",
      "Epoch:    6/10    Loss: 3.9523014855384826\n",
      "\n",
      "Epoch:    6/10    Loss: 4.074161674976349\n",
      "\n",
      "Epoch:    6/10    Loss: 3.739747796058655\n",
      "\n",
      "Epoch:    6/10    Loss: 3.94134309053421\n",
      "\n",
      "Epoch:    6/10    Loss: 3.8916321659088133\n",
      "\n",
      "Epoch:    6/10    Loss: 3.987945704460144\n",
      "\n",
      "Epoch:    6/10    Loss: 3.852451367378235\n",
      "\n",
      "Epoch:    6/10    Loss: 3.8053716588020325\n",
      "\n",
      "Epoch:    6/10    Loss: 3.865496814250946\n",
      "\n",
      "Epoch:    6/10    Loss: 3.8149609041213988\n",
      "\n",
      "Epoch:    6/10    Loss: 3.7024243116378783\n",
      "\n",
      "Epoch:    6/10    Loss: 3.688837859630585\n",
      "\n",
      "Epoch:    6/10    Loss: 3.6909921002388\n",
      "\n",
      "Epoch:    6/10    Loss: 3.88583961725235\n",
      "\n",
      "Epoch:    6/10    Loss: 3.9650374841690064\n",
      "\n",
      "Epoch:    6/10    Loss: 3.65354761838913\n",
      "\n",
      "Epoch:    6/10    Loss: 4.0436608338356015\n",
      "\n",
      "Epoch:    6/10    Loss: 3.7607476723194124\n",
      "\n",
      "Epoch:    6/10    Loss: 4.186131374835968\n",
      "\n",
      "Epoch:    6/10    Loss: 3.7705268812179566\n",
      "\n",
      "Epoch:    6/10    Loss: 4.131917200088501\n",
      "\n",
      "Epoch:    6/10    Loss: 4.259880349636078\n",
      "\n",
      "Epoch:    6/10    Loss: 3.9122525453567505\n",
      "\n",
      "Epoch:    6/10    Loss: 3.7263737154006957\n",
      "\n",
      "Epoch:    6/10    Loss: 3.695809073448181\n",
      "\n",
      "Epoch:    6/10    Loss: 3.719016816616058\n",
      "\n",
      "Epoch:    6/10    Loss: 3.7313526105880737\n",
      "\n",
      "Epoch:    6/10    Loss: 3.8122305154800413\n",
      "\n",
      "Epoch:    6/10    Loss: 3.4954326510429383\n",
      "\n",
      "Epoch:    6/10    Loss: 3.678455128669739\n",
      "\n",
      "Epoch:    6/10    Loss: 3.6070152366161348\n",
      "\n",
      "Epoch:    6/10    Loss: 3.7739595055580137\n",
      "\n",
      "Epoch:    6/10    Loss: 3.6102194011211397\n",
      "\n",
      "Epoch:    6/10    Loss: 3.6258075511455536\n",
      "\n",
      "Epoch:    6/10    Loss: 3.949923723936081\n",
      "\n",
      "Epoch:    6/10    Loss: 3.627841839790344\n",
      "\n",
      "Epoch:    6/10    Loss: 3.7936225271224977\n",
      "\n",
      "Epoch:    6/10    Loss: 3.9065973472595217\n",
      "\n",
      "Epoch:    6/10    Loss: 3.7805223870277405\n",
      "\n",
      "Epoch:    6/10    Loss: 4.2393014526367185\n",
      "\n",
      "Epoch:    6/10    Loss: 3.495520343780518\n",
      "\n",
      "Epoch:    6/10    Loss: 3.443624894618988\n",
      "\n",
      "Epoch:    6/10    Loss: 3.8065255665779114\n",
      "\n",
      "Epoch:    6/10    Loss: 3.85358380317688\n",
      "\n",
      "Epoch:    6/10    Loss: 3.9594810342788698\n",
      "\n",
      "Epoch:    6/10    Loss: 4.091667397022247\n",
      "\n",
      "Epoch:    6/10    Loss: 4.00093225479126\n",
      "\n",
      "Epoch:    6/10    Loss: 3.8974341583251952\n",
      "\n",
      "Epoch:    6/10    Loss: 3.7349319183826446\n",
      "\n",
      "Epoch:    6/10    Loss: 3.5627999341487886\n",
      "\n",
      "Epoch:    6/10    Loss: 4.007431466579437\n",
      "\n",
      "Epoch:    6/10    Loss: 3.8259051382541656\n",
      "\n",
      "Epoch:    6/10    Loss: 3.880208759307861\n",
      "\n",
      "Epoch:    6/10    Loss: 3.7881166553497314\n",
      "\n",
      "Epoch:    6/10    Loss: 3.6889220237731934\n",
      "\n",
      "Epoch:    6/10    Loss: 3.8753714418411254\n",
      "\n",
      "Epoch:    6/10    Loss: 3.71705087184906\n",
      "\n",
      "Epoch:    6/10    Loss: 3.6589856553077698\n",
      "\n",
      "Epoch:    6/10    Loss: 3.944351507425308\n",
      "\n",
      "Epoch:    6/10    Loss: 3.974300162792206\n",
      "\n",
      "Epoch:    6/10    Loss: 3.716774024963379\n",
      "\n",
      "Epoch:    6/10    Loss: 3.8988441967964174\n",
      "\n",
      "Epoch:    6/10    Loss: 3.3652714896202087\n",
      "\n",
      "Epoch:    6/10    Loss: 3.682753028869629\n",
      "\n",
      "Epoch:    6/10    Loss: 3.816709282398224\n",
      "\n",
      "Epoch:    6/10    Loss: 4.007638602256775\n",
      "\n",
      "Epoch:    6/10    Loss: 3.7378750324249266\n",
      "\n",
      "Epoch:    6/10    Loss: 3.9022264552116392\n",
      "\n",
      "Epoch:    6/10    Loss: 3.7198111534118654\n",
      "\n",
      "Epoch:    6/10    Loss: 3.5758017754554747\n",
      "\n",
      "Epoch:    6/10    Loss: 3.7595680260658266\n",
      "\n",
      "Epoch:    6/10    Loss: 3.977228059768677\n",
      "\n",
      "Epoch:    6/10    Loss: 3.85961021900177\n",
      "\n",
      "Epoch:    6/10    Loss: 4.128497223854065\n",
      "\n",
      "Epoch:    6/10    Loss: 3.9440313172340393\n",
      "\n",
      "Epoch:    6/10    Loss: 3.9625775170326234\n",
      "\n",
      "Epoch:    6/10    Loss: 3.989864156246185\n",
      "\n",
      "Epoch:    6/10    Loss: 3.8766021013259886\n",
      "\n",
      "Epoch:    6/10    Loss: 3.6285484790802003\n",
      "\n",
      "Epoch:    6/10    Loss: 3.9193936920166017\n",
      "\n",
      "Epoch:    6/10    Loss: 3.9260029017925264\n",
      "\n",
      "Epoch:    6/10    Loss: 3.8426348900794984\n",
      "\n",
      "Epoch:    6/10    Loss: 4.1905907225608825\n",
      "\n",
      "Epoch:    6/10    Loss: 3.974656276702881\n",
      "\n",
      "Epoch:    6/10    Loss: 3.9077818965911866\n",
      "\n",
      "Epoch:    6/10    Loss: 3.765964317321777\n",
      "\n",
      "Epoch:    6/10    Loss: 3.8569036507606507\n",
      "\n",
      "Epoch:    6/10    Loss: 4.19833132147789\n",
      "\n",
      "Epoch:    6/10    Loss: 4.209656956195832\n",
      "\n",
      "Epoch:    6/10    Loss: 3.9687294936180115\n",
      "\n",
      "Epoch:    6/10    Loss: 4.13078644990921\n",
      "\n",
      "Epoch:    6/10    Loss: 4.162414348125457\n",
      "\n",
      "Epoch:    6/10    Loss: 4.1755147290229795\n",
      "\n",
      "Epoch:    6/10    Loss: 4.094243462085724\n",
      "\n",
      "Epoch:    6/10    Loss: 4.160653791427612\n",
      "\n",
      "Epoch:    6/10    Loss: 3.9085809803009033\n",
      "\n",
      "Epoch:    6/10    Loss: 3.9874853801727297\n",
      "\n",
      "Epoch:    6/10    Loss: 3.917947027683258\n",
      "\n",
      "Epoch:    6/10    Loss: 3.960716609954834\n",
      "\n",
      "Epoch:    6/10    Loss: 3.99840345621109\n",
      "\n",
      "Epoch:    6/10    Loss: 4.14132052898407\n",
      "\n",
      "Epoch:    6/10    Loss: 4.083916823863984\n",
      "\n",
      "Epoch:    6/10    Loss: 3.8627960467338562\n",
      "\n",
      "Epoch:    6/10    Loss: 4.1951677918434145\n",
      "\n",
      "Epoch:    6/10    Loss: 4.036218037605286\n",
      "\n",
      "Epoch:    6/10    Loss: 3.7861424565315245\n",
      "\n",
      "Epoch:    6/10    Loss: 4.1223149943351745\n",
      "\n",
      "Epoch:    6/10    Loss: 4.129744713306427\n",
      "\n",
      "Epoch:    6/10    Loss: 3.885674374103546\n",
      "\n",
      "Epoch:    6/10    Loss: 4.177510595321655\n",
      "\n",
      "Epoch:    6/10    Loss: 3.9564074301719665\n",
      "\n",
      "Epoch:    6/10    Loss: 4.294772684574127\n",
      "\n",
      "Epoch:    6/10    Loss: 4.053094503879547\n",
      "\n",
      "Epoch:    6/10    Loss: 4.011692854166031\n",
      "\n",
      "Epoch:    6/10    Loss: 3.8963045382499697\n",
      "\n",
      "Epoch:    6/10    Loss: 4.113941717147827\n",
      "\n",
      "Epoch:    6/10    Loss: 3.939677367210388\n",
      "\n",
      "Epoch:    6/10    Loss: 4.053024368286133\n",
      "\n",
      "Epoch:    6/10    Loss: 3.9738576292991636\n",
      "\n",
      "Epoch:    6/10    Loss: 3.8963305234909056\n",
      "\n",
      "Epoch:    6/10    Loss: 3.834185712337494\n",
      "\n",
      "Epoch:    6/10    Loss: 4.1760058283805845\n",
      "\n",
      "Epoch:    6/10    Loss: 4.315902729034423\n",
      "\n",
      "Epoch:    6/10    Loss: 3.96835440158844\n",
      "\n",
      "Epoch:    6/10    Loss: 3.9165094256401063\n",
      "\n",
      "Epoch:    6/10    Loss: 3.897844395637512\n",
      "\n",
      "Epoch:    6/10    Loss: 3.8205538284778595\n",
      "\n",
      "Epoch:    6/10    Loss: 4.24338131904602\n",
      "\n",
      "Epoch:    6/10    Loss: 3.996531853675842\n",
      "\n",
      "Epoch:    6/10    Loss: 3.9859415388107298\n",
      "\n",
      "Epoch:    6/10    Loss: 4.083029336929322\n",
      "\n",
      "Epoch:    6/10    Loss: 4.153359446525574\n",
      "\n",
      "Epoch:    6/10    Loss: 3.9894520092010497\n",
      "\n",
      "Epoch:    6/10    Loss: 3.725189073085785\n",
      "\n",
      "Epoch:    6/10    Loss: 4.006769111156464\n",
      "\n",
      "Epoch:    6/10    Loss: 4.016616458892822\n",
      "\n",
      "Epoch:    6/10    Loss: 3.850891330242157\n",
      "\n",
      "Epoch:    6/10    Loss: 3.806031494140625\n",
      "\n",
      "Epoch:    6/10    Loss: 3.934910910129547\n",
      "\n",
      "Epoch:    6/10    Loss: 4.258785915374756\n",
      "\n",
      "Epoch:    6/10    Loss: 4.100130324363708\n",
      "\n",
      "Epoch:    6/10    Loss: 4.037752816677093\n",
      "\n",
      "Epoch:    6/10    Loss: 3.9929259538650514\n",
      "\n",
      "Epoch:    6/10    Loss: 3.8490579962730407\n",
      "\n",
      "Epoch:    6/10    Loss: 3.747459810972214\n",
      "\n",
      "Epoch:    6/10    Loss: 3.9307029247283936\n",
      "\n",
      "Epoch:    6/10    Loss: 3.8111147964000702\n",
      "\n",
      "Epoch:    6/10    Loss: 3.8641265559196474\n",
      "\n",
      "Epoch:    6/10    Loss: 4.645551919937134\n",
      "\n",
      "Epoch:    7/10    Loss: 4.110482752992866\n",
      "\n",
      "Epoch:    7/10    Loss: 3.817988052368164\n",
      "\n",
      "Epoch:    7/10    Loss: 3.5541621589660646\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8592431378364562\n",
      "\n",
      "Epoch:    7/10    Loss: 3.5859211921691894\n",
      "\n",
      "Epoch:    7/10    Loss: 3.6266430389881132\n",
      "\n",
      "Epoch:    7/10    Loss: 3.781925733089447\n",
      "\n",
      "Epoch:    7/10    Loss: 3.7406400346755984\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8529861831665038\n",
      "\n",
      "Epoch:    7/10    Loss: 3.620959893465042\n",
      "\n",
      "Epoch:    7/10    Loss: 3.9072297477722167\n",
      "\n",
      "Epoch:    7/10    Loss: 3.7885887813568115\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8530696845054626\n",
      "\n",
      "Epoch:    7/10    Loss: 3.56971070766449\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8014333939552305\n",
      "\n",
      "Epoch:    7/10    Loss: 3.844755811691284\n",
      "\n",
      "Epoch:    7/10    Loss: 3.626271164417267\n",
      "\n",
      "Epoch:    7/10    Loss: 3.910512402057648\n",
      "\n",
      "Epoch:    7/10    Loss: 3.7614665365219118\n",
      "\n",
      "Epoch:    7/10    Loss: 3.896425259113312\n",
      "\n",
      "Epoch:    7/10    Loss: 3.634824882745743\n",
      "\n",
      "Epoch:    7/10    Loss: 3.789274339675903\n",
      "\n",
      "Epoch:    7/10    Loss: 3.9365500664710997\n",
      "\n",
      "Epoch:    7/10    Loss: 3.7618687200546264\n",
      "\n",
      "Epoch:    7/10    Loss: 3.7900935864448546\n",
      "\n",
      "Epoch:    7/10    Loss: 4.111186294555664\n",
      "\n",
      "Epoch:    7/10    Loss: 3.666224160194397\n",
      "\n",
      "Epoch:    7/10    Loss: 4.010480899810791\n",
      "\n",
      "Epoch:    7/10    Loss: 3.7896388399600984\n",
      "\n",
      "Epoch:    7/10    Loss: 3.5173136401176452\n",
      "\n",
      "Epoch:    7/10    Loss: 4.000152842998505\n",
      "\n",
      "Epoch:    7/10    Loss: 3.6422385239601134\n",
      "\n",
      "Epoch:    7/10    Loss: 4.305462145805359\n",
      "\n",
      "Epoch:    7/10    Loss: 4.046839649677277\n",
      "\n",
      "Epoch:    7/10    Loss: 3.6623649287223814\n",
      "\n",
      "Epoch:    7/10    Loss: 3.6602294278144836\n",
      "\n",
      "Epoch:    7/10    Loss: 3.576873961687088\n",
      "\n",
      "Epoch:    7/10    Loss: 3.5828679394721985\n",
      "\n",
      "Epoch:    7/10    Loss: 3.703077688217163\n",
      "\n",
      "Epoch:    7/10    Loss: 3.773184175491333\n",
      "\n",
      "Epoch:    7/10    Loss: 3.5149021899700164\n",
      "\n",
      "Epoch:    7/10    Loss: 3.588549156188965\n",
      "\n",
      "Epoch:    7/10    Loss: 3.827229630947113\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8001180446147917\n",
      "\n",
      "Epoch:    7/10    Loss: 4.258964097499847\n",
      "\n",
      "Epoch:    7/10    Loss: 3.865404908657074\n",
      "\n",
      "Epoch:    7/10    Loss: 3.7426899933815\n",
      "\n",
      "Epoch:    7/10    Loss: 3.907249710559845\n",
      "\n",
      "Epoch:    7/10    Loss: 3.4758532428741455\n",
      "\n",
      "Epoch:    7/10    Loss: 3.7653167176246645\n",
      "\n",
      "Epoch:    7/10    Loss: 3.809640679359436\n",
      "\n",
      "Epoch:    7/10    Loss: 3.7984757924079897\n",
      "\n",
      "Epoch:    7/10    Loss: 3.95131072640419\n",
      "\n",
      "Epoch:    7/10    Loss: 3.815848183631897\n",
      "\n",
      "Epoch:    7/10    Loss: 3.7987895226478576\n",
      "\n",
      "Epoch:    7/10    Loss: 3.7379302763938904\n",
      "\n",
      "Epoch:    7/10    Loss: 3.567000560760498\n",
      "\n",
      "Epoch:    7/10    Loss: 3.531767132282257\n",
      "\n",
      "Epoch:    7/10    Loss: 3.428799817562103\n",
      "\n",
      "Epoch:    7/10    Loss: 3.627846477031708\n",
      "\n",
      "Epoch:    7/10    Loss: 3.877032792568207\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8542756283283235\n",
      "\n",
      "Epoch:    7/10    Loss: 3.801196980476379\n",
      "\n",
      "Epoch:    7/10    Loss: 3.467095000743866\n",
      "\n",
      "Epoch:    7/10    Loss: 3.6254651725292204\n",
      "\n",
      "Epoch:    7/10    Loss: 3.6987684774398804\n",
      "\n",
      "Epoch:    7/10    Loss: 3.5140174078941344\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8004987907409666\n",
      "\n",
      "Epoch:    7/10    Loss: 3.494502100944519\n",
      "\n",
      "Epoch:    7/10    Loss: 3.581161024570465\n",
      "\n",
      "Epoch:    7/10    Loss: 3.6389311146736145\n",
      "\n",
      "Epoch:    7/10    Loss: 3.730097098350525\n",
      "\n",
      "Epoch:    7/10    Loss: 3.6322302269935607\n",
      "\n",
      "Epoch:    7/10    Loss: 3.7847816717624663\n",
      "\n",
      "Epoch:    7/10    Loss: 3.7590497589111327\n",
      "\n",
      "Epoch:    7/10    Loss: 3.554720981121063\n",
      "\n",
      "Epoch:    7/10    Loss: 3.814022822380066\n",
      "\n",
      "Epoch:    7/10    Loss: 3.5422333765029905\n",
      "\n",
      "Epoch:    7/10    Loss: 3.605884175300598\n",
      "\n",
      "Epoch:    7/10    Loss: 4.1640901017189025\n",
      "\n",
      "Epoch:    7/10    Loss: 3.653868775367737\n",
      "\n",
      "Epoch:    7/10    Loss: 4.354189624786377\n",
      "\n",
      "Epoch:    7/10    Loss: 4.092183694839478\n",
      "\n",
      "Epoch:    7/10    Loss: 3.7325077176094057\n",
      "\n",
      "Epoch:    7/10    Loss: 3.6662023186683657\n",
      "\n",
      "Epoch:    7/10    Loss: 3.6703199017047883\n",
      "\n",
      "Epoch:    7/10    Loss: 3.926852641105652\n",
      "\n",
      "Epoch:    7/10    Loss: 4.06677316904068\n",
      "\n",
      "Epoch:    7/10    Loss: 3.962137613296509\n",
      "\n",
      "Epoch:    7/10    Loss: 3.6603134083747864\n",
      "\n",
      "Epoch:    7/10    Loss: 3.93206839799881\n",
      "\n",
      "Epoch:    7/10    Loss: 3.7859187364578246\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8818115997314453\n",
      "\n",
      "Epoch:    7/10    Loss: 3.670676760673523\n",
      "\n",
      "Epoch:    7/10    Loss: 3.7618017840385436\n",
      "\n",
      "Epoch:    7/10    Loss: 3.7458517217636107\n",
      "\n",
      "Epoch:    7/10    Loss: 3.749434279203415\n",
      "\n",
      "Epoch:    7/10    Loss: 3.952390787601471\n",
      "\n",
      "Epoch:    7/10    Loss: 3.5905121183395385\n",
      "\n",
      "Epoch:    7/10    Loss: 3.5894896566867827\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8215650606155394\n",
      "\n",
      "Epoch:    7/10    Loss: 3.664617795944214\n",
      "\n",
      "Epoch:    7/10    Loss: 3.6734315264225006\n",
      "\n",
      "Epoch:    7/10    Loss: 3.7277950608730315\n",
      "\n",
      "Epoch:    7/10    Loss: 4.098900611400604\n",
      "\n",
      "Epoch:    7/10    Loss: 4.232429912090302\n",
      "\n",
      "Epoch:    7/10    Loss: 4.05717502117157\n",
      "\n",
      "Epoch:    7/10    Loss: 3.747253367900848\n",
      "\n",
      "Epoch:    7/10    Loss: 3.627964611053467\n",
      "\n",
      "Epoch:    7/10    Loss: 3.96577751159668\n",
      "\n",
      "Epoch:    7/10    Loss: 3.944717710018158\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8217643547058104\n",
      "\n",
      "Epoch:    7/10    Loss: 3.7530383181571962\n",
      "\n",
      "Epoch:    7/10    Loss: 3.824888246059418\n",
      "\n",
      "Epoch:    7/10    Loss: 4.0477909755706785\n",
      "\n",
      "Epoch:    7/10    Loss: 4.014085980653763\n",
      "\n",
      "Epoch:    7/10    Loss: 4.009743552207947\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8314615201950075\n",
      "\n",
      "Epoch:    7/10    Loss: 4.121985557079316\n",
      "\n",
      "Epoch:    7/10    Loss: 4.116015305519104\n",
      "\n",
      "Epoch:    7/10    Loss: 3.9776155304908754\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8804331827163696\n",
      "\n",
      "Epoch:    7/10    Loss: 4.073008902072907\n",
      "\n",
      "Epoch:    7/10    Loss: 3.9152794241905213\n",
      "\n",
      "Epoch:    7/10    Loss: 3.749543071985245\n",
      "\n",
      "Epoch:    7/10    Loss: 3.5582241368293763\n",
      "\n",
      "Epoch:    7/10    Loss: 3.974085018634796\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8660171937942507\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8724019384384154\n",
      "\n",
      "Epoch:    7/10    Loss: 3.9655722045898436\n",
      "\n",
      "Epoch:    7/10    Loss: 4.034636552333832\n",
      "\n",
      "Epoch:    7/10    Loss: 3.7130443453788757\n",
      "\n",
      "Epoch:    7/10    Loss: 3.9201583790779115\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8332009506225586\n",
      "\n",
      "Epoch:    7/10    Loss: 3.979435451030731\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8295314002037046\n",
      "\n",
      "Epoch:    7/10    Loss: 3.771418123245239\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8574834418296815\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8184635615348816\n",
      "\n",
      "Epoch:    7/10    Loss: 3.6916517543792726\n",
      "\n",
      "Epoch:    7/10    Loss: 3.6366499876976013\n",
      "\n",
      "Epoch:    7/10    Loss: 3.6268081140518187\n",
      "\n",
      "Epoch:    7/10    Loss: 3.844447271823883\n",
      "\n",
      "Epoch:    7/10    Loss: 3.9565212333202364\n",
      "\n",
      "Epoch:    7/10    Loss: 3.611002063751221\n",
      "\n",
      "Epoch:    7/10    Loss: 4.001205790042877\n",
      "\n",
      "Epoch:    7/10    Loss: 3.7223547327518465\n",
      "\n",
      "Epoch:    7/10    Loss: 4.146220374107361\n",
      "\n",
      "Epoch:    7/10    Loss: 3.706113302707672\n",
      "\n",
      "Epoch:    7/10    Loss: 4.118712553977966\n",
      "\n",
      "Epoch:    7/10    Loss: 4.1988981294631955\n",
      "\n",
      "Epoch:    7/10    Loss: 3.912705271244049\n",
      "\n",
      "Epoch:    7/10    Loss: 3.7191716265678405\n",
      "\n",
      "Epoch:    7/10    Loss: 3.6713328742980957\n",
      "\n",
      "Epoch:    7/10    Loss: 3.6500870966911316\n",
      "\n",
      "Epoch:    7/10    Loss: 3.703387631177902\n",
      "\n",
      "Epoch:    7/10    Loss: 3.781488609313965\n",
      "\n",
      "Epoch:    7/10    Loss: 3.4542508506774903\n",
      "\n",
      "Epoch:    7/10    Loss: 3.639283037185669\n",
      "\n",
      "Epoch:    7/10    Loss: 3.570575281381607\n",
      "\n",
      "Epoch:    7/10    Loss: 3.756225275993347\n",
      "\n",
      "Epoch:    7/10    Loss: 3.570080269575119\n",
      "\n",
      "Epoch:    7/10    Loss: 3.5949280142784117\n",
      "\n",
      "Epoch:    7/10    Loss: 3.945432336330414\n",
      "\n",
      "Epoch:    7/10    Loss: 3.595716633796692\n",
      "\n",
      "Epoch:    7/10    Loss: 3.7677723598480224\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8730946469306944\n",
      "\n",
      "Epoch:    7/10    Loss: 3.746096873283386\n",
      "\n",
      "Epoch:    7/10    Loss: 4.181471102237701\n",
      "\n",
      "Epoch:    7/10    Loss: 3.454048844575882\n",
      "\n",
      "Epoch:    7/10    Loss: 3.450412220954895\n",
      "\n",
      "Epoch:    7/10    Loss: 3.774756305217743\n",
      "\n",
      "Epoch:    7/10    Loss: 3.812504061460495\n",
      "\n",
      "Epoch:    7/10    Loss: 3.914909222126007\n",
      "\n",
      "Epoch:    7/10    Loss: 4.0624079465866085\n",
      "\n",
      "Epoch:    7/10    Loss: 3.9786935353279116\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8602050852775576\n",
      "\n",
      "Epoch:    7/10    Loss: 3.7476060032844543\n",
      "\n",
      "Epoch:    7/10    Loss: 3.5400025284290315\n",
      "\n",
      "Epoch:    7/10    Loss: 3.955237040519714\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8299680399894713\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8665275621414184\n",
      "\n",
      "Epoch:    7/10    Loss: 3.747339417934418\n",
      "\n",
      "Epoch:    7/10    Loss: 3.6780445551872254\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8509761667251587\n",
      "\n",
      "Epoch:    7/10    Loss: 3.676083164215088\n",
      "\n",
      "Epoch:    7/10    Loss: 3.6123239994049072\n",
      "\n",
      "Epoch:    7/10    Loss: 3.902984366416931\n",
      "\n",
      "Epoch:    7/10    Loss: 3.946761734485626\n",
      "\n",
      "Epoch:    7/10    Loss: 3.733144910335541\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8772097539901735\n",
      "\n",
      "Epoch:    7/10    Loss: 3.3845059490203857\n",
      "\n",
      "Epoch:    7/10    Loss: 3.6543983328342438\n",
      "\n",
      "Epoch:    7/10    Loss: 3.761247544288635\n",
      "\n",
      "Epoch:    7/10    Loss: 3.9681165862083434\n",
      "\n",
      "Epoch:    7/10    Loss: 3.733944056034088\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8815001845359802\n",
      "\n",
      "Epoch:    7/10    Loss: 3.7079501485824586\n",
      "\n",
      "Epoch:    7/10    Loss: 3.5518020153045655\n",
      "\n",
      "Epoch:    7/10    Loss: 3.739885919094086\n",
      "\n",
      "Epoch:    7/10    Loss: 3.9280798721313475\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8598376226425173\n",
      "\n",
      "Epoch:    7/10    Loss: 4.0930637550354\n",
      "\n",
      "Epoch:    7/10    Loss: 3.9249909567832946\n",
      "\n",
      "Epoch:    7/10    Loss: 3.945445681810379\n",
      "\n",
      "Epoch:    7/10    Loss: 3.9686992454528807\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8583887243270873\n",
      "\n",
      "Epoch:    7/10    Loss: 3.626517653465271\n",
      "\n",
      "Epoch:    7/10    Loss: 3.9140009355545042\n",
      "\n",
      "Epoch:    7/10    Loss: 3.9251856350898744\n",
      "\n",
      "Epoch:    7/10    Loss: 3.816273844242096\n",
      "\n",
      "Epoch:    7/10    Loss: 4.17887398481369\n",
      "\n",
      "Epoch:    7/10    Loss: 3.930728316307068\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8899507403373716\n",
      "\n",
      "Epoch:    7/10    Loss: 3.7357921159267424\n",
      "\n",
      "Epoch:    7/10    Loss: 3.842776403427124\n",
      "\n",
      "Epoch:    7/10    Loss: 4.1479223239421845\n",
      "\n",
      "Epoch:    7/10    Loss: 4.156192371845245\n",
      "\n",
      "Epoch:    7/10    Loss: 3.9031455302238465\n",
      "\n",
      "Epoch:    7/10    Loss: 4.110416166782379\n",
      "\n",
      "Epoch:    7/10    Loss: 4.154281640052796\n",
      "\n",
      "Epoch:    7/10    Loss: 4.230301592350006\n",
      "\n",
      "Epoch:    7/10    Loss: 4.122755706310272\n",
      "\n",
      "Epoch:    7/10    Loss: 4.197418060302734\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8774109935760497\n",
      "\n",
      "Epoch:    7/10    Loss: 3.957827067375183\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8814680886268618\n",
      "\n",
      "Epoch:    7/10    Loss: 3.9066626024246216\n",
      "\n",
      "Epoch:    7/10    Loss: 3.9739434504508973\n",
      "\n",
      "Epoch:    7/10    Loss: 4.122765002250671\n",
      "\n",
      "Epoch:    7/10    Loss: 4.074555969238281\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8311490917205813\n",
      "\n",
      "Epoch:    7/10    Loss: 4.193168187141419\n",
      "\n",
      "Epoch:    7/10    Loss: 4.043078335523606\n",
      "\n",
      "Epoch:    7/10    Loss: 3.761300859451294\n",
      "\n",
      "Epoch:    7/10    Loss: 4.0862357759475705\n",
      "\n",
      "Epoch:    7/10    Loss: 4.090098152160644\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8513140749931334\n",
      "\n",
      "Epoch:    7/10    Loss: 4.127568926811218\n",
      "\n",
      "Epoch:    7/10    Loss: 3.940103073120117\n",
      "\n",
      "Epoch:    7/10    Loss: 4.2648553681373595\n",
      "\n",
      "Epoch:    7/10    Loss: 4.02213408946991\n",
      "\n",
      "Epoch:    7/10    Loss: 4.002219717502594\n",
      "\n",
      "Epoch:    7/10    Loss: 3.9200794100761414\n",
      "\n",
      "Epoch:    7/10    Loss: 4.070573036670685\n",
      "\n",
      "Epoch:    7/10    Loss: 3.9195375311374665\n",
      "\n",
      "Epoch:    7/10    Loss: 4.037636597156524\n",
      "\n",
      "Epoch:    7/10    Loss: 3.9725139355659485\n",
      "\n",
      "Epoch:    7/10    Loss: 3.9105899357795715\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8216062355041505\n",
      "\n",
      "Epoch:    7/10    Loss: 4.162945156097412\n",
      "\n",
      "Epoch:    7/10    Loss: 4.301774220466614\n",
      "\n",
      "Epoch:    7/10    Loss: 3.9121860432624818\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8694150173664092\n",
      "\n",
      "Epoch:    7/10    Loss: 3.853699142932892\n",
      "\n",
      "Epoch:    7/10    Loss: 3.7849662256240846\n",
      "\n",
      "Epoch:    7/10    Loss: 4.237785118818283\n",
      "\n",
      "Epoch:    7/10    Loss: 4.002522537708282\n",
      "\n",
      "Epoch:    7/10    Loss: 3.9690325689315795\n",
      "\n",
      "Epoch:    7/10    Loss: 4.059970846176148\n",
      "\n",
      "Epoch:    7/10    Loss: 4.145893099308014\n",
      "\n",
      "Epoch:    7/10    Loss: 3.970236279964447\n",
      "\n",
      "Epoch:    7/10    Loss: 3.6896662390232087\n",
      "\n",
      "Epoch:    7/10    Loss: 3.970204564332962\n",
      "\n",
      "Epoch:    7/10    Loss: 3.9818188166618347\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8332852697372437\n",
      "\n",
      "Epoch:    7/10    Loss: 3.7639519715309144\n",
      "\n",
      "Epoch:    7/10    Loss: 3.8942387390136717\n",
      "\n",
      "Epoch:    7/10    Loss: 4.235034308433533\n",
      "\n",
      "Epoch:    7/10    Loss: 4.117686920166015\n",
      "\n",
      "Epoch:    7/10    Loss: 4.040639357566834\n",
      "\n",
      "Epoch:    7/10    Loss: 3.954727602005005\n",
      "\n",
      "Epoch:    7/10    Loss: 3.774585509300232\n",
      "\n",
      "Epoch:    7/10    Loss: 3.685637857913971\n",
      "\n",
      "Epoch:    7/10    Loss: 3.902082438468933\n",
      "\n",
      "Epoch:    7/10    Loss: 3.7493374586105346\n",
      "\n",
      "Epoch:    7/10    Loss: 3.788325868844986\n",
      "\n",
      "Epoch:    7/10    Loss: 4.601541092395783\n",
      "\n",
      "Epoch:    8/10    Loss: 4.089531918589988\n",
      "\n",
      "Epoch:    8/10    Loss: 3.820504801273346\n",
      "\n",
      "Epoch:    8/10    Loss: 3.53911253452301\n",
      "\n",
      "Epoch:    8/10    Loss: 3.808522243499756\n",
      "\n",
      "Epoch:    8/10    Loss: 3.5792435848712922\n",
      "\n",
      "Epoch:    8/10    Loss: 3.5980665564537047\n",
      "\n",
      "Epoch:    8/10    Loss: 3.770947835445404\n",
      "\n",
      "Epoch:    8/10    Loss: 3.7202400016784667\n",
      "\n",
      "Epoch:    8/10    Loss: 3.8437319731712343\n",
      "\n",
      "Epoch:    8/10    Loss: 3.5901359724998474\n",
      "\n",
      "Epoch:    8/10    Loss: 3.8988482975959777\n",
      "\n",
      "Epoch:    8/10    Loss: 3.7600136494636534\n",
      "\n",
      "Epoch:    8/10    Loss: 3.8110215568542483\n",
      "\n",
      "Epoch:    8/10    Loss: 3.5268407678604126\n",
      "\n",
      "Epoch:    8/10    Loss: 3.7579622638225554\n",
      "\n",
      "Epoch:    8/10    Loss: 3.83202513217926\n",
      "\n",
      "Epoch:    8/10    Loss: 3.612861895561218\n",
      "\n",
      "Epoch:    8/10    Loss: 3.853551435470581\n",
      "\n",
      "Epoch:    8/10    Loss: 3.7336079454421998\n",
      "\n",
      "Epoch:    8/10    Loss: 3.874652535915375\n",
      "\n",
      "Epoch:    8/10    Loss: 3.596940040588379\n",
      "\n",
      "Epoch:    8/10    Loss: 3.741765329837799\n",
      "\n",
      "Epoch:    8/10    Loss: 3.9295712876319886\n",
      "\n",
      "Epoch:    8/10    Loss: 3.794746913909912\n",
      "\n",
      "Epoch:    8/10    Loss: 3.7651622772216795\n",
      "\n",
      "Epoch:    8/10    Loss: 4.090855193138123\n",
      "\n",
      "Epoch:    8/10    Loss: 3.675718083381653\n",
      "\n",
      "Epoch:    8/10    Loss: 4.026430721282959\n",
      "\n",
      "Epoch:    8/10    Loss: 3.774710228443146\n",
      "\n",
      "Epoch:    8/10    Loss: 3.4711178731918335\n",
      "\n",
      "Epoch:    8/10    Loss: 3.962040147781372\n",
      "\n",
      "Epoch:    8/10    Loss: 3.6131868958473206\n",
      "\n",
      "Epoch:    8/10    Loss: 4.23203696012497\n",
      "\n",
      "Epoch:    8/10    Loss: 4.0079191780090335\n",
      "\n",
      "Epoch:    8/10    Loss: 3.6360886120796203\n",
      "\n",
      "Epoch:    8/10    Loss: 3.629664340019226\n",
      "\n",
      "Epoch:    8/10    Loss: 3.585906958580017\n",
      "\n",
      "Epoch:    8/10    Loss: 3.580436359643936\n",
      "\n",
      "Epoch:    8/10    Loss: 3.672754502296448\n",
      "\n",
      "Epoch:    8/10    Loss: 3.7582833766937256\n",
      "\n",
      "Epoch:    8/10    Loss: 3.48879834651947\n",
      "\n",
      "Epoch:    8/10    Loss: 3.549534327983856\n",
      "\n",
      "Epoch:    8/10    Loss: 3.763326494693756\n",
      "\n",
      "Epoch:    8/10    Loss: 3.764105154275894\n",
      "\n",
      "Epoch:    8/10    Loss: 4.22286853313446\n",
      "\n",
      "Epoch:    8/10    Loss: 3.849246141910553\n",
      "\n",
      "Epoch:    8/10    Loss: 3.7244633841514587\n",
      "\n",
      "Epoch:    8/10    Loss: 3.9225926399230957\n",
      "\n",
      "Epoch:    8/10    Loss: 3.4548137867450714\n",
      "\n",
      "Epoch:    8/10    Loss: 3.729003038406372\n",
      "\n",
      "Epoch:    8/10    Loss: 3.804419660568237\n",
      "\n",
      "Epoch:    8/10    Loss: 3.7694269788265227\n",
      "\n",
      "Epoch:    8/10    Loss: 3.9315051782131194\n",
      "\n",
      "Epoch:    8/10    Loss: 3.7918671488761904\n",
      "\n",
      "Epoch:    8/10    Loss: 3.75424152135849\n",
      "\n",
      "Epoch:    8/10    Loss: 3.714209566116333\n",
      "\n",
      "Epoch:    8/10    Loss: 3.5153839766979216\n",
      "\n",
      "Epoch:    8/10    Loss: 3.493982813358307\n",
      "\n",
      "Epoch:    8/10    Loss: 3.3969573473930357\n",
      "\n",
      "Epoch:    8/10    Loss: 3.580998339653015\n",
      "\n",
      "Epoch:    8/10    Loss: 3.87514390707016\n",
      "\n",
      "Epoch:    8/10    Loss: 3.8155351746082307\n",
      "\n",
      "Epoch:    8/10    Loss: 3.769104813337326\n",
      "\n",
      "Epoch:    8/10    Loss: 3.4632347238063814\n",
      "\n",
      "Epoch:    8/10    Loss: 3.5483234131336214\n",
      "\n",
      "Epoch:    8/10    Loss: 3.675275242328644\n",
      "\n",
      "Epoch:    8/10    Loss: 3.476174006462097\n",
      "\n",
      "Epoch:    8/10    Loss: 3.805048689842224\n",
      "\n",
      "Epoch:    8/10    Loss: 3.4718179368972777\n",
      "\n",
      "Epoch:    8/10    Loss: 3.567602937221527\n",
      "\n",
      "Epoch:    8/10    Loss: 3.60953382730484\n",
      "\n",
      "Epoch:    8/10    Loss: 3.655037724971771\n",
      "\n",
      "Epoch:    8/10    Loss: 3.6189027571678163\n",
      "\n",
      "Epoch:    8/10    Loss: 3.7464518415927888\n",
      "\n",
      "Epoch:    8/10    Loss: 3.7201125383377076\n",
      "\n",
      "Epoch:    8/10    Loss: 3.5864018535614015\n",
      "\n",
      "Epoch:    8/10    Loss: 3.792812020778656\n",
      "\n",
      "Epoch:    8/10    Loss: 3.5049235606193543\n",
      "\n",
      "Epoch:    8/10    Loss: 3.5669976818561553\n",
      "\n",
      "Epoch:    8/10    Loss: 4.109429154396057\n",
      "\n",
      "Epoch:    8/10    Loss: 3.6049489426612853\n",
      "\n",
      "Epoch:    8/10    Loss: 4.343717112541198\n",
      "\n",
      "Epoch:    8/10    Loss: 4.042172565460205\n",
      "\n",
      "Epoch:    8/10    Loss: 3.6682653284072875\n",
      "\n",
      "Epoch:    8/10    Loss: 3.6308121919631957\n",
      "\n",
      "Epoch:    8/10    Loss: 3.6193888449668883\n",
      "\n",
      "Epoch:    8/10    Loss: 3.900586898326874\n",
      "\n",
      "Epoch:    8/10    Loss: 4.0800518536567685\n",
      "\n",
      "Epoch:    8/10    Loss: 3.975353093147278\n",
      "\n",
      "Epoch:    8/10    Loss: 3.6855768942832947\n",
      "\n",
      "Epoch:    8/10    Loss: 3.9392713022232058\n",
      "\n",
      "Epoch:    8/10    Loss: 3.7475901579856874\n",
      "\n",
      "Epoch:    8/10    Loss: 3.8598843836784362\n",
      "\n",
      "Epoch:    8/10    Loss: 3.6396317791938784\n",
      "\n",
      "Epoch:    8/10    Loss: 3.785898255109787\n",
      "\n",
      "Epoch:    8/10    Loss: 3.7132724213600157\n",
      "\n",
      "Epoch:    8/10    Loss: 3.715727972984314\n",
      "\n",
      "Epoch:    8/10    Loss: 3.90640353679657\n",
      "\n",
      "Epoch:    8/10    Loss: 3.5924276518821716\n",
      "\n",
      "Epoch:    8/10    Loss: 3.6033639419078827\n",
      "\n",
      "Epoch:    8/10    Loss: 3.8037323427200316\n",
      "\n",
      "Epoch:    8/10    Loss: 3.626859652996063\n",
      "\n",
      "Epoch:    8/10    Loss: 3.636274697780609\n",
      "\n",
      "Epoch:    8/10    Loss: 3.7457910883426666\n",
      "\n",
      "Epoch:    8/10    Loss: 4.1038009810447695\n",
      "\n",
      "Epoch:    8/10    Loss: 4.2197541952133175\n",
      "\n",
      "Epoch:    8/10    Loss: 4.037070616483688\n",
      "\n",
      "Epoch:    8/10    Loss: 3.6980137252807617\n",
      "\n",
      "Epoch:    8/10    Loss: 3.6191658663749693\n",
      "\n",
      "Epoch:    8/10    Loss: 3.9542051458358767\n",
      "\n",
      "Epoch:    8/10    Loss: 3.9024006593227387\n",
      "\n",
      "Epoch:    8/10    Loss: 3.810572414398193\n",
      "\n",
      "Epoch:    8/10    Loss: 3.7703334426879884\n",
      "\n",
      "Epoch:    8/10    Loss: 3.762331677675247\n",
      "\n",
      "Epoch:    8/10    Loss: 4.059386880397796\n",
      "\n",
      "Epoch:    8/10    Loss: 3.9377514624595644\n",
      "\n",
      "Epoch:    8/10    Loss: 3.9760846972465513\n",
      "\n",
      "Epoch:    8/10    Loss: 3.7968938374519348\n",
      "\n",
      "Epoch:    8/10    Loss: 4.097414915561676\n",
      "\n",
      "Epoch:    8/10    Loss: 4.090868644714355\n",
      "\n",
      "Epoch:    8/10    Loss: 3.9760037302970885\n",
      "\n",
      "Epoch:    8/10    Loss: 3.8207004737854002\n",
      "\n",
      "Epoch:    8/10    Loss: 4.037518017292022\n",
      "\n",
      "Epoch:    8/10    Loss: 3.858636527061462\n",
      "\n",
      "Epoch:    8/10    Loss: 3.733151135444641\n",
      "\n",
      "Epoch:    8/10    Loss: 3.516472599506378\n",
      "\n",
      "Epoch:    8/10    Loss: 3.9360338997840882\n",
      "\n",
      "Epoch:    8/10    Loss: 3.8771276926994322\n",
      "\n",
      "Epoch:    8/10    Loss: 3.828054472208023\n",
      "\n",
      "Epoch:    8/10    Loss: 3.971711664199829\n",
      "\n",
      "Epoch:    8/10    Loss: 4.035156590938568\n",
      "\n",
      "Epoch:    8/10    Loss: 3.70647225856781\n",
      "\n",
      "Epoch:    8/10    Loss: 3.873277499675751\n",
      "\n",
      "Epoch:    8/10    Loss: 3.85138774394989\n",
      "\n",
      "Epoch:    8/10    Loss: 3.973148934841156\n",
      "\n",
      "Epoch:    8/10    Loss: 3.8018038964271543\n",
      "\n",
      "Epoch:    8/10    Loss: 3.7643750953674315\n",
      "\n",
      "Epoch:    8/10    Loss: 3.830778465270996\n",
      "\n",
      "Epoch:    8/10    Loss: 3.782739953994751\n",
      "\n",
      "Epoch:    8/10    Loss: 3.6489940166473387\n",
      "\n",
      "Epoch:    8/10    Loss: 3.6692868077754976\n",
      "\n",
      "Epoch:    8/10    Loss: 3.6496050453186033\n",
      "\n",
      "Epoch:    8/10    Loss: 3.8390013217926025\n",
      "\n",
      "Epoch:    8/10    Loss: 3.9181398344039917\n",
      "\n",
      "Epoch:    8/10    Loss: 3.6140305519104006\n",
      "\n",
      "Epoch:    8/10    Loss: 3.977701210975647\n",
      "\n",
      "Epoch:    8/10    Loss: 3.700724664926529\n",
      "\n",
      "Epoch:    8/10    Loss: 4.12017884016037\n",
      "\n",
      "Epoch:    8/10    Loss: 3.7007473254203798\n",
      "\n",
      "Epoch:    8/10    Loss: 4.106658802032471\n",
      "\n",
      "Epoch:    8/10    Loss: 4.20330053806305\n",
      "\n",
      "Epoch:    8/10    Loss: 3.8952592635154724\n",
      "\n",
      "Epoch:    8/10    Loss: 3.6878651762008667\n",
      "\n",
      "Epoch:    8/10    Loss: 3.6853507137298585\n",
      "\n",
      "Epoch:    8/10    Loss: 3.6751761651039123\n",
      "\n",
      "Epoch:    8/10    Loss: 3.6784272408485412\n",
      "\n",
      "Epoch:    8/10    Loss: 3.776938455104828\n",
      "\n",
      "Epoch:    8/10    Loss: 3.4310453510284424\n",
      "\n",
      "Epoch:    8/10    Loss: 3.6445439624786378\n",
      "\n",
      "Epoch:    8/10    Loss: 3.548159635066986\n",
      "\n",
      "Epoch:    8/10    Loss: 3.7432283329963685\n",
      "\n",
      "Epoch:    8/10    Loss: 3.5706422579288484\n",
      "\n",
      "Epoch:    8/10    Loss: 3.598492683172226\n",
      "\n",
      "Epoch:    8/10    Loss: 3.939198899269104\n",
      "\n",
      "Epoch:    8/10    Loss: 3.5933372712135316\n",
      "\n",
      "Epoch:    8/10    Loss: 3.758965117931366\n",
      "\n",
      "Epoch:    8/10    Loss: 3.8343894934654235\n",
      "\n",
      "Epoch:    8/10    Loss: 3.7119427347183227\n",
      "\n",
      "Epoch:    8/10    Loss: 4.198674468994141\n",
      "\n",
      "Epoch:    8/10    Loss: 3.461319777965546\n",
      "\n",
      "Epoch:    8/10    Loss: 3.4466675448417665\n",
      "\n",
      "Epoch:    8/10    Loss: 3.7688645005226133\n",
      "\n",
      "Epoch:    8/10    Loss: 3.7993085885047915\n",
      "\n",
      "Epoch:    8/10    Loss: 3.9038287353515626\n",
      "\n",
      "Epoch:    8/10    Loss: 4.034304151535034\n",
      "\n",
      "Epoch:    8/10    Loss: 3.9678426575660706\n",
      "\n",
      "Epoch:    8/10    Loss: 3.8556799197196963\n",
      "\n",
      "Epoch:    8/10    Loss: 3.7085153222084046\n",
      "\n",
      "Epoch:    8/10    Loss: 3.5596054124832155\n",
      "\n",
      "Epoch:    8/10    Loss: 3.9602994823455813\n",
      "\n",
      "Epoch:    8/10    Loss: 3.8067819380760195\n",
      "\n",
      "Epoch:    8/10    Loss: 3.889310097694397\n",
      "\n",
      "Epoch:    8/10    Loss: 3.8036689281463625\n",
      "\n",
      "Epoch:    8/10    Loss: 3.7206401801109314\n",
      "\n",
      "Epoch:    8/10    Loss: 3.8246320629119874\n",
      "\n",
      "Epoch:    8/10    Loss: 3.676147141456604\n",
      "\n",
      "Epoch:    8/10    Loss: 3.602926378250122\n",
      "\n",
      "Epoch:    8/10    Loss: 3.931143352985382\n",
      "\n",
      "Epoch:    8/10    Loss: 3.9539146995544434\n",
      "\n",
      "Epoch:    8/10    Loss: 3.6879321813583372\n",
      "\n",
      "Epoch:    8/10    Loss: 3.7975331211090086\n",
      "\n",
      "Epoch:    8/10    Loss: 3.3483998370170593\n",
      "\n",
      "Epoch:    8/10    Loss: 3.650177009105682\n",
      "\n",
      "Epoch:    8/10    Loss: 3.747894113063812\n",
      "\n",
      "Epoch:    8/10    Loss: 3.961512622833252\n",
      "\n",
      "Epoch:    8/10    Loss: 3.7459776175022124\n",
      "\n",
      "Epoch:    8/10    Loss: 3.862921743392944\n",
      "\n",
      "Epoch:    8/10    Loss: 3.6824443900585173\n",
      "\n",
      "Epoch:    8/10    Loss: 3.503211808204651\n",
      "\n",
      "Epoch:    8/10    Loss: 3.6827057719230654\n",
      "\n",
      "Epoch:    8/10    Loss: 3.867535445690155\n",
      "\n",
      "Epoch:    8/10    Loss: 3.849812874794006\n",
      "\n",
      "Epoch:    8/10    Loss: 4.104167380332947\n",
      "\n",
      "Epoch:    8/10    Loss: 3.894073178768158\n",
      "\n",
      "Epoch:    8/10    Loss: 3.9158629846572874\n",
      "\n",
      "Epoch:    8/10    Loss: 3.9375411319732665\n",
      "\n",
      "Epoch:    8/10    Loss: 3.802137408256531\n",
      "\n",
      "Epoch:    8/10    Loss: 3.5739881205558777\n",
      "\n",
      "Epoch:    8/10    Loss: 3.873975715637207\n",
      "\n",
      "Epoch:    8/10    Loss: 3.864294089078903\n",
      "\n",
      "Epoch:    8/10    Loss: 3.8134625148773194\n",
      "\n",
      "Epoch:    8/10    Loss: 4.140632779598236\n",
      "\n",
      "Epoch:    8/10    Loss: 3.9109615874290466\n",
      "\n",
      "Epoch:    8/10    Loss: 3.8764065670967103\n",
      "\n",
      "Epoch:    8/10    Loss: 3.714884033203125\n",
      "\n",
      "Epoch:    8/10    Loss: 3.8074522185325623\n",
      "\n",
      "Epoch:    8/10    Loss: 4.115267255306244\n",
      "\n",
      "Epoch:    8/10    Loss: 4.089309620857239\n",
      "\n",
      "Epoch:    8/10    Loss: 3.865329818725586\n",
      "\n",
      "Epoch:    8/10    Loss: 4.06614022731781\n",
      "\n",
      "Epoch:    8/10    Loss: 4.114421911239624\n",
      "\n",
      "Epoch:    8/10    Loss: 4.147969665527344\n",
      "\n",
      "Epoch:    8/10    Loss: 4.081431882381439\n",
      "\n",
      "Epoch:    8/10    Loss: 4.111892023086548\n",
      "\n",
      "Epoch:    8/10    Loss: 3.8581157433986664\n",
      "\n",
      "Epoch:    8/10    Loss: 3.9208530950546265\n",
      "\n",
      "Epoch:    8/10    Loss: 3.843300039768219\n",
      "\n",
      "Epoch:    8/10    Loss: 3.8752533864974974\n",
      "\n",
      "Epoch:    8/10    Loss: 3.920179843902588\n",
      "\n",
      "Epoch:    8/10    Loss: 4.0939974999427795\n",
      "\n",
      "Epoch:    8/10    Loss: 4.012771754264832\n",
      "\n",
      "Epoch:    8/10    Loss: 3.8107118511199953\n",
      "\n",
      "Epoch:    8/10    Loss: 4.1955332493782045\n",
      "\n",
      "Epoch:    8/10    Loss: 4.01216756105423\n",
      "\n",
      "Epoch:    8/10    Loss: 3.7019142842292787\n",
      "\n",
      "Epoch:    8/10    Loss: 4.043524866104126\n",
      "\n",
      "Epoch:    8/10    Loss: 4.064097173213959\n",
      "\n",
      "Epoch:    8/10    Loss: 3.787976896762848\n",
      "\n",
      "Epoch:    8/10    Loss: 4.10702620267868\n",
      "\n",
      "Epoch:    8/10    Loss: 3.8636493611335756\n",
      "\n",
      "Epoch:    8/10    Loss: 4.287245461940765\n",
      "\n",
      "Epoch:    8/10    Loss: 3.9811467576026915\n",
      "\n",
      "Epoch:    8/10    Loss: 3.9447302055358886\n",
      "\n",
      "Epoch:    8/10    Loss: 3.845063169002533\n",
      "\n",
      "Epoch:    8/10    Loss: 3.9981556296348573\n",
      "\n",
      "Epoch:    8/10    Loss: 3.8988564348220827\n",
      "\n",
      "Epoch:    8/10    Loss: 4.019302365779876\n",
      "\n",
      "Epoch:    8/10    Loss: 3.9741055536270142\n",
      "\n",
      "Epoch:    8/10    Loss: 3.908638799190521\n",
      "\n",
      "Epoch:    8/10    Loss: 3.832816343307495\n",
      "\n",
      "Epoch:    8/10    Loss: 4.123061692714691\n",
      "\n",
      "Epoch:    8/10    Loss: 4.283720991611481\n",
      "\n",
      "Epoch:    8/10    Loss: 3.8827846908569335\n",
      "\n",
      "Epoch:    8/10    Loss: 3.8352401471138\n",
      "\n",
      "Epoch:    8/10    Loss: 3.8035660696029665\n",
      "\n",
      "Epoch:    8/10    Loss: 3.7586476600170133\n",
      "\n",
      "Epoch:    8/10    Loss: 4.180987876653671\n",
      "\n",
      "Epoch:    8/10    Loss: 3.9658460807800293\n",
      "\n",
      "Epoch:    8/10    Loss: 3.962348234653473\n",
      "\n",
      "Epoch:    8/10    Loss: 3.9987332344055178\n",
      "\n",
      "Epoch:    8/10    Loss: 4.096461985111237\n",
      "\n",
      "Epoch:    8/10    Loss: 3.9345169138908385\n",
      "\n",
      "Epoch:    8/10    Loss: 3.6675710773468015\n",
      "\n",
      "Epoch:    8/10    Loss: 3.9201942217350005\n",
      "\n",
      "Epoch:    8/10    Loss: 3.9340133929252623\n",
      "\n",
      "Epoch:    8/10    Loss: 3.7904568910598755\n",
      "\n",
      "Epoch:    8/10    Loss: 3.72972722530365\n",
      "\n",
      "Epoch:    8/10    Loss: 3.882819268703461\n",
      "\n",
      "Epoch:    8/10    Loss: 4.1899300479888915\n",
      "\n",
      "Epoch:    8/10    Loss: 4.054657168388367\n",
      "\n",
      "Epoch:    8/10    Loss: 4.024472296237946\n",
      "\n",
      "Epoch:    8/10    Loss: 3.857900598049164\n",
      "\n",
      "Epoch:    8/10    Loss: 3.7382996535301207\n",
      "\n",
      "Epoch:    8/10    Loss: 3.666103994846344\n",
      "\n",
      "Epoch:    8/10    Loss: 3.8902234089374543\n",
      "\n",
      "Epoch:    8/10    Loss: 3.7398801386356353\n",
      "\n",
      "Epoch:    8/10    Loss: 3.7646707212924957\n",
      "\n",
      "Epoch:    8/10    Loss: 4.5511677765846255\n",
      "\n",
      "Epoch:    9/10    Loss: 4.0591341565164285\n",
      "\n",
      "Epoch:    9/10    Loss: 3.8390234184265135\n",
      "\n",
      "Epoch:    9/10    Loss: 3.585877196788788\n",
      "\n",
      "Epoch:    9/10    Loss: 3.8181075716018675\n",
      "\n",
      "Epoch:    9/10    Loss: 3.6042710447311403\n",
      "\n",
      "Epoch:    9/10    Loss: 3.599912099838257\n",
      "\n",
      "Epoch:    9/10    Loss: 3.775669140815735\n",
      "\n",
      "Epoch:    9/10    Loss: 3.6935732793807983\n",
      "\n",
      "Epoch:    9/10    Loss: 3.8125367617607115\n",
      "\n",
      "Epoch:    9/10    Loss: 3.5984618353843687\n",
      "\n",
      "Epoch:    9/10    Loss: 3.871031677722931\n",
      "\n",
      "Epoch:    9/10    Loss: 3.735847190618515\n",
      "\n",
      "Epoch:    9/10    Loss: 3.808157641887665\n",
      "\n",
      "Epoch:    9/10    Loss: 3.5279740929603576\n",
      "\n",
      "Epoch:    9/10    Loss: 3.789936443567276\n",
      "\n",
      "Epoch:    9/10    Loss: 3.813058934211731\n",
      "\n",
      "Epoch:    9/10    Loss: 3.6093190729618074\n",
      "\n",
      "Epoch:    9/10    Loss: 3.861471030712128\n",
      "\n",
      "Epoch:    9/10    Loss: 3.762738564014435\n",
      "\n",
      "Epoch:    9/10    Loss: 3.864857749938965\n",
      "\n",
      "Epoch:    9/10    Loss: 3.5498455536365507\n",
      "\n",
      "Epoch:    9/10    Loss: 3.7131807684898375\n",
      "\n",
      "Epoch:    9/10    Loss: 3.8622367429733275\n",
      "\n",
      "Epoch:    9/10    Loss: 3.7535405731201172\n",
      "\n",
      "Epoch:    9/10    Loss: 3.737699735164642\n",
      "\n",
      "Epoch:    9/10    Loss: 4.059069175720214\n",
      "\n",
      "Epoch:    9/10    Loss: 3.655235824584961\n",
      "\n",
      "Epoch:    9/10    Loss: 3.9766817331314086\n",
      "\n",
      "Epoch:    9/10    Loss: 3.746279842853546\n",
      "\n",
      "Epoch:    9/10    Loss: 3.4819319152832033\n",
      "\n",
      "Epoch:    9/10    Loss: 3.947806978225708\n",
      "\n",
      "Epoch:    9/10    Loss: 3.6273391747474673\n",
      "\n",
      "Epoch:    9/10    Loss: 4.212917988300323\n",
      "\n",
      "Epoch:    9/10    Loss: 3.949087600708008\n",
      "\n",
      "Epoch:    9/10    Loss: 3.660355727672577\n",
      "\n",
      "Epoch:    9/10    Loss: 3.617965557575226\n",
      "\n",
      "Epoch:    9/10    Loss: 3.5726868879795073\n",
      "\n",
      "Epoch:    9/10    Loss: 3.5469936466217042\n",
      "\n",
      "Epoch:    9/10    Loss: 3.6400435328483582\n",
      "\n",
      "Epoch:    9/10    Loss: 3.687042620182037\n",
      "\n",
      "Epoch:    9/10    Loss: 3.46469309091568\n",
      "\n",
      "Epoch:    9/10    Loss: 3.5040004062652588\n",
      "\n",
      "Epoch:    9/10    Loss: 3.7820124793052674\n",
      "\n",
      "Epoch:    9/10    Loss: 3.72318674325943\n",
      "\n",
      "Epoch:    9/10    Loss: 4.226626121997834\n",
      "\n",
      "Epoch:    9/10    Loss: 3.8209627962112425\n",
      "\n",
      "Epoch:    9/10    Loss: 3.6749300956726074\n",
      "\n",
      "Epoch:    9/10    Loss: 3.892835338115692\n",
      "\n",
      "Epoch:    9/10    Loss: 3.4516180980205537\n",
      "\n",
      "Epoch:    9/10    Loss: 3.682260398864746\n",
      "\n",
      "Epoch:    9/10    Loss: 3.775863919258118\n",
      "\n",
      "Epoch:    9/10    Loss: 3.7421197593212128\n",
      "\n",
      "Epoch:    9/10    Loss: 3.8882277500629425\n",
      "\n",
      "Epoch:    9/10    Loss: 3.7704327058792115\n",
      "\n",
      "Epoch:    9/10    Loss: 3.726676309108734\n",
      "\n",
      "Epoch:    9/10    Loss: 3.7252539682388304\n",
      "\n",
      "Epoch:    9/10    Loss: 3.5034665071964266\n",
      "\n",
      "Epoch:    9/10    Loss: 3.487762099504471\n",
      "\n",
      "Epoch:    9/10    Loss: 3.4047450721263885\n",
      "\n",
      "Epoch:    9/10    Loss: 3.589611701965332\n",
      "\n",
      "Epoch:    9/10    Loss: 3.9080785632133486\n",
      "\n",
      "Epoch:    9/10    Loss: 3.7936856245994566\n",
      "\n",
      "Epoch:    9/10    Loss: 3.7552615892887116\n",
      "\n",
      "Epoch:    9/10    Loss: 3.459610925912857\n",
      "\n",
      "Epoch:    9/10    Loss: 3.531214747428894\n",
      "\n",
      "Epoch:    9/10    Loss: 3.6491897177696226\n",
      "\n",
      "Epoch:    9/10    Loss: 3.503668831586838\n",
      "\n",
      "Epoch:    9/10    Loss: 3.7759575664997103\n",
      "\n",
      "Epoch:    9/10    Loss: 3.468374049663544\n",
      "\n",
      "Epoch:    9/10    Loss: 3.539310643672943\n",
      "\n",
      "Epoch:    9/10    Loss: 3.607284891605377\n",
      "\n",
      "Epoch:    9/10    Loss: 3.6311258101463317\n",
      "\n",
      "Epoch:    9/10    Loss: 3.5758835709095003\n",
      "\n",
      "Epoch:    9/10    Loss: 3.756643521785736\n",
      "\n",
      "Epoch:    9/10    Loss: 3.725465259552002\n",
      "\n",
      "Epoch:    9/10    Loss: 3.548791723251343\n",
      "\n",
      "Epoch:    9/10    Loss: 3.7934831833839415\n",
      "\n",
      "Epoch:    9/10    Loss: 3.466099030971527\n",
      "\n",
      "Epoch:    9/10    Loss: 3.5741730451583864\n",
      "\n",
      "Epoch:    9/10    Loss: 4.1268632173538204\n",
      "\n",
      "Epoch:    9/10    Loss: 3.588672566413879\n",
      "\n",
      "Epoch:    9/10    Loss: 4.276371011734009\n",
      "\n",
      "Epoch:    9/10    Loss: 3.9976945734024047\n",
      "\n",
      "Epoch:    9/10    Loss: 3.643185966014862\n",
      "\n",
      "Epoch:    9/10    Loss: 3.6112945961952208\n",
      "\n",
      "Epoch:    9/10    Loss: 3.651074550151825\n",
      "\n",
      "Epoch:    9/10    Loss: 3.927689094543457\n",
      "\n",
      "Epoch:    9/10    Loss: 4.093679709434509\n",
      "\n",
      "Epoch:    9/10    Loss: 3.9561207914352416\n",
      "\n",
      "Epoch:    9/10    Loss: 3.62919771194458\n",
      "\n",
      "Epoch:    9/10    Loss: 3.89012558221817\n",
      "\n",
      "Epoch:    9/10    Loss: 3.7575568652153013\n",
      "\n",
      "Epoch:    9/10    Loss: 3.833622817993164\n",
      "\n",
      "Epoch:    9/10    Loss: 3.62988361120224\n",
      "\n",
      "Epoch:    9/10    Loss: 3.7371120405197145\n",
      "\n",
      "Epoch:    9/10    Loss: 3.741227395534515\n",
      "\n",
      "Epoch:    9/10    Loss: 3.702687314748764\n",
      "\n",
      "Epoch:    9/10    Loss: 3.9019901585578918\n",
      "\n",
      "Epoch:    9/10    Loss: 3.5429184651374817\n",
      "\n",
      "Epoch:    9/10    Loss: 3.600490508079529\n",
      "\n",
      "Epoch:    9/10    Loss: 3.774055712223053\n",
      "\n",
      "Epoch:    9/10    Loss: 3.6005471289157867\n",
      "\n",
      "Epoch:    9/10    Loss: 3.6132179737091064\n",
      "\n",
      "Epoch:    9/10    Loss: 3.713199609518051\n",
      "\n",
      "Epoch:    9/10    Loss: 4.039977295398712\n",
      "\n",
      "Epoch:    9/10    Loss: 4.170540585517883\n",
      "\n",
      "Epoch:    9/10    Loss: 4.01163400888443\n",
      "\n",
      "Epoch:    9/10    Loss: 3.667710907459259\n",
      "\n",
      "Epoch:    9/10    Loss: 3.5793376636505125\n",
      "\n",
      "Epoch:    9/10    Loss: 3.912708914279938\n",
      "\n",
      "Epoch:    9/10    Loss: 3.8991321289539336\n",
      "\n",
      "Epoch:    9/10    Loss: 3.8131132984161376\n",
      "\n",
      "Epoch:    9/10    Loss: 3.7438052344322204\n",
      "\n",
      "Epoch:    9/10    Loss: 3.7439712536334993\n",
      "\n",
      "Epoch:    9/10    Loss: 4.034343256950378\n",
      "\n",
      "Epoch:    9/10    Loss: 3.918796557188034\n",
      "\n",
      "Epoch:    9/10    Loss: 3.9472084426879883\n",
      "\n",
      "Epoch:    9/10    Loss: 3.808142523765564\n",
      "\n",
      "Epoch:    9/10    Loss: 4.087379810810089\n",
      "\n",
      "Epoch:    9/10    Loss: 4.059073519706726\n",
      "\n",
      "Epoch:    9/10    Loss: 3.9464168453216555\n",
      "\n",
      "Epoch:    9/10    Loss: 3.822967550754547\n",
      "\n",
      "Epoch:    9/10    Loss: 4.032075867652893\n",
      "\n",
      "Epoch:    9/10    Loss: 3.826706726551056\n",
      "\n",
      "Epoch:    9/10    Loss: 3.6861906814575196\n",
      "\n",
      "Epoch:    9/10    Loss: 3.478207817077637\n",
      "\n",
      "Epoch:    9/10    Loss: 3.8554224801063537\n",
      "\n",
      "Epoch:    9/10    Loss: 3.8044934844970704\n",
      "\n",
      "Epoch:    9/10    Loss: 3.7913006019592284\n",
      "\n",
      "Epoch:    9/10    Loss: 3.9702923464775086\n",
      "\n",
      "Epoch:    9/10    Loss: 4.0154727888107296\n",
      "\n",
      "Epoch:    9/10    Loss: 3.6745469880104067\n",
      "\n",
      "Epoch:    9/10    Loss: 3.8798272728919985\n",
      "\n",
      "Epoch:    9/10    Loss: 3.8152820253372193\n",
      "\n",
      "Epoch:    9/10    Loss: 3.8952218770980833\n",
      "\n",
      "Epoch:    9/10    Loss: 3.7614475417137148\n",
      "\n",
      "Epoch:    9/10    Loss: 3.7229736113548277\n",
      "\n",
      "Epoch:    9/10    Loss: 3.8019090461730958\n",
      "\n",
      "Epoch:    9/10    Loss: 3.7426905715465546\n",
      "\n",
      "Epoch:    9/10    Loss: 3.6196494460105897\n",
      "\n",
      "Epoch:    9/10    Loss: 3.6068169188499453\n",
      "\n",
      "Epoch:    9/10    Loss: 3.596879620552063\n",
      "\n",
      "Epoch:    9/10    Loss: 3.809317936897278\n",
      "\n",
      "Epoch:    9/10    Loss: 3.8828101325035096\n",
      "\n",
      "Epoch:    9/10    Loss: 3.5880997943878175\n",
      "\n",
      "Epoch:    9/10    Loss: 3.9334724521636963\n",
      "\n",
      "Epoch:    9/10    Loss: 3.6562642776966094\n",
      "\n",
      "Epoch:    9/10    Loss: 4.050003044605255\n",
      "\n",
      "Epoch:    9/10    Loss: 3.6256459951400757\n",
      "\n",
      "Epoch:    9/10    Loss: 4.023102912902832\n",
      "\n",
      "Epoch:    9/10    Loss: 4.133693814277649\n",
      "\n",
      "Epoch:    9/10    Loss: 3.8836334800720214\n",
      "\n",
      "Epoch:    9/10    Loss: 3.7071325278282163\n",
      "\n",
      "Epoch:    9/10    Loss: 3.657211217880249\n",
      "\n",
      "Epoch:    9/10    Loss: 3.654762576818466\n",
      "\n",
      "Epoch:    9/10    Loss: 3.6768213963508605\n",
      "\n",
      "Epoch:    9/10    Loss: 3.7497769808769226\n",
      "\n",
      "Epoch:    9/10    Loss: 3.425058226585388\n",
      "\n",
      "Epoch:    9/10    Loss: 3.630604348182678\n",
      "\n",
      "Epoch:    9/10    Loss: 3.5493542230129242\n",
      "\n",
      "Epoch:    9/10    Loss: 3.7147231245040895\n",
      "\n",
      "Epoch:    9/10    Loss: 3.5270918655395507\n",
      "\n",
      "Epoch:    9/10    Loss: 3.5637865269184115\n",
      "\n",
      "Epoch:    9/10    Loss: 3.896558773517609\n",
      "\n",
      "Epoch:    9/10    Loss: 3.5693855714797973\n",
      "\n",
      "Epoch:    9/10    Loss: 3.7310979628562926\n",
      "\n",
      "Epoch:    9/10    Loss: 3.8362567615509033\n",
      "\n",
      "Epoch:    9/10    Loss: 3.736277823448181\n",
      "\n",
      "Epoch:    9/10    Loss: 4.182810709476471\n",
      "\n",
      "Epoch:    9/10    Loss: 3.4742268180847167\n",
      "\n",
      "Epoch:    9/10    Loss: 3.3999506413936613\n",
      "\n",
      "Epoch:    9/10    Loss: 3.753873360157013\n",
      "\n",
      "Epoch:    9/10    Loss: 3.779221566915512\n",
      "\n",
      "Epoch:    9/10    Loss: 3.8696613550186156\n",
      "\n",
      "Epoch:    9/10    Loss: 3.984247899055481\n",
      "\n",
      "Epoch:    9/10    Loss: 3.9444052290916445\n",
      "\n",
      "Epoch:    9/10    Loss: 3.8117197442054747\n",
      "\n",
      "Epoch:    9/10    Loss: 3.691599556207657\n",
      "\n",
      "Epoch:    9/10    Loss: 3.505674500465393\n",
      "\n",
      "Epoch:    9/10    Loss: 3.925866448879242\n",
      "\n",
      "Epoch:    9/10    Loss: 3.7766475558280943\n",
      "\n",
      "Epoch:    9/10    Loss: 3.8120592260360717\n",
      "\n",
      "Epoch:    9/10    Loss: 3.7723011922836305\n",
      "\n",
      "Epoch:    9/10    Loss: 3.6257917618751527\n",
      "\n",
      "Epoch:    9/10    Loss: 3.8166839933395384\n",
      "\n",
      "Epoch:    9/10    Loss: 3.6318608498573304\n",
      "\n",
      "Epoch:    9/10    Loss: 3.5503652691841125\n",
      "\n",
      "Epoch:    9/10    Loss: 3.872490572929382\n",
      "\n",
      "Epoch:    9/10    Loss: 3.899750249385834\n",
      "\n",
      "Epoch:    9/10    Loss: 3.6707262110710146\n",
      "\n",
      "Epoch:    9/10    Loss: 3.8013638854026794\n",
      "\n",
      "Epoch:    9/10    Loss: 3.3311122035980225\n",
      "\n",
      "Epoch:    9/10    Loss: 3.5972837150096892\n",
      "\n",
      "Epoch:    9/10    Loss: 3.697744839191437\n",
      "\n",
      "Epoch:    9/10    Loss: 3.9177530431747436\n",
      "\n",
      "Epoch:    9/10    Loss: 3.651666233539581\n",
      "\n",
      "Epoch:    9/10    Loss: 3.7828656530380247\n",
      "\n",
      "Epoch:    9/10    Loss: 3.6734428095817564\n",
      "\n",
      "Epoch:    9/10    Loss: 3.5410819816589356\n",
      "\n",
      "Epoch:    9/10    Loss: 3.664488339424133\n",
      "\n",
      "Epoch:    9/10    Loss: 3.862443919181824\n",
      "\n",
      "Epoch:    9/10    Loss: 3.7903792548179625\n",
      "\n",
      "Epoch:    9/10    Loss: 4.053257482051849\n",
      "\n",
      "Epoch:    9/10    Loss: 3.8335649609565734\n",
      "\n",
      "Epoch:    9/10    Loss: 3.8976759839057924\n",
      "\n",
      "Epoch:    9/10    Loss: 3.880084042549133\n",
      "\n",
      "Epoch:    9/10    Loss: 3.79130765914917\n",
      "\n",
      "Epoch:    9/10    Loss: 3.5644231057167053\n",
      "\n",
      "Epoch:    9/10    Loss: 3.8344971632957456\n",
      "\n",
      "Epoch:    9/10    Loss: 3.8492992615699766\n",
      "\n",
      "Epoch:    9/10    Loss: 3.7475484514236452\n",
      "\n",
      "Epoch:    9/10    Loss: 4.111188199520111\n",
      "\n",
      "Epoch:    9/10    Loss: 3.85946236371994\n",
      "\n",
      "Epoch:    9/10    Loss: 3.836053373813629\n",
      "\n",
      "Epoch:    9/10    Loss: 3.68850555896759\n",
      "\n",
      "Epoch:    9/10    Loss: 3.805258643627167\n",
      "\n",
      "Epoch:    9/10    Loss: 4.097342066764831\n",
      "\n",
      "Epoch:    9/10    Loss: 4.071876134872436\n",
      "\n",
      "Epoch:    9/10    Loss: 3.8489938235282897\n",
      "\n",
      "Epoch:    9/10    Loss: 4.029982028007507\n",
      "\n",
      "Epoch:    9/10    Loss: 4.09651370048523\n",
      "\n",
      "Epoch:    9/10    Loss: 4.154222507476806\n",
      "\n",
      "Epoch:    9/10    Loss: 4.04123494386673\n",
      "\n",
      "Epoch:    9/10    Loss: 4.099061992168426\n",
      "\n",
      "Epoch:    9/10    Loss: 3.8478837704658506\n",
      "\n",
      "Epoch:    9/10    Loss: 3.905672187805176\n",
      "\n",
      "Epoch:    9/10    Loss: 3.800404188632965\n",
      "\n",
      "Epoch:    9/10    Loss: 3.83360018491745\n",
      "\n",
      "Epoch:    9/10    Loss: 3.8894060277938842\n",
      "\n",
      "Epoch:    9/10    Loss: 4.040243365764618\n",
      "\n",
      "Epoch:    9/10    Loss: 3.9641849756240846\n",
      "\n",
      "Epoch:    9/10    Loss: 3.7979714345932005\n",
      "\n",
      "Epoch:    9/10    Loss: 4.124786326885223\n",
      "\n",
      "Epoch:    9/10    Loss: 3.9645164716243744\n",
      "\n",
      "Epoch:    9/10    Loss: 3.675429883003235\n",
      "\n",
      "Epoch:    9/10    Loss: 4.015698149204254\n",
      "\n",
      "Epoch:    9/10    Loss: 4.0264992022514345\n",
      "\n",
      "Epoch:    9/10    Loss: 3.7902261281013487\n",
      "\n",
      "Epoch:    9/10    Loss: 4.099701817035675\n",
      "\n",
      "Epoch:    9/10    Loss: 3.843028209209442\n",
      "\n",
      "Epoch:    9/10    Loss: 4.187702040672303\n",
      "\n",
      "Epoch:    9/10    Loss: 3.9301480317115782\n",
      "\n",
      "Epoch:    9/10    Loss: 3.9298646688461303\n",
      "\n",
      "Epoch:    9/10    Loss: 3.8453826880455018\n",
      "\n",
      "Epoch:    9/10    Loss: 3.964716286659241\n",
      "\n",
      "Epoch:    9/10    Loss: 3.8876994478702547\n",
      "\n",
      "Epoch:    9/10    Loss: 3.9932626605033876\n",
      "\n",
      "Epoch:    9/10    Loss: 3.9223874688148497\n",
      "\n",
      "Epoch:    9/10    Loss: 3.834773075580597\n",
      "\n",
      "Epoch:    9/10    Loss: 3.797513208389282\n",
      "\n",
      "Epoch:    9/10    Loss: 4.11458815574646\n",
      "\n",
      "Epoch:    9/10    Loss: 4.242539076805115\n",
      "\n",
      "Epoch:    9/10    Loss: 3.8771351027488707\n",
      "\n",
      "Epoch:    9/10    Loss: 3.8119986510276793\n",
      "\n",
      "Epoch:    9/10    Loss: 3.772782027721405\n",
      "\n",
      "Epoch:    9/10    Loss: 3.7502821254730225\n",
      "\n",
      "Epoch:    9/10    Loss: 4.211082811355591\n",
      "\n",
      "Epoch:    9/10    Loss: 3.929781265258789\n",
      "\n",
      "Epoch:    9/10    Loss: 3.9016984581947325\n",
      "\n",
      "Epoch:    9/10    Loss: 3.9832732033729554\n",
      "\n",
      "Epoch:    9/10    Loss: 4.094381582736969\n",
      "\n",
      "Epoch:    9/10    Loss: 3.9293650674819944\n",
      "\n",
      "Epoch:    9/10    Loss: 3.637740718126297\n",
      "\n",
      "Epoch:    9/10    Loss: 3.926147894859314\n",
      "\n",
      "Epoch:    9/10    Loss: 3.925740456581116\n",
      "\n",
      "Epoch:    9/10    Loss: 3.7448347568511964\n",
      "\n",
      "Epoch:    9/10    Loss: 3.6840347266197204\n",
      "\n",
      "Epoch:    9/10    Loss: 3.884283926486969\n",
      "\n",
      "Epoch:    9/10    Loss: 4.173058640956879\n",
      "\n",
      "Epoch:    9/10    Loss: 4.033311562538147\n",
      "\n",
      "Epoch:    9/10    Loss: 4.023897604942322\n",
      "\n",
      "Epoch:    9/10    Loss: 3.795947482585907\n",
      "\n",
      "Epoch:    9/10    Loss: 3.7391787755489347\n",
      "\n",
      "Epoch:    9/10    Loss: 3.6192234599590303\n",
      "\n",
      "Epoch:    9/10    Loss: 3.8620506918430326\n",
      "\n",
      "Epoch:    9/10    Loss: 3.7519865548610687\n",
      "\n",
      "Epoch:    9/10    Loss: 3.7639850211143493\n",
      "\n",
      "Epoch:    9/10    Loss: 4.50941116809845\n",
      "\n",
      "Epoch:   10/10    Loss: 4.040574334980397\n",
      "\n",
      "Epoch:   10/10    Loss: 3.8210527515411377\n",
      "\n",
      "Epoch:   10/10    Loss: 3.5483458709716795\n",
      "\n",
      "Epoch:   10/10    Loss: 3.8092050170898437\n",
      "\n",
      "Epoch:   10/10    Loss: 3.5626332747936247\n",
      "\n",
      "Epoch:   10/10    Loss: 3.570144399404526\n",
      "\n",
      "Epoch:   10/10    Loss: 3.763919780254364\n",
      "\n",
      "Epoch:   10/10    Loss: 3.696351625919342\n",
      "\n",
      "Epoch:   10/10    Loss: 3.787401393651962\n",
      "\n",
      "Epoch:   10/10    Loss: 3.5740595853328703\n",
      "\n",
      "Epoch:   10/10    Loss: 3.8477073645591737\n",
      "\n",
      "Epoch:   10/10    Loss: 3.730479259490967\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7685395789146425\n",
      "\n",
      "Epoch:   10/10    Loss: 3.5088766741752626\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7251935625076293\n",
      "\n",
      "Epoch:   10/10    Loss: 3.788134278059006\n",
      "\n",
      "Epoch:   10/10    Loss: 3.552140234708786\n",
      "\n",
      "Epoch:   10/10    Loss: 3.835626332759857\n",
      "\n",
      "Epoch:   10/10    Loss: 3.684829924106598\n",
      "\n",
      "Epoch:   10/10    Loss: 3.8780205821990967\n",
      "\n",
      "Epoch:   10/10    Loss: 3.562948440313339\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7301191163063048\n",
      "\n",
      "Epoch:   10/10    Loss: 3.8340789437294007\n",
      "\n",
      "Epoch:   10/10    Loss: 3.6897983050346372\n",
      "\n",
      "Epoch:   10/10    Loss: 3.6953789687156675\n",
      "\n",
      "Epoch:   10/10    Loss: 4.032787315845489\n",
      "\n",
      "Epoch:   10/10    Loss: 3.6305841493606565\n",
      "\n",
      "Epoch:   10/10    Loss: 3.9670827460289\n",
      "\n",
      "Epoch:   10/10    Loss: 3.731531182527542\n",
      "\n",
      "Epoch:   10/10    Loss: 3.4583752036094664\n",
      "\n",
      "Epoch:   10/10    Loss: 3.9337434124946595\n",
      "\n",
      "Epoch:   10/10    Loss: 3.580233850479126\n",
      "\n",
      "Epoch:   10/10    Loss: 4.192625064849853\n",
      "\n",
      "Epoch:   10/10    Loss: 3.9153889298439024\n",
      "\n",
      "Epoch:   10/10    Loss: 3.590588128566742\n",
      "\n",
      "Epoch:   10/10    Loss: 3.57210643529892\n",
      "\n",
      "Epoch:   10/10    Loss: 3.529153562784195\n",
      "\n",
      "Epoch:   10/10    Loss: 3.527687153816223\n",
      "\n",
      "Epoch:   10/10    Loss: 3.58818172454834\n",
      "\n",
      "Epoch:   10/10    Loss: 3.6857396471500397\n",
      "\n",
      "Epoch:   10/10    Loss: 3.4530113554000854\n",
      "\n",
      "Epoch:   10/10    Loss: 3.533901529312134\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7407655346393587\n",
      "\n",
      "Epoch:   10/10    Loss: 3.6760908198356628\n",
      "\n",
      "Epoch:   10/10    Loss: 4.206943564414978\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7932900524139406\n",
      "\n",
      "Epoch:   10/10    Loss: 3.6784124302864076\n",
      "\n",
      "Epoch:   10/10    Loss: 3.86305091381073\n",
      "\n",
      "Epoch:   10/10    Loss: 3.3946518123149874\n",
      "\n",
      "Epoch:   10/10    Loss: 3.6702459764480593\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7666958928108216\n",
      "\n",
      "Epoch:   10/10    Loss: 3.746529904603958\n",
      "\n",
      "Epoch:   10/10    Loss: 3.8794218373298643\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7395270538330077\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7150623989105225\n",
      "\n",
      "Epoch:   10/10    Loss: 3.6912281942367553\n",
      "\n",
      "Epoch:   10/10    Loss: 3.503893747329712\n",
      "\n",
      "Epoch:   10/10    Loss: 3.475577690601349\n",
      "\n",
      "Epoch:   10/10    Loss: 3.403339601755142\n",
      "\n",
      "Epoch:   10/10    Loss: 3.575008592605591\n",
      "\n",
      "Epoch:   10/10    Loss: 3.817392017841339\n",
      "\n",
      "Epoch:   10/10    Loss: 3.794649519920349\n",
      "\n",
      "Epoch:   10/10    Loss: 3.743211976289749\n",
      "\n",
      "Epoch:   10/10    Loss: 3.4288044393062593\n",
      "\n",
      "Epoch:   10/10    Loss: 3.506740859746933\n",
      "\n",
      "Epoch:   10/10    Loss: 3.6614944064617156\n",
      "\n",
      "Epoch:   10/10    Loss: 3.46362841963768\n",
      "\n",
      "Epoch:   10/10    Loss: 3.732381998300552\n",
      "\n",
      "Epoch:   10/10    Loss: 3.45453449010849\n",
      "\n",
      "Epoch:   10/10    Loss: 3.521146706342697\n",
      "\n",
      "Epoch:   10/10    Loss: 3.552443459033966\n",
      "\n",
      "Epoch:   10/10    Loss: 3.5975146532058715\n",
      "\n",
      "Epoch:   10/10    Loss: 3.5366781771183016\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7321396970748903\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7017106366157533\n",
      "\n",
      "Epoch:   10/10    Loss: 3.5464938843250273\n",
      "\n",
      "Epoch:   10/10    Loss: 3.8247346901893615\n",
      "\n",
      "Epoch:   10/10    Loss: 3.469663782119751\n",
      "\n",
      "Epoch:   10/10    Loss: 3.546140116453171\n",
      "\n",
      "Epoch:   10/10    Loss: 4.078889882564544\n",
      "\n",
      "Epoch:   10/10    Loss: 3.5651593089103697\n",
      "\n",
      "Epoch:   10/10    Loss: 4.253383123874665\n",
      "\n",
      "Epoch:   10/10    Loss: 3.951119737625122\n",
      "\n",
      "Epoch:   10/10    Loss: 3.654824936389923\n",
      "\n",
      "Epoch:   10/10    Loss: 3.5953862833976746\n",
      "\n",
      "Epoch:   10/10    Loss: 3.619556231498718\n",
      "\n",
      "Epoch:   10/10    Loss: 3.870145938396454\n",
      "\n",
      "Epoch:   10/10    Loss: 4.054004356861115\n",
      "\n",
      "Epoch:   10/10    Loss: 3.918513834476471\n",
      "\n",
      "Epoch:   10/10    Loss: 3.6068378043174745\n",
      "\n",
      "Epoch:   10/10    Loss: 3.8588307332992553\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7058191108703613\n",
      "\n",
      "Epoch:   10/10    Loss: 3.816965525150299\n",
      "\n",
      "Epoch:   10/10    Loss: 3.5660431456565855\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7233687663078308\n",
      "\n",
      "Epoch:   10/10    Loss: 3.6926422834396364\n",
      "\n",
      "Epoch:   10/10    Loss: 3.659981540441513\n",
      "\n",
      "Epoch:   10/10    Loss: 3.8365335774421694\n",
      "\n",
      "Epoch:   10/10    Loss: 3.528584290742874\n",
      "\n",
      "Epoch:   10/10    Loss: 3.549066412448883\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7547181963920595\n",
      "\n",
      "Epoch:   10/10    Loss: 3.5879805982112885\n",
      "\n",
      "Epoch:   10/10    Loss: 3.620124485492706\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7252870976924894\n",
      "\n",
      "Epoch:   10/10    Loss: 4.042236087322235\n",
      "\n",
      "Epoch:   10/10    Loss: 4.113892869949341\n",
      "\n",
      "Epoch:   10/10    Loss: 3.969905010461807\n",
      "\n",
      "Epoch:   10/10    Loss: 3.6294664120674134\n",
      "\n",
      "Epoch:   10/10    Loss: 3.5380725979804994\n",
      "\n",
      "Epoch:   10/10    Loss: 3.9039947736263274\n",
      "\n",
      "Epoch:   10/10    Loss: 3.8614374566078187\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7448212087154387\n",
      "\n",
      "Epoch:   10/10    Loss: 3.70273921251297\n",
      "\n",
      "Epoch:   10/10    Loss: 3.744062684774399\n",
      "\n",
      "Epoch:   10/10    Loss: 3.9544066762924195\n",
      "\n",
      "Epoch:   10/10    Loss: 3.898002462387085\n",
      "\n",
      "Epoch:   10/10    Loss: 3.9471908617019653\n",
      "\n",
      "Epoch:   10/10    Loss: 3.8113783502578737\n",
      "\n",
      "Epoch:   10/10    Loss: 4.066576334238053\n",
      "\n",
      "Epoch:   10/10    Loss: 4.0542736864089965\n",
      "\n",
      "Epoch:   10/10    Loss: 3.92082080245018\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7861023116111756\n",
      "\n",
      "Epoch:   10/10    Loss: 4.027726223468781\n",
      "\n",
      "Epoch:   10/10    Loss: 3.8329994606971742\n",
      "\n",
      "Epoch:   10/10    Loss: 3.6523229765892027\n",
      "\n",
      "Epoch:   10/10    Loss: 3.4583111071586607\n",
      "\n",
      "Epoch:   10/10    Loss: 3.871127347946167\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7985035157203675\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7895352733135224\n",
      "\n",
      "Epoch:   10/10    Loss: 3.9157429575920104\n",
      "\n",
      "Epoch:   10/10    Loss: 3.9357020974159242\n",
      "\n",
      "Epoch:   10/10    Loss: 3.6236236095428467\n",
      "\n",
      "Epoch:   10/10    Loss: 3.851636703014374\n",
      "\n",
      "Epoch:   10/10    Loss: 3.774582405090332\n",
      "\n",
      "Epoch:   10/10    Loss: 3.877156777381897\n",
      "\n",
      "Epoch:   10/10    Loss: 3.724085512161255\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7450370812416076\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7615294098854064\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7420812153816225\n",
      "\n",
      "Epoch:   10/10    Loss: 3.584795711040497\n",
      "\n",
      "Epoch:   10/10    Loss: 3.5912347376346587\n",
      "\n",
      "Epoch:   10/10    Loss: 3.589767024517059\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7778943085670473\n",
      "\n",
      "Epoch:   10/10    Loss: 3.8658530819416046\n",
      "\n",
      "Epoch:   10/10    Loss: 3.640589966773987\n",
      "\n",
      "Epoch:   10/10    Loss: 3.8984266543388366\n",
      "\n",
      "Epoch:   10/10    Loss: 3.6663346910476684\n",
      "\n",
      "Epoch:   10/10    Loss: 4.0851534700393675\n",
      "\n",
      "Epoch:   10/10    Loss: 3.6347093200683593\n",
      "\n",
      "Epoch:   10/10    Loss: 4.012800765037537\n",
      "\n",
      "Epoch:   10/10    Loss: 4.125494010448456\n",
      "\n",
      "Epoch:   10/10    Loss: 3.853761100769043\n",
      "\n",
      "Epoch:   10/10    Loss: 3.658429539203644\n",
      "\n",
      "Epoch:   10/10    Loss: 3.6463000428676606\n",
      "\n",
      "Epoch:   10/10    Loss: 3.6348623096942902\n",
      "\n",
      "Epoch:   10/10    Loss: 3.652858282327652\n",
      "\n",
      "Epoch:   10/10    Loss: 3.710113320350647\n",
      "\n",
      "Epoch:   10/10    Loss: 3.401630792617798\n",
      "\n",
      "Epoch:   10/10    Loss: 3.564397532939911\n",
      "\n",
      "Epoch:   10/10    Loss: 3.5427733182907106\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7027396368980408\n",
      "\n",
      "Epoch:   10/10    Loss: 3.489985008239746\n",
      "\n",
      "Epoch:   10/10    Loss: 3.529745535850525\n",
      "\n",
      "Epoch:   10/10    Loss: 3.8610380268096924\n",
      "\n",
      "Epoch:   10/10    Loss: 3.5124510407447813\n",
      "\n",
      "Epoch:   10/10    Loss: 3.6669191265106202\n",
      "\n",
      "Epoch:   10/10    Loss: 3.8295387506484984\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7026738023757932\n",
      "\n",
      "Epoch:   10/10    Loss: 4.134010753631592\n",
      "\n",
      "Epoch:   10/10    Loss: 3.451793433427811\n",
      "\n",
      "Epoch:   10/10    Loss: 3.4209880423545838\n",
      "\n",
      "Epoch:   10/10    Loss: 3.719071636199951\n",
      "\n",
      "Epoch:   10/10    Loss: 3.738804486989975\n",
      "\n",
      "Epoch:   10/10    Loss: 3.828900578022003\n",
      "\n",
      "Epoch:   10/10    Loss: 3.96343120098114\n",
      "\n",
      "Epoch:   10/10    Loss: 3.935344421863556\n",
      "\n",
      "Epoch:   10/10    Loss: 3.8023520040512087\n",
      "\n",
      "Epoch:   10/10    Loss: 3.657716827392578\n",
      "\n",
      "Epoch:   10/10    Loss: 3.46482525229454\n",
      "\n",
      "Epoch:   10/10    Loss: 3.898534779548645\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7291856837272643\n",
      "\n",
      "Epoch:   10/10    Loss: 3.794446190595627\n",
      "\n",
      "Epoch:   10/10    Loss: 3.6913259530067446\n",
      "\n",
      "Epoch:   10/10    Loss: 3.5760612630844117\n",
      "\n",
      "Epoch:   10/10    Loss: 3.747000880241394\n",
      "\n",
      "Epoch:   10/10    Loss: 3.636754252910614\n",
      "\n",
      "Epoch:   10/10    Loss: 3.5617201709747315\n",
      "\n",
      "Epoch:   10/10    Loss: 3.835955753326416\n",
      "\n",
      "Epoch:   10/10    Loss: 3.8898705577850343\n",
      "\n",
      "Epoch:   10/10    Loss: 3.6707987999916076\n",
      "\n",
      "Epoch:   10/10    Loss: 3.793826539516449\n",
      "\n",
      "Epoch:   10/10    Loss: 3.286093556880951\n",
      "\n",
      "Epoch:   10/10    Loss: 3.600814768075943\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7299407148361206\n",
      "\n",
      "Epoch:   10/10    Loss: 3.8779072093963625\n",
      "\n",
      "Epoch:   10/10    Loss: 3.638928647041321\n",
      "\n",
      "Epoch:   10/10    Loss: 3.771012537479401\n",
      "\n",
      "Epoch:   10/10    Loss: 3.612029939889908\n",
      "\n",
      "Epoch:   10/10    Loss: 3.478804798126221\n",
      "\n",
      "Epoch:   10/10    Loss: 3.662020845413208\n",
      "\n",
      "Epoch:   10/10    Loss: 3.850652980804443\n",
      "\n",
      "Epoch:   10/10    Loss: 3.768945972919464\n",
      "\n",
      "Epoch:   10/10    Loss: 4.02963709115982\n",
      "\n",
      "Epoch:   10/10    Loss: 3.8465182685852053\n",
      "\n",
      "Epoch:   10/10    Loss: 3.881258623600006\n",
      "\n",
      "Epoch:   10/10    Loss: 3.9132477045059204\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7654765677452087\n",
      "\n",
      "Epoch:   10/10    Loss: 3.5467972946166992\n",
      "\n",
      "Epoch:   10/10    Loss: 3.82415620803833\n",
      "\n",
      "Epoch:   10/10    Loss: 3.852082953453064\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7138444709777834\n",
      "\n",
      "Epoch:   10/10    Loss: 4.082243111133575\n",
      "\n",
      "Epoch:   10/10    Loss: 3.841760847568512\n",
      "\n",
      "Epoch:   10/10    Loss: 3.802143025398254\n",
      "\n",
      "Epoch:   10/10    Loss: 3.65228231549263\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7535015988349913\n",
      "\n",
      "Epoch:   10/10    Loss: 4.106482181549072\n",
      "\n",
      "Epoch:   10/10    Loss: 4.056833634376526\n",
      "\n",
      "Epoch:   10/10    Loss: 3.8173309350013733\n",
      "\n",
      "Epoch:   10/10    Loss: 3.983357558250427\n",
      "\n",
      "Epoch:   10/10    Loss: 4.023218078613281\n",
      "\n",
      "Epoch:   10/10    Loss: 4.079990289211273\n",
      "\n",
      "Epoch:   10/10    Loss: 3.9964314484596253\n",
      "\n",
      "Epoch:   10/10    Loss: 4.070074601173401\n",
      "\n",
      "Epoch:   10/10    Loss: 3.8183499217033385\n",
      "\n",
      "Epoch:   10/10    Loss: 3.8423326897621153\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7810333132743836\n",
      "\n",
      "Epoch:   10/10    Loss: 3.8327638578414915\n",
      "\n",
      "Epoch:   10/10    Loss: 3.883022084236145\n",
      "\n",
      "Epoch:   10/10    Loss: 4.002684717178345\n",
      "\n",
      "Epoch:   10/10    Loss: 3.950214126110077\n",
      "\n",
      "Epoch:   10/10    Loss: 3.753524224758148\n",
      "\n",
      "Epoch:   10/10    Loss: 4.061699371337891\n",
      "\n",
      "Epoch:   10/10    Loss: 3.942174265384674\n",
      "\n",
      "Epoch:   10/10    Loss: 3.6607360672950744\n",
      "\n",
      "Epoch:   10/10    Loss: 3.9985534834861753\n",
      "\n",
      "Epoch:   10/10    Loss: 3.9529167461395263\n",
      "\n",
      "Epoch:   10/10    Loss: 3.759764769077301\n",
      "\n",
      "Epoch:   10/10    Loss: 4.098440742492675\n",
      "\n",
      "Epoch:   10/10    Loss: 3.852699267864227\n",
      "\n",
      "Epoch:   10/10    Loss: 4.172670488357544\n",
      "\n",
      "Epoch:   10/10    Loss: 3.9384513521194457\n",
      "\n",
      "Epoch:   10/10    Loss: 3.9218530082702636\n",
      "\n",
      "Epoch:   10/10    Loss: 3.813182909488678\n",
      "\n",
      "Epoch:   10/10    Loss: 3.950540404319763\n",
      "\n",
      "Epoch:   10/10    Loss: 3.809421672821045\n",
      "\n",
      "Epoch:   10/10    Loss: 3.962162957191467\n",
      "\n",
      "Epoch:   10/10    Loss: 3.8983094549179076\n",
      "\n",
      "Epoch:   10/10    Loss: 3.8181890511512755\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7923262763023375\n",
      "\n",
      "Epoch:   10/10    Loss: 4.075654866695404\n",
      "\n",
      "Epoch:   10/10    Loss: 4.257382977008819\n",
      "\n",
      "Epoch:   10/10    Loss: 3.8552686858177183\n",
      "\n",
      "Epoch:   10/10    Loss: 3.851619760990143\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7682479000091553\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7375197529792787\n",
      "\n",
      "Epoch:   10/10    Loss: 4.165794265270233\n",
      "\n",
      "Epoch:   10/10    Loss: 3.91017459154129\n",
      "\n",
      "Epoch:   10/10    Loss: 3.8634912848472593\n",
      "\n",
      "Epoch:   10/10    Loss: 3.9426395106315613\n",
      "\n",
      "Epoch:   10/10    Loss: 4.054035596847534\n",
      "\n",
      "Epoch:   10/10    Loss: 3.9055719900131227\n",
      "\n",
      "Epoch:   10/10    Loss: 3.6074192214012144\n",
      "\n",
      "Epoch:   10/10    Loss: 3.898726567029953\n",
      "\n",
      "Epoch:   10/10    Loss: 3.9043306636810304\n",
      "\n",
      "Epoch:   10/10    Loss: 3.729084985256195\n",
      "\n",
      "Epoch:   10/10    Loss: 3.6663335299491884\n",
      "\n",
      "Epoch:   10/10    Loss: 3.867075169086456\n",
      "\n",
      "Epoch:   10/10    Loss: 4.150085206031799\n",
      "\n",
      "Epoch:   10/10    Loss: 3.9957688450813293\n",
      "\n",
      "Epoch:   10/10    Loss: 3.9688371443748474\n",
      "\n",
      "Epoch:   10/10    Loss: 3.9070230817794798\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7696941781044004\n",
      "\n",
      "Epoch:   10/10    Loss: 3.649705731868744\n",
      "\n",
      "Epoch:   10/10    Loss: 3.854251654148102\n",
      "\n",
      "Epoch:   10/10    Loss: 3.747330412864685\n",
      "\n",
      "Epoch:   10/10    Loss: 3.7313312292099\n",
      "\n",
      "Epoch:   10/10    Loss: 4.473118240833283\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type RNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Trained and Saved\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "\n",
    "# create model and move to gpu if available\n",
    "rnn = RNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout=0.5)\n",
    "if train_on_gpu:\n",
    "    rnn.cuda()\n",
    "\n",
    "# defining loss and optimization functions for training\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# training the model\n",
    "from workspace_utils import active_session\n",
    "\n",
    "with active_session():\n",
    "    trained_rnn = train_rnn(rnn, batch_size, optimizer, criterion, num_epochs, show_every_n_batches)\n",
    "\n",
    "# saving the trained modely\n",
    "helper.save_model('./save/trained_rnn', trained_rnn)\n",
    "print('Model Trained and Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: How did you decide on your model hyperparameters? \n",
    "For example, did you try different sequence_lengths and find that one size made the model converge faster? What about your hidden_dim and n_layers; how did you decide on those?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** (Write answer, here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Checkpoint\n",
    "\n",
    "After running the above training cell, your model will be saved by name, `trained_rnn`, and if you save your notebook progress, **you can pause here and come back to this code at another time**. You can resume your progress by running the next cell, which will load in our word:id dictionaries _and_ load in your saved model by name!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import torch\n",
    "import helper\n",
    "import problem_unittests as tests\n",
    "\n",
    "_, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()\n",
    "trained_rnn = helper.load_model('./save/trained_rnn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate TV Script\n",
    "With the network trained and saved, you'll use it to generate a new, \"fake\" Seinfeld TV script in this section.\n",
    "\n",
    "### Generate Text\n",
    "To generate the text, the network needs to start with a single word and repeat its predictions until it reaches a set length. You'll be using the `generate` function to do this. It takes a word id to start with, `prime_id`, and generates a set length of text, `predict_len`. Also note that it uses topk sampling to introduce some randomness in choosing the most likely next word, given an output set of word scores!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def generate(rnn, prime_id, int_to_vocab, token_dict, pad_value, predict_len=100):\n",
    "    \"\"\"\n",
    "    Generate text using the neural network\n",
    "    :param decoder: The PyTorch Module that holds the trained neural network\n",
    "    :param prime_id: The word id to start the first prediction\n",
    "    :param int_to_vocab: Dict of word id keys to word values\n",
    "    :param token_dict: Dict of puncuation tokens keys to puncuation values\n",
    "    :param pad_value: The value used to pad a sequence\n",
    "    :param predict_len: The length of text to generate\n",
    "    :return: The generated text\n",
    "    \"\"\"\n",
    "    rnn.eval()\n",
    "    \n",
    "    # create a sequence (batch_size=1) with the prime_id\n",
    "    current_seq = np.full((1, sequence_length), pad_value)\n",
    "    current_seq[-1][-1] = prime_id\n",
    "    predicted = [int_to_vocab[prime_id]]\n",
    "    \n",
    "    for _ in range(predict_len):\n",
    "        if train_on_gpu:\n",
    "            current_seq = torch.LongTensor(current_seq).cuda()\n",
    "        else:\n",
    "            current_seq = torch.LongTensor(current_seq)\n",
    "        \n",
    "        # initialize the hidden state\n",
    "        hidden = rnn.init_hidden(current_seq.size(0))\n",
    "        \n",
    "        # get the output of the rnn\n",
    "        output, _ = rnn(current_seq, hidden)\n",
    "        \n",
    "        # get the next word probabilities\n",
    "        p = F.softmax(output, dim=1).data\n",
    "        if(train_on_gpu):\n",
    "            p = p.cpu() # move to cpu\n",
    "         \n",
    "        # use top_k sampling to get the index of the next word\n",
    "        top_k = 5\n",
    "        p, top_i = p.topk(top_k)\n",
    "        top_i = top_i.numpy().squeeze()\n",
    "        \n",
    "        # select the likely next word index with some element of randomness\n",
    "        p = p.numpy().squeeze()\n",
    "        word_i = np.random.choice(top_i, p=p/p.sum())\n",
    "        \n",
    "        # retrieve that word from the dictionary\n",
    "        word = int_to_vocab[word_i]\n",
    "        predicted.append(word)     \n",
    "        \n",
    "        # the generated word becomes the next \"current sequence\" and the cycle can continue\n",
    "        current_seq = np.roll(current_seq, -1, 1)\n",
    "        current_seq[-1][-1] = word_i\n",
    "    \n",
    "    gen_sentences = ' '.join(predicted)\n",
    "    \n",
    "    # Replace punctuation tokens\n",
    "    for key, token in token_dict.items():\n",
    "        ending = ' ' if key in ['\\n', '(', '\"'] else ''\n",
    "        gen_sentences = gen_sentences.replace(' ' + token.lower(), key)\n",
    "    gen_sentences = gen_sentences.replace('\\n ', '\\n')\n",
    "    gen_sentences = gen_sentences.replace('( ', '(')\n",
    "    \n",
    "    # return all the sentences\n",
    "    return gen_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a New Script\n",
    "It's time to generate the text. Set `gen_length` to the length of TV script you want to generate and set `prime_word` to one of the following to start the prediction:\n",
    "- \"jerry\"\n",
    "- \"elaine\"\n",
    "- \"george\"\n",
    "- \"kramer\"\n",
    "\n",
    "You can set the prime word to _any word_ in our dictionary, but it's best to start with a name for generating a TV script. (You can also start with any other names you find in the original text file!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:41: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jerry: play. unwind love. unwind california, we'll hear, we'll play ones mean matter matter only mean several matter matter what matter, are you true? cause robbing matter several shame are months than are robbing boss several shame several matter ever think are you robbing matter ever robbing several experience emergency matter? cause i mean mean we'll prove we'll be ever matter. we'll die. bout matter. cause are you scared.\n",
      "\n",
      "jerry: officer. what mean, california robbing robbing california ones, california? mean what mean, we'll prove several several ones idiot, only jerry is matter what mean defendants are matter? several months. matter matter, are you kidding? we'll tell you several ones matter matter, matter she have have play court than order several boss ever mean are you robbing california robbing court several matter ever have ever play york ones ever matter matter are we gonna make living living boss ever mean california says think do we mean, mean mean matter several idiot toxic matter are letting you have got correct boss ever do matter?\n",
      "\n",
      "jerry: what?\n",
      "\n",
      "sales woman: mr. ross: apartment] k- five dollars. : what mean, california? robbing robbing play play california matter are matter are you ready? do you ever die ever mean several matter ones are matter what are you doing here? mean several matter ones matter what are you ever got robbing california appointment robbing matter ever mean have be smart ones robbing matter ever mean mean are you scared several boss ever matter ever have ever order robbing court ever matter robbing court several year robbing court several months? mean several minutes are robbing robbing the fling matter?\n",
      "\n",
      "elaine: oh, she knew she got robbing court, matter are i mean are robbing robbing court, make boss ever mean are robbing california several matter matter ever mean. are you kidding. cause glory matter matter, what are you payin' ever matter defendants matter matter, matter what's goin' on. cause do you think what mean mean are robbing robbing robbing court than matter several idiot? what are you doing, matter defendants matter correct must be matter, matter we\n"
     ]
    }
   ],
   "source": [
    "# run the cell multiple times to get different results!\n",
    "gen_length = 400 # modify the length to your preference\n",
    "prime_word = 'jerry' # name for starting the script\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "pad_word = helper.SPECIAL_WORDS['PADDING']\n",
    "generated_script = generate(trained_rnn, vocab_to_int[prime_word + ':'], int_to_vocab, token_dict, vocab_to_int[pad_word], gen_length)\n",
    "print(generated_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save your favorite scripts\n",
    "\n",
    "Once you have a script that you like (or find interesting), save it to a text file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save script to a text file\n",
    "f =  open(\"generated_script_1.txt\",\"w\")\n",
    "f.write(generated_script)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The TV Script is Not Perfect\n",
    "It's ok if the TV script doesn't make perfect sense. It should look like alternating lines of dialogue, here is one such example of a few generated lines.\n",
    "\n",
    "### Example generated script\n",
    "\n",
    ">jerry: what about me?\n",
    ">\n",
    ">jerry: i don't have to wait.\n",
    ">\n",
    ">kramer:(to the sales table)\n",
    ">\n",
    ">elaine:(to jerry) hey, look at this, i'm a good doctor.\n",
    ">\n",
    ">newman:(to elaine) you think i have no idea of this...\n",
    ">\n",
    ">elaine: oh, you better take the phone, and he was a little nervous.\n",
    ">\n",
    ">kramer:(to the phone) hey, hey, jerry, i don't want to be a little bit.(to kramer and jerry) you can't.\n",
    ">\n",
    ">jerry: oh, yeah. i don't even know, i know.\n",
    ">\n",
    ">jerry:(to the phone) oh, i know.\n",
    ">\n",
    ">kramer:(laughing) you know...(to jerry) you don't know.\n",
    "\n",
    "You can see that there are multiple characters that say (somewhat) complete sentences, but it doesn't have to be perfect! It takes quite a while to get good results, and often, you'll have to use a smaller vocabulary (and discard uncommon words), or get more data.  The Seinfeld dataset is about 3.4 MB, which is big enough for our purposes; for script generation you'll want more than 1 MB of text, generally. \n",
    "\n",
    "# Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook. Save the notebook file as \"dlnd_tv_script_generation.ipynb\" and save another copy as an HTML file by clicking \"File\" -> \"Download as..\"->\"html\". Include the \"helper.py\" and \"problem_unittests.py\" files in your submission. Once you download these files, compress them into one zip file for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
